{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the KielMotionAnalysisToolbox (KielMAT). We are a Python based toolbox for processing motion data.</p> <p>The toolbox is aimed at motion researchers who want to use Python-based open-source software to process their data. We have implemented validated algorithms in modules to process motion data, as shown in the table below:</p>"},{"location":"#overview-of-modules","title":"Overview of Modules","text":"<p>The table below provides an overview of key modules, their functionalities, input data, validation datasets, and outputs.</p> Module Description Input Data Validation Dataset Event Type Output Parameters Gait Sequence Detection Detects gait sequences 3D accelerations from lower back IMU Mobilise-D and KeepControl gait sequence - Initial Contact Detection Detects initial and final contacts within each gait cycle 3D accelerations from lower back IMU Mobilise-D and KeepControl initial contact, final contact Temporal parameters (e.g., step time, stride time) Physical Activity Monitoring Monitors physical activity levels 3D accelerations from wrist IMU Fair Park \u2161 - Mean and duration of activity level Postural Transition Detection Detects sit-to-stand and stand-to-sit transitions 3D acceleration and gyroscope data from lower back IMU KeepControl and SENSE-PARK sit-to-stand, stand-to-sit Spatio-temporal parameters (e.g., postural transition angle) Turn Detection Detects turn movements 3D acceleration and gyroscope data from lower back IMU KeepControl and SENSE-PARK turn Spatio-temporal parameters (e.g., turn angle)"},{"location":"#units","title":"Units","text":"<p>The table below provides an overview of commonly used value types and their corresponding units. Before starting work with modules in the toolbox, ensure that all data is in standard SI units as specified. This ensures compatibility with the algorithms, which are designed to expect inputs in these units.</p> Value Unit Acceleration m/s\u00b2 Angular Velocity deg/s Velocity m/s Distance m Time s Sampling Rate Hz"},{"location":"#installation","title":"Installation","text":"<p>The toolbox has been released on pypi and can be installed via pip: <pre><code>pip install kielmat\n</code></pre> It requires Python 3.10 or higher.</p>"},{"location":"#data-classes","title":"Data classes","text":"<p>The idea is that various motion data can be loaded into our dedicated dataclass which rely on principles from the Motion-BIDS standard.</p>"},{"location":"#data-classes-conceptual-framework","title":"Data classes: conceptual framework","text":"<p>Motion data is recorded with many different systems and modalities, each with their own proprietary data format. KielMAT deals with this by organizing both data and metadata in a BIDS-like format. The BIDS format suggests that motion recording data from a single tracking system is organized in a single <code>*_tracksys-&lt;label&gt;_motion.tsv</code> file.</p> <p>[!NOTE] A tracking system is defined as a group of motion channels that share hardware properties (the recording device) and software properties (the recording duration and number of samples).</p> <p>In KielMAT, data from a single tracking system is therefore loaded into a single <code>pandas.DataFrame</code>. The column headers of this <code>pandas.DataFrame</code> refer to the channels, and the corresponding channels information is likewise available as a <code>pandas.DataFrame</code>.</p> <p>Similarly, if any events are available for the given recording, these are loaded into a single <code>pandas.DataFrame</code> for each tracking system as well. The events derived from the toolbox can be exported to a BIDS like '*_events.tsv' file.</p>"},{"location":"#data-classes-in-practice","title":"Data classes: in practice","text":"<p>These concepts are translated into a KielMAT dataclass for each recording: <code>KielMATRecording</code>: <pre><code>classDiagram\n   class KielMATRecording {\n      data: dict[str, pd.DataFrame]\n      channels: dict[str, pd.DataFrame]\n      info: None | dict[str, Any] = None\n      events: None | dict[str, pd.DataFrame] = None\n      events_info: None | dict[str, Any] = None\n      add_events(tracking_system, new_events)\n      add_info(key, value)\n      export_events(file_path, tracking_system=None, file_name=None, bids_compatible_fname=False)\n   }\n</code></pre>  A recording consists of the motion data from one or more tracking systems, where each tracking system may consist motion data from one or more tracked points. Therefore, the motion data (<code>KielMATRecording.data</code>) are organized as a dictionary where the dictionary keys refer to the tracking systems, and the corresponding values the actual (raw) data as a <code>pandas.DataFrame</code>. The description of data channels (<code>KielMATRecording.channels</code>) is availabe as a dictionary with the same keys, and the values contain the channels description.</p>"},{"location":"#example-1-custom-dataset","title":"Example 1: Custom Dataset","text":"<p>You can create a KielMATRecording instance from your own motion data.  Suppose you have motion data from your tracking system in a CSV file structured as follows:</p> <pre><code>      timestamp  YourTrackedPoint_ACCEL_x  YourTrackedPoint_ACCEL_y  YourTrackedPoint_ACCEL_z  YourTrackedPoint_GYRO_x  YourTrackedPoint_GYRO_y  YourTrackedPoint_GYRO_z\n0     0.00       0.1                       0.2                       9.8                       0.01                     0.02                     0.03\n1     0.01       0.1                       0.2                       9.8                       0.01                     0.02                     0.03\n...   ...        ...                       ...                       ...                       ...                      ...                      ...\n</code></pre> <p>You can create a <code>KielMATRecording</code> as follows:</p> <p><pre><code>import pandas as pd\nfrom kielmat.utils.kielmat_dataclass import KielMATRecording\n\n# Load your motion data into a pandas DataFrame\nmotion_data = pd.read_csv(\"path_to_your_data.csv\")\n\n# Calculate the sampling frequency using the timestamp column\ntime_diff = motion_data[\"timestamp\"].diff().dropna()  # Calculate time differences\nsampling_frequency = 1 / time_diff.mean()  # Sampling frequency in Hz\n\n# Drop the timestamp column, as it is not needed in the motion data\nmotion_data = motion_data.drop(columns=[\"timestamp\"])\n\n# Define the tracking system and tracked point names\ntracking_system = \"YourTrackingSystem\"\ntracked_point = \"YourTrackedPoint\"\n\n# Create the data dictionary\ndata = {tracking_system: motion_data}\n\n# Create the channels DataFrame\nchannels_info = pd.DataFrame({\n    \"name\": [f\"{tracked_point}_ACCEL_x\", f\"{tracked_point}_ACCEL_y\", \n             f\"{tracked_point}_ACCEL_z\", f\"{tracked_point}_GYRO_x\", \n             f\"{tracked_point}_GYRO_y\", f\"{tracked_point}_GYRO_z\"],\n    \"type\": [\"ACCEL\", \"ACCEL\", \"ACCEL\", \"GYRO\", \"GYRO\", \"GYRO\"],\n    \"component\": [\"x\", \"y\", \"z\", \"x\", \"y\", \"z\"],\n    \"tracked_point\": [tracked_point] * 6,\n    \"units\": [\"g\", \"g\", \"g\", \"deg/s\", \"deg/s\", \"deg/s\"],\n    \"sampling_frequency\": [sampling_frequency] * 6\n})\n\n# Create the channels dictionary\nchannels = {tracking_system: channels_info}\n\n# Create a KielMATRecording instance\nrecording = KielMATRecording(data=data, channels=channels)\n\n# Print data and channels information\nprint(recording.data)\nprint(recording.channels)\n</code></pre> <pre><code>   {'YourTrackingSystem':    YourTrackedPoint_ACCEL_x  YourTrackedPoint_ACCEL_y  \\\n   0                         0.1                       0.2   \n   1                         0.1                       0.2   \n   ...                       ...                       ...    \n\n      YourTrackedPoint_ACCEL_z  YourTrackedPoint_GYRO_x  YourTrackedPoint_GYRO_y  \\\n   0                       9.8                     0.01                     0.02   \n   1                       9.8                     0.01                     0.02   \n   ...                     ...                     ...                      ...      \n\n      YourTrackedPoint_GYRO_z  \n   0                     0.03  \n   1                     0.03  \n   ...                   ...  }\n\n   {'YourTrackingSystem':             name component   type     tracked_point  units  \\\n   0  YourTrackedPoint_ACCEL_x         x  ACCEL  YourTrackedPoint      g   \n   1  YourTrackedPoint_ACCEL_y         y  ACCEL  YourTrackedPoint      g   \n   2  YourTrackedPoint_ACCEL_z         z  ACCEL  YourTrackedPoint      g   \n   3   YourTrackedPoint_GYRO_x         x   GYRO  YourTrackedPoint  deg/s   \n   4   YourTrackedPoint_GYRO_y         y   GYRO  YourTrackedPoint  deg/s   \n   5   YourTrackedPoint_GYRO_z         z   GYRO  YourTrackedPoint  deg/s   \n\n      sampling_frequency  \n   0               100.0  \n   1               100.0  \n   2               100.0  \n   3               100.0  \n   4               100.0  \n   5               100.0  }\n</code></pre></p>"},{"location":"#example-2-mobilise-d-dataset","title":"Example 2: Mobilise-D Dataset","text":"<p>You can also load data from the <code>Mobilise-D</code> dataset, one of the datasets available in the toolbox. To do this, use the <code>load_recording()</code> function in the <code>kielmat.datasets.mobilised</code>.</p> <pre><code>import numpy as np\nfrom pathlib import Path\nfrom kielmat.datasets import mobilised\n\n# Load data from the Mobilise-D dataset\nrecording = mobilised.load_recording()\n\n# The keys of the recording\nrecording.__dict__.keys()\ndict_keys(['data', 'channels', 'info', 'events', 'events_info'])\n\n# Print the data information\nprint(recording.data)\n{'SU':         LowerBack_ACCEL_x  LowerBack_ACCEL_y  LowerBack_ACCEL_z  \\\n0              0.933334           0.084820          -0.302665   \n1              0.932675           0.084844          -0.300591   \n2              0.932350           0.082886          -0.310576   \n3              0.929716           0.081786          -0.303551   \n4              0.932825           0.077879          -0.308859   \n...                   ...                ...                ...   \n693471        -0.192553          -0.016052          -0.984290   \n693472        -0.189575          -0.016449          -0.988130   \n693473        -0.191176          -0.017954          -0.983820   \n693474        -0.189691          -0.014539          -0.986376   \n693475        -0.192993          -0.015306          -0.989452   \n\n               LowerBack_GYRO_x  LowerBack_GYRO_y  LowerBack_GYRO_z  \\\n0              5.600066          1.120697          0.489152   \n1              5.440734          1.401663          0.279477   \n2              5.196312          1.168802          0.435765   \n3              5.553083          1.116346          0.383447   \n4              5.437505          0.892803         -0.150115   \n...                  ...               ...               ...   \n693471        -0.225874          0.832856          0.704711   \n693472        -0.393438          0.598116          0.522755   \n693473        -0.430749          0.417541          0.282336   \n693474        -0.279277          0.559122          0.418693   \n693475        -0.563741          0.478618          0.411295   \n\n               LowerBack_MAGN_x  LowerBack_MAGN_y  LowerBack_MAGN_z  \\\n0             -93.972011        -25.023998         44.675028   \n1             -93.958012        -25.016007         44.610055   \n2             -93.946010        -25.000014         44.520078   \n3             -93.938007        -24.980018         44.411097   \n4             -93.935003        -24.957021         44.287113   \n...                  ...               ...               ...   \n693471        -50.718928        -36.997006         34.111960   \n693472        -50.649929        -37.003005         34.072972   \n693473        -50.579936        -37.008003         34.044986   \n693474        -50.515946        -37.011000         34.031004   \n693475        -50.460961        -37.010996         34.035025   \n\n               LowerBack_BARO_n/a  \n0              990.394600  \n1              990.395100  \n2              990.395600  \n3              990.396199  \n4              990.396700  \n...                    ...  \n693471         990.204600  \n693472         990.204900  \n693473         990.205200  \n693474         990.205500  \n693475         990.205800  \n\n[693476 rows x 10 columns]}\n\n# Print the channels information \nprint(recording.channels)\n{'SU':                  \n   name                 type  component   tracked_point  units    sampling_frequency\n0  LowerBack_ACCEL_x    Acc   x           LowerBack      g        100.0\n1  LowerBack_ACCEL_y    Acc   y           LowerBack      g        100.0\n2  LowerBack_ACCEL_z    Acc   z           LowerBack      g        100.0\n3  LowerBack_ANGVEL_x   Gyr   x           LowerBack      deg/s    100.0\n4  LowerBack_ANGVEL_y   Gyr   y           LowerBack      deg/s    100.0\n5  LowerBack_ANGVEL_z   Gyr   z           LowerBack      deg/s    100.0\n6  LowerBack_MAGN_x     Mag   x           LowerBack      \u00b5T       100.0\n7  LowerBack_MAGN_y     Mag   y           LowerBack      \u00b5T       100.0\n8  LowerBack_MAGN_z     Mag   z           LowerBack      \u00b5T       100.0\n9  LowerBack_BARO_n/a   Bar   n/a         LowerBack      hPa      100.0, \n}\n</code></pre> <p>[!NOTE] In the examples you find a tutorial (Load data into KielMAT) that explains the basics of the dataclass and how to work with them.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>We welcome contributions to KielMAT! Please refer to our contributing guide for more details.</p>"},{"location":"#paper","title":"Paper","text":"<p>The paper has been recently published in JOSS. You can find the paper here.</p>"},{"location":"#authors","title":"Authors","text":"<p>Masoud Abedinifar, Julius Welzel, Walter Maetzler, Clint Hansen &amp; Robbin Romijnders</p> <p></p>"},{"location":"background/","title":"Background","text":"<p>The definition of our data classes is derived from the Brain Imaging Data Structure (BIDS) standards. The BIDS extension for motion analysis requires that motion data from each tracking system is stored in a single <code>*_motion.tsv</code> file. A tracking system is defined as a group of motion channels that share hardware properties (the recording device) and software properties (the recording duration and number of samples). All relevant metadata about any tracking system is stored in an accompanying sidecar <code>*_tracksys-&lt;label&gt;_motion.json</code> file. Data from different tracking systems are stored in different <code>*_tracksys-&lt;label&gt;_motion.tsv</code> files, each of which is accompanied by <code>*_tracksys-&lt;label&gt;_motion.json</code> and <code>*_tracksys-&lt;label&gt;_channels.tsv</code> files.</p>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing-guide","title":"Contributing guide","text":"<p>Thanks for considering contributing to our toolbox! KielMAT is an open-source project and we welcome contributions from anyone to further enhance this project</p> <p>There are lots of ways to contribute, such as: - Use the software, and when you find bugs, tell us about them! We can only fix the bugs we know about. - Tell us about parts of the documentation that you find confusing or unclear. - Tell us about things you wish KielMAT could do, or things it can do but you wish they were easier. - Fix bugs. - Implement new features. - Improve existing tutorials or write new ones.</p> <p>To report bugs, request new features, or ask about confusing documentation, it\u2019s usually best to open a new issue on GitHub. For better reproducibility, be sure to include information about your operating system and KielMAT version, and (if applicable) include a reproducible code sample that is as short as possible and ideally uses one of our example datasets.</p>"},{"location":"contributing/#overview","title":"Overview","text":"<p>In general you'll be working with three different copies of the the KielMAT codebase: the official remote copy at https://github.com/neurogeriatricskiel/KielMAT (usually called <code>upstream</code>), your remote <code>fork</code> of the upstream repository (similar URL, but with your username in place of <code>KielMAT</code>, and usually called <code>origin</code>), and the local copy of the codebase on your computer. The typical contribution process is to:</p> <ol> <li>synchronize your local copy with <code>upstream</code></li> <li>make changes to your local copy</li> <li><code>push</code> your changes to <code>origin</code> (your remote fork of the upstream)</li> <li>submit a <code>pull request</code> from your fork into <code>upstream</code></li> </ol>"},{"location":"contributing/#setting-up-your-local-development-environment","title":"Setting up your local development environment","text":"<ol> <li>Clone the repository</li> <li>Set up the environment via poetry. (If you don't have poetry, you can install it from here.) Then go to the repository directory, and run <code>poetry install</code>.</li> <li>Make changes to the code</li> <li>Push to your fork</li> <li>Open a Pull request</li> </ol>"},{"location":"dataclass/","title":"Dataclass","text":"<p>In the following, the KielMAT dataclass is described. The dataclass is used to store motion data in a standardized way. We provide a small set of import functions, each of which returns a <code>pandas.DataFrame</code> or a dict. Users should easily be able to write their own import functions to get their data into the provided dataclass (this step might take some thinking). After the data is in the dataclass, running functions on the data from our toolbox should be really straightforward.</p> <pre><code>classDiagram\n   class KielMATRecording {\n      data: dict[str, pd.DataFrame]\n      channels: dict[str, pd.DataFrame]\n      info: None | dict[str, Any] = None\n      events: None | dict[str, pd.DataFrame] = None\n      events_info: None | dict[str, Any] = None\n      add_events(tracking_system, new_events)\n      add_info(key, value)\n      export_events(file_path, tracking_system=None, file_name=None, bids_compatible_fname=False)\n      validate_channels() -&gt; str\n   }\n</code></pre> <p>A recording consists of the motion data from one or more tracking systems, where each tracking system may consist motion data from one or more tracked points. Therefore, the motion data (<code>KielMATRecording.data</code>) are organized as a dictionary where the dictionary keys refer to the tracking systems, and the corresponding values the actual (raw) data as a <code>pandas.DataFrame</code>. The description of data channels (<code>KielMATRecording.channels</code>) is availabe as a dictionary with the same keys, and the values contain the channels description.</p>"},{"location":"dataclass/#utils.kielmat_dataclass.KielMATRecording","title":"<code>KielMATRecording</code>  <code>dataclass</code>","text":"<p>Dataclass to hold any data and associated infos for a KielMAT recording.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>dict</code> <p>The data is stored as a pandas DataFrame for each unique tracking system.</p> <code>channels</code> <code>dict</code> <p>The channels descriptions are stored as a pandas DataFrame for each unique tracking system.</p> <code>info</code> <code>dict</code> <p>The infos on the subject, task, and more, are stored as a nested dictionary.</p> <code>events</code> <code>dict</code> <p>The events are stored as a pandas DataFrame for each unique tracking system.</p> <code>events_info</code> <code>dict</code> <p>The event infos are stored as a nested dictionary.</p> Source code in <code>kielmat/utils/kielmat_dataclass.py</code> <pre><code>@dataclass(kw_only=True)\nclass KielMATRecording:\n    \"\"\"Dataclass to hold any data and associated infos for a KielMAT recording.\n\n    Attributes:\n        data (dict): The data is stored as a pandas DataFrame for each unique tracking system.\n        channels (dict): The channels descriptions are stored as a pandas DataFrame for each unique tracking system.\n        info (dict): The infos on the subject, task, and more, are stored as a nested dictionary.\n        events (dict): The events are stored as a pandas DataFrame for each unique tracking system.\n        events_info (dict): The event infos are stored as a nested dictionary.\n    \"\"\"\n\n    data: dict[str, pd.DataFrame]\n    channels: dict[str, pd.DataFrame]\n    info: None | dict[str, Any] = None\n    events: None | dict[str, pd.DataFrame] = None\n    events_info: None | dict[str, Any] = None\n\n    def __post_init__(self):\n        # Validate channels when an instance is created\n        self.validate_channels()\n\n    def validate_channels(self) -&gt; str:\n        \"\"\"\n        Validates the channel dataframes for each system.\n\n        This function checks if the channel dataframes have the required columns in the correct order,\n        and if the data types of the columns are valid. It also performs additional value checks for\n        optional columns.\n\n        Raises:\n            ValueError: If the channel dataframe does not have the required columns in the correct order,\n                or if the 'component' column contains invalid values, or if the 'type' column is not\n                uppercase strings, or if the 'status' column contains invalid values.\n            TypeError: If the 'name' column is not of type string.\n\n        Returns:\n            Confirmation message indicating that all channel dataframes are valid.\n        \"\"\"\n        for system_name, df in self.channels.items():\n            # Check required columns and their order\n            if not df.columns.tolist()[:6] == REQUIRED_COLUMNS:\n                raise ValueError(\n                    f\"Channels dataframe for '{system_name}' does not have the required columns in correct order. The correct order is: {REQUIRED_COLUMNS}.\"\n                )\n\n            # Check data types\n            if not all(isinstance(name, str) for name in df[\"name\"]):\n                raise TypeError(\n                    f\"Column 'name' in '{system_name}' must be of type string.\"\n                )\n            invalid_components = set(\n                [\n                    item\n                    for item in df[\"component\"]\n                    if item not in VALID_COMPONENT_TYPES and not pd.isna(item)\n                ]\n            )\n            if invalid_components:\n                raise ValueError(\n                    f\"Column 'component' in '{system_name}' contains invalid values: {invalid_components}.\"\n                )\n            if not all(isinstance(typ, str) and typ.isupper() for typ in df[\"type\"]):\n                raise ValueError(\n                    f\"Column 'type' in '{system_name}' must be uppercase strings.\"\n                )\n\n            # Additional value checks for optional columns\n            if \"status\" in df.columns and not all(\n                s in VALID_CHANNEL_STATUS_VALUES for s in df[\"status\"] if s != \"n/a\"\n            ):\n                raise ValueError(\n                    f\"Column 'status' in '{system_name}' contains invalid values.\"\n                )\n\n        return \"All channel dataframes are valid.\"\n\n    def add_events(self, tracking_system: str, new_events: pd.DataFrame) -&gt; None:\n        \"\"\"Add events to the recording for a specific tracking system.\n\n        Args:\n            tracking_system (str): Tracking system for which events are to be added.\n            new_events (pd.DataFrame): Events to be added in BIDS format.\n        \"\"\"\n        if self.events is None:\n            self.events = {}\n\n        if tracking_system not in self.events:\n            self.events[tracking_system] = new_events\n        else:\n            existing_events = self.events[tracking_system]\n            self.events[tracking_system] = pd.concat(\n                [existing_events, new_events], ignore_index=True\n            )\n\n    def add_info(self, key: str, value: Any) -&gt; None:\n        \"\"\"Add information to the info dictionary. Valid keys are : 'Subject', 'Session', 'Task'.\n\n        Args:\n            key (str): The key for the information.\n            value (Any): The value of the information.\n\n        Raises:\n            ValueError: If the provided 'key' is not one of the valid info keys.\n\n        Examples:\n            &gt;&gt;&gt; recording.add_info(\"Subject\", \"01\")\n        \"\"\"\n        if self.info is None:\n            self.info = {}\n\n        # Check if the key belongs to a list of keywords\n        if key not in VALID_INFO_KEYS:\n            print(\n                f\"Warning: Invalid info key '{key}'. Valid info keys are: {VALID_INFO_KEYS}\"\n            )\n\n        # add the key-value pair to the info dictionary\n        self.info[key] = value\n\n        # Check if the value are lower case, if not, convert to lower case and give warning\n        if isinstance(value, str):\n            self.info[key] = value.lower()\n            print(\n                f\"Warning: The value of the key '{key}' should be lower case. Converted to lower case.\"\n            )\n\n        # check if value contains underscore or space, if yes, remove and give warning\n        if \"_\" in value or \" \" in value:\n            self.info[key] = value.replace(\"_\", \"\").replace(\" \", \"\")\n            print(\n                f\"Warning: The value of the key '{key}' should not contain underscore or space. Removed underscore and space.\"\n            )\n\n    def export_events(\n        self,\n        file_path: str,\n        tracking_system: Optional[str] = None,\n        file_name: Optional[str] = None,\n        bids_compatible_fname: Optional[bool] = False,\n    ) -&gt; None:\n        \"\"\"Export events for a specific tracking system to a file.\n\n        Args:\n            tracking_system (Optional[str]): Tracking system for which events are to be exported.\n                If None, events from all tracking systems will be exported (default is None).\n            file_path (str): Path to the directory where the file should be saved.\n            file_name (Optional[str]): Name of the file to be exported. If None, a default name will be used.\n            bids_compatible_fname (bool): Flag indicating whether the exported filename should be BIDS compatible (default is False).\n        \"\"\"\n        if self.events is not None:\n            if tracking_system is None:\n                all_events = pd.concat(\n                    self.events.values(),\n                    keys=self.events.keys(),\n                    names=[\"tracking_system\"],\n                )\n                if file_name is None:\n                    file_name = \"all_events.csv\"\n                if bids_compatible_fname:\n                    # Construct the filename using subject ID and task name\n                    subject_id = self.info.get(\"Subject\", \"\")\n                    task_name = self.info.get(\"Task\", \"\")\n                    # check if subject_id and task_name are present in the info dictionary\n                    if subject_id == None or task_name == None:\n                        raise ValueError(\n                            \"Subject ID and Task Name should be specified in the info dictionary.\"\n                        )\n                    file_name = f\"sub-{subject_id}_task-{task_name}_events.csv\"\n                    # check if session is present in the info dictionary\n                    session = self.info.get(\"Session\")\n                    if session != None:\n                        file_name = f\"sub-{subject_id}_ses-{session}_task-{task_name}_events.csv\"\n                    file_path = Path(file_path).joinpath(file_name)\n                    all_events.to_csv(file_path, sep=\"\\t\", index=False)\n                else:\n                    file_path = Path(file_path).joinpath(file_name)\n                    all_events.to_csv(file_path, index=False)\n            elif tracking_system in self.events:\n                if file_name is None:\n                    file_name = f\"{tracking_system}_events.csv\"\n                if bids_compatible_fname:\n                    file_name = file_name.replace(\".csv\", \"_events.tsv\")\n                    file_path = Path(file_path).joinpath(file_name)\n                    self.events[tracking_system].to_csv(\n                        file_path, sep=\"\\t\", index=False\n                    )\n                else:\n                    file_path = Path(file_path).joinpath(file_name)\n                    self.events[tracking_system].to_csv(file_path, index=False)\n\n            # check if file_path is BIDS compatible\n            if bids_compatible_fname:\n                # validate the file_path\n                validator = BIDSValidator()\n                errors = validator.is_bids(file_path)\n                if errors:\n                    raise ValueError(f\"File path '{file_path}' is not BIDS compatible.\")\n</code></pre>"},{"location":"dataclass/#utils.kielmat_dataclass.KielMATRecording.add_events","title":"<code>add_events(tracking_system, new_events)</code>","text":"<p>Add events to the recording for a specific tracking system.</p> <p>Parameters:</p> Name Type Description Default <code>tracking_system</code> <code>str</code> <p>Tracking system for which events are to be added.</p> required <code>new_events</code> <code>DataFrame</code> <p>Events to be added in BIDS format.</p> required Source code in <code>kielmat/utils/kielmat_dataclass.py</code> <pre><code>def add_events(self, tracking_system: str, new_events: pd.DataFrame) -&gt; None:\n    \"\"\"Add events to the recording for a specific tracking system.\n\n    Args:\n        tracking_system (str): Tracking system for which events are to be added.\n        new_events (pd.DataFrame): Events to be added in BIDS format.\n    \"\"\"\n    if self.events is None:\n        self.events = {}\n\n    if tracking_system not in self.events:\n        self.events[tracking_system] = new_events\n    else:\n        existing_events = self.events[tracking_system]\n        self.events[tracking_system] = pd.concat(\n            [existing_events, new_events], ignore_index=True\n        )\n</code></pre>"},{"location":"dataclass/#utils.kielmat_dataclass.KielMATRecording.add_info","title":"<code>add_info(key, value)</code>","text":"<p>Add information to the info dictionary. Valid keys are : 'Subject', 'Session', 'Task'.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key for the information.</p> required <code>value</code> <code>Any</code> <p>The value of the information.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provided 'key' is not one of the valid info keys.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; recording.add_info(\"Subject\", \"01\")\n</code></pre> Source code in <code>kielmat/utils/kielmat_dataclass.py</code> <pre><code>def add_info(self, key: str, value: Any) -&gt; None:\n    \"\"\"Add information to the info dictionary. Valid keys are : 'Subject', 'Session', 'Task'.\n\n    Args:\n        key (str): The key for the information.\n        value (Any): The value of the information.\n\n    Raises:\n        ValueError: If the provided 'key' is not one of the valid info keys.\n\n    Examples:\n        &gt;&gt;&gt; recording.add_info(\"Subject\", \"01\")\n    \"\"\"\n    if self.info is None:\n        self.info = {}\n\n    # Check if the key belongs to a list of keywords\n    if key not in VALID_INFO_KEYS:\n        print(\n            f\"Warning: Invalid info key '{key}'. Valid info keys are: {VALID_INFO_KEYS}\"\n        )\n\n    # add the key-value pair to the info dictionary\n    self.info[key] = value\n\n    # Check if the value are lower case, if not, convert to lower case and give warning\n    if isinstance(value, str):\n        self.info[key] = value.lower()\n        print(\n            f\"Warning: The value of the key '{key}' should be lower case. Converted to lower case.\"\n        )\n\n    # check if value contains underscore or space, if yes, remove and give warning\n    if \"_\" in value or \" \" in value:\n        self.info[key] = value.replace(\"_\", \"\").replace(\" \", \"\")\n        print(\n            f\"Warning: The value of the key '{key}' should not contain underscore or space. Removed underscore and space.\"\n        )\n</code></pre>"},{"location":"dataclass/#utils.kielmat_dataclass.KielMATRecording.export_events","title":"<code>export_events(file_path, tracking_system=None, file_name=None, bids_compatible_fname=False)</code>","text":"<p>Export events for a specific tracking system to a file.</p> <p>Parameters:</p> Name Type Description Default <code>tracking_system</code> <code>Optional[str]</code> <p>Tracking system for which events are to be exported. If None, events from all tracking systems will be exported (default is None).</p> <code>None</code> <code>file_path</code> <code>str</code> <p>Path to the directory where the file should be saved.</p> required <code>file_name</code> <code>Optional[str]</code> <p>Name of the file to be exported. If None, a default name will be used.</p> <code>None</code> <code>bids_compatible_fname</code> <code>bool</code> <p>Flag indicating whether the exported filename should be BIDS compatible (default is False).</p> <code>False</code> Source code in <code>kielmat/utils/kielmat_dataclass.py</code> <pre><code>def export_events(\n    self,\n    file_path: str,\n    tracking_system: Optional[str] = None,\n    file_name: Optional[str] = None,\n    bids_compatible_fname: Optional[bool] = False,\n) -&gt; None:\n    \"\"\"Export events for a specific tracking system to a file.\n\n    Args:\n        tracking_system (Optional[str]): Tracking system for which events are to be exported.\n            If None, events from all tracking systems will be exported (default is None).\n        file_path (str): Path to the directory where the file should be saved.\n        file_name (Optional[str]): Name of the file to be exported. If None, a default name will be used.\n        bids_compatible_fname (bool): Flag indicating whether the exported filename should be BIDS compatible (default is False).\n    \"\"\"\n    if self.events is not None:\n        if tracking_system is None:\n            all_events = pd.concat(\n                self.events.values(),\n                keys=self.events.keys(),\n                names=[\"tracking_system\"],\n            )\n            if file_name is None:\n                file_name = \"all_events.csv\"\n            if bids_compatible_fname:\n                # Construct the filename using subject ID and task name\n                subject_id = self.info.get(\"Subject\", \"\")\n                task_name = self.info.get(\"Task\", \"\")\n                # check if subject_id and task_name are present in the info dictionary\n                if subject_id == None or task_name == None:\n                    raise ValueError(\n                        \"Subject ID and Task Name should be specified in the info dictionary.\"\n                    )\n                file_name = f\"sub-{subject_id}_task-{task_name}_events.csv\"\n                # check if session is present in the info dictionary\n                session = self.info.get(\"Session\")\n                if session != None:\n                    file_name = f\"sub-{subject_id}_ses-{session}_task-{task_name}_events.csv\"\n                file_path = Path(file_path).joinpath(file_name)\n                all_events.to_csv(file_path, sep=\"\\t\", index=False)\n            else:\n                file_path = Path(file_path).joinpath(file_name)\n                all_events.to_csv(file_path, index=False)\n        elif tracking_system in self.events:\n            if file_name is None:\n                file_name = f\"{tracking_system}_events.csv\"\n            if bids_compatible_fname:\n                file_name = file_name.replace(\".csv\", \"_events.tsv\")\n                file_path = Path(file_path).joinpath(file_name)\n                self.events[tracking_system].to_csv(\n                    file_path, sep=\"\\t\", index=False\n                )\n            else:\n                file_path = Path(file_path).joinpath(file_name)\n                self.events[tracking_system].to_csv(file_path, index=False)\n\n        # check if file_path is BIDS compatible\n        if bids_compatible_fname:\n            # validate the file_path\n            validator = BIDSValidator()\n            errors = validator.is_bids(file_path)\n            if errors:\n                raise ValueError(f\"File path '{file_path}' is not BIDS compatible.\")\n</code></pre>"},{"location":"dataclass/#utils.kielmat_dataclass.KielMATRecording.validate_channels","title":"<code>validate_channels()</code>","text":"<p>Validates the channel dataframes for each system.</p> <p>This function checks if the channel dataframes have the required columns in the correct order, and if the data types of the columns are valid. It also performs additional value checks for optional columns.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the channel dataframe does not have the required columns in the correct order, or if the 'component' column contains invalid values, or if the 'type' column is not uppercase strings, or if the 'status' column contains invalid values.</p> <code>TypeError</code> <p>If the 'name' column is not of type string.</p> <p>Returns:</p> Type Description <code>str</code> <p>Confirmation message indicating that all channel dataframes are valid.</p> Source code in <code>kielmat/utils/kielmat_dataclass.py</code> <pre><code>def validate_channels(self) -&gt; str:\n    \"\"\"\n    Validates the channel dataframes for each system.\n\n    This function checks if the channel dataframes have the required columns in the correct order,\n    and if the data types of the columns are valid. It also performs additional value checks for\n    optional columns.\n\n    Raises:\n        ValueError: If the channel dataframe does not have the required columns in the correct order,\n            or if the 'component' column contains invalid values, or if the 'type' column is not\n            uppercase strings, or if the 'status' column contains invalid values.\n        TypeError: If the 'name' column is not of type string.\n\n    Returns:\n        Confirmation message indicating that all channel dataframes are valid.\n    \"\"\"\n    for system_name, df in self.channels.items():\n        # Check required columns and their order\n        if not df.columns.tolist()[:6] == REQUIRED_COLUMNS:\n            raise ValueError(\n                f\"Channels dataframe for '{system_name}' does not have the required columns in correct order. The correct order is: {REQUIRED_COLUMNS}.\"\n            )\n\n        # Check data types\n        if not all(isinstance(name, str) for name in df[\"name\"]):\n            raise TypeError(\n                f\"Column 'name' in '{system_name}' must be of type string.\"\n            )\n        invalid_components = set(\n            [\n                item\n                for item in df[\"component\"]\n                if item not in VALID_COMPONENT_TYPES and not pd.isna(item)\n            ]\n        )\n        if invalid_components:\n            raise ValueError(\n                f\"Column 'component' in '{system_name}' contains invalid values: {invalid_components}.\"\n            )\n        if not all(isinstance(typ, str) and typ.isupper() for typ in df[\"type\"]):\n            raise ValueError(\n                f\"Column 'type' in '{system_name}' must be uppercase strings.\"\n            )\n\n        # Additional value checks for optional columns\n        if \"status\" in df.columns and not all(\n            s in VALID_CHANNEL_STATUS_VALUES for s in df[\"status\"] if s != \"n/a\"\n        ):\n            raise ValueError(\n                f\"Column 'status' in '{system_name}' contains invalid values.\"\n            )\n\n    return \"All channel dataframes are valid.\"\n</code></pre>"},{"location":"faq/","title":"FAQ / Troubleshooting","text":""},{"location":"faq/#why-does-the-output-of-kielmat-not-make-sense","title":"Why does the output of KielMAT not make sense?","text":"<p>If the output you are getting from KielMAT does not make sense, please check the following:</p> <ul> <li>Is the sampling frequency correct?</li> <li>Are the units correct?</li> <li>Did you accidentally mix up the accelerometer and gyroscope data?</li> </ul>"},{"location":"faq/#what-units-are-my-data-in","title":"What units are my data in?","text":"<p>If you are unsure about the units of your data, you can do a quick and dirty check by looking at the data. For example, if you are looking at accelerometer data, you can check if the values are in the range of -1 to 1. If they are, the data is likely in g. If the values are in the range of -9.81 to 9.81, the data is likely in m/s^2. Similarly, for gyroscope data, if the values are in the range of -180 to 180, the data is likely in degrees per second.</p>"},{"location":"faq/#why-am-i-encountering-a-sslcertverificationerror","title":"Why am I encountering a <code>SSLCertVerificationError</code>?","text":"<p>The <code>SSLCertVerificationError</code> occurs when Python\u2019s SSL module encounters an issue verifying the SSL certificate of a remote server. This can happen in secure environments like institutional networks where network security policies might be more restrictive. To address this error, you may want to try the following:</p> <ul> <li>Update the certificate store: make sure that the certificate store used by Python is up-to-date. This can be done by updating the <code>certifi</code> package, which Python's <code>requests</code> library (commonly used for HTTP requests) relies on:  </li> </ul> <pre><code>pip install --upgrade certifi\n</code></pre> <ul> <li>Download the datasets manually: you can also manually download the datasets for the respective websites, and see if that works. For that purpose, navigate in your webbrowser to Zenodo for the Mobilise-D dataset or OpenNeuro for the Keep Control dataset, and  then download the datasets to a local folder. If you are not allowed to download the datasets from the respective websites, then it may help to contact your local IT department.</li> </ul>"},{"location":"datasets/","title":"Overview","text":"<p>This section of the project documentation focuses on the available datasets used within the KielMAT toolbox. These datasets are essential for testing and validating the functionality of the toolbox\u2019s modules. Below is an introduction to the available datasets, with links to further details and data access.</p>"},{"location":"datasets/#keep-control","title":"Keep Control","text":"<p>The Keep Control dataset is derived from the Keep Control project, which is part of an Industrial Academic Initial Training Network. This dataset includes full-body mobility data collected from both healthy and neurological cohorts, and is primarily used to validate inertial measurement unit (IMU) algorithms.</p>"},{"location":"datasets/#mobilise-d","title":"Mobilise-D","text":"<p>The Mobilise-D dataset is derived from the Mobilise-D consortium, a European project aimed at developing a comprehensive system for monitoring and evaluating people's gait using digital technologies. The dataset includes data collected using sensors worn on the body, such as a low back-worn inertial measurement unit (IMU). The dataset provides valuable insights into real-world gait analysis using wearable sensors and has been used to validate gait measurement methodologies.</p>"},{"location":"datasets/keepcontrol/","title":"KeepControl","text":""},{"location":"datasets/keepcontrol/#keep-control","title":"Keep Control","text":"<p>The Keep Control dataset derived from the Keep Control project and is a Industrial Academic Initial Training Network working towards specific diagnosis and treatment of age-related gait and balance deficits. Part of the dataset was made publicly available on figshare, and it was published as Warmerdam et al., Data, 2022, Full-Body Mobility Data to Validate Inertial Measurement Unit Algorithms in Healthy and Neurological Cohorts, doi: 10.3390/data7100136.</p> <p>For this dataset a simple load function is provided to load the data into the KielMAT dataclasses.</p>"},{"location":"datasets/keepcontrol/#datasets.keepcontrol.fetch_dataset","title":"<code>fetch_dataset(dataset_path=Path(__file__).parent / '_keepcontrol')</code>","text":"<p>Fetch the Keep Control dataset from the OpenNeuro repository. Args:     dataset_path (str | Path, optional): The path where the dataset is stored. Defaults to Path(file).parent/\"_keepcontrol\".</p> Source code in <code>kielmat/datasets/keepcontrol.py</code> <pre><code>def fetch_dataset(\n    dataset_path: str | Path = Path(__file__).parent / \"_keepcontrol\",\n) -&gt; None:\n    \"\"\"Fetch the Keep Control dataset from the OpenNeuro repository.\n    Args:\n        dataset_path (str | Path, optional): The path where the dataset is stored. Defaults to Path(__file__).parent/\"_keepcontrol\".\n    \"\"\"\n    dataset_path = Path(dataset_path) if isinstance(dataset_path, str) else dataset_path\n\n    # Check if target folder exists, if not create it\n    if not dataset_path.exists():\n        dataset_path.parent.joinpath(\"_keepcontrol\").mkdir(parents=True, exist_ok=True)\n\n    # check if the dataset has already been downloaded (directory is not empty), if not download it\n    if not any(dataset_path.iterdir()):\n        # Download the dataset using openneuro-py\n        openneuro.download(\n            dataset=\"ds005258\",  # this is the example Keep Control dataset on OpenNeuro, maintained by Julius Welzel\n            target_dir=dataset_path,\n        )\n\n    return\n</code></pre>"},{"location":"datasets/keepcontrol/#datasets.keepcontrol.load_recording","title":"<code>load_recording(dataset_path=Path(__file__).parent / '_keepcontrol', id='pp001', task='walkSlow', tracking_systems=['imu', 'omc'], tracked_points=None)</code>","text":"<p>Load a recording from the Keep Control validation study. Args:     dataset_path (str or Path, optional): The path to the dataset. Defaults to the \"_keepcontrol\" directory in the same directory as this file.     id (str): The ID of the recording.     tracking_systems (str or list of str): A string or list of strings representing the tracking systems for which data should be returned.     tracked_points (None, str or list of str, optional): The tracked points of interest. If None, all tracked points will be returned. Defaults to None. Returns:     KielMATRecording: An instance of the KielMATRecording dataclass containing the loaded data and channels.</p> Source code in <code>kielmat/datasets/keepcontrol.py</code> <pre><code>def load_recording(\n    dataset_path: str | Path = Path(__file__).parent / \"_keepcontrol\",\n    id: str = \"pp001\",\n    task: str = \"walkSlow\",\n    tracking_systems: Union[str, list[str]] = [\"imu\", \"omc\"],\n    tracked_points: Optional[Union[None, str, list[str]]] = None,\n):\n    \"\"\"\n    Load a recording from the Keep Control validation study.\n    Args:\n        dataset_path (str or Path, optional): The path to the dataset. Defaults to the \"_keepcontrol\" directory in the same directory as this file.\n        id (str): The ID of the recording.\n        tracking_systems (str or list of str): A string or list of strings representing the tracking systems for which data should be returned.\n        tracked_points (None, str or list of str, optional): The tracked points of interest. If None, all tracked points will be returned. Defaults to None.\n    Returns:\n        KielMATRecording: An instance of the KielMATRecording dataclass containing the loaded data and channels.\n    \"\"\"\n\n    # Fetch the dataset if it does not exist\n    if not dataset_path.exists():\n        fetch_dataset()\n\n    # check if id contains sub or sub- substring, if so replace it with ''\n    id = id.replace(\"sub\", \"\").replace(\"-\", \"\")\n\n    # check if task contains task or task- substring, if so replace it with ''\n    task = task.replace(\"task\", \"\").replace(\"-\", \"\")\n\n    # Put tracking systems in a list\n    if isinstance(tracking_systems, str):\n        tracking_systems = [tracking_systems]\n\n    # check if tracked points has been specified, if not use all tracked points\n    if tracked_points is None:\n        tracked_points = {\n            tracksys: VALID_TRACKED_POINTS[tracksys] for tracksys in tracking_systems\n        }\n    # Tracked points will be a dictionary mapping\n    # each tracking system to a list of tracked points of interest\n    if isinstance(tracked_points, str):\n        tracked_points = [tracked_points]\n    if isinstance(tracked_points, list):\n        tracked_points = {tracksys: tracked_points for tracksys in tracking_systems}\n    # use the VALID_TRACKED_POINTS dictionary to get the valid tracked points for each tracking system\n    # return error of some tracked_points are not valid\n    # log which of the specified tracked points are not valid\n    for tracksys in tracking_systems:\n        if not all(\n            tracked_point in VALID_TRACKED_POINTS[tracksys]\n            for tracked_point in tracked_points[tracksys]\n        ):\n            logging.warning(f\"Invalid tracked points for tracking system {tracksys}.\")\n            logging.warning(\n                f\"Valid tracked points are: {VALID_TRACKED_POINTS[tracksys]}\"\n            )\n            invalid_points = [\n                tracked_point\n                for tracked_point in tracked_points[tracksys]\n                if tracked_point not in VALID_TRACKED_POINTS[tracksys]\n            ]\n            logging.warning(f\"Invalid tracked points are: {invalid_points}\")\n            return\n\n    # Load data and channels for each tracking system\n    data_dict, channels_dict = {}, {}\n    for tracksys in tracking_systems:\n        # Find avaliable files for the give ID and task and tracking system\n        file_name = list(\n            dataset_path.glob(\n                f\"sub-{id}/motion/sub-{id}_task-{task}_tracksys-{tracksys}_*motion.tsv\"\n            )\n        )\n        # check if file exists, if not log message and return\n        if not file_name:\n            logging.warning(\n                f\"No files found for ID {id}, task {task}, and tracking system {tracksys}.\"\n            )\n            return\n        # check if multiple files are found, if so log message and return\n        if len(file_name) &gt; 1:\n            logging.warning(\n                f\"Multiple files found for ID {id}, task {task}, and tracking system {tracksys}.\"\n            )\n            return\n\n        # Load the data and channels for the tracking system\n        df_data = pd.read_csv(file_name[0], sep=\"\\t\")\n        df_channels = pd.read_csv(\n            file_name[0].parent\n            / f\"sub-{id}_task-{task}_tracksys-{tracksys}_channels.tsv\",\n            sep=\"\\t\",\n        )\n\n        # filter the data and channels to only include the tracked points of interest\n        df_channels = df_channels[\n            df_channels[\"tracked_point\"].isin(tracked_points[tracksys])\n        ]\n\n        # only keep df_data columns that are in df_channels\n        col_names = df_channels[\"name\"].values\n        df_data = df_data[col_names]\n\n        # transform the data and channels into a dictionary for the KielMATRecording dataclass\n        data_dict[tracksys] = df_data\n        channels_dict[tracksys] = df_channels\n\n    # construct data class\n    recording = KielMATRecording(data=data_dict, channels=channels_dict)\n\n    # add information about the recording to the data class\n    recording.add_info(\"Subject\", id)\n    recording.add_info(\"Task\", task)\n\n    return recording\n</code></pre>"},{"location":"datasets/mobilised/","title":"Mobilise-D","text":""},{"location":"datasets/mobilised/#mobilise-d","title":"Mobilise-D","text":"<p>The Mobilise-D dataset derived from the Mobilise-D consortium and is a European project that aims to develop a comprehensive system to monitor and evaluate people's gait based on digital technologies, including sensors worn on the body, such as a low back-worn inertial measurement unit (IMU). Example data were made publicly available as Mic\u00f3-Amigo et al., Zenodo, 2023, Assessing real-world gait with digital technology? Validation, insights and recommendations from the Mobilise-D consortium [Data set], doi: 10.5281/zenodo.7547125 and results for the entire dataset were published as Mic\u00f3-Amigo et al., Journal of NeuroEngineering and Rehabilitation, 2023, Assessing real-world gait with digital technology? Validation, insights and recommendations from the Mobilise-D consortium, doi: 10.1186/s12984-023-01198-5.</p> <p>For this dataset a simple load function is provided to load the data into the KielMAT dataclasses.</p>"},{"location":"datasets/mobilised/#datasets.mobilised.fetch_dataset","title":"<code>fetch_dataset(progressbar=True, dataset_path=Path(__file__).parent / '_mobilised')</code>","text":"<p>Fetch the Mobilise-D dataset from the Zenodo repository.</p> <p>Parameters:</p> Name Type Description Default <code>progressbar</code> <code>bool</code> <p>Whether to display a progressbar. Defaults to True.</p> <code>True</code> <code>dataset_path</code> <code>str | Path</code> <p>The path where the dataset is stored. Defaults to Path(file).parent/\"_mobilised\".</p> <code>parent / '_mobilised'</code> Source code in <code>kielmat/datasets/mobilised.py</code> <pre><code>def fetch_dataset(\n    progressbar: bool = True,\n    dataset_path: str | Path = Path(__file__).parent / \"_mobilised\",\n) -&gt; None:\n    \"\"\"Fetch the Mobilise-D dataset from the Zenodo repository.\n\n    Args:\n        progressbar (bool, optional): Whether to display a progressbar. Defaults to True.\n        dataset_path (str | Path, optional): The path where the dataset is stored. Defaults to Path(__file__).parent/\"_mobilised\".\n    \"\"\"\n    dataset_path = Path(dataset_path) if isinstance(dataset_path, str) else dataset_path\n\n    # Check if zip archive has already been downloaded\n    if not dataset_path.exists():\n        dataset_path.parent.joinpath(\"_mobilised\").mkdir(parents=True, exist_ok=True)\n    _output_file = dataset_path.joinpath(\"Mobilise-D_dataset.zip\")\n\n    if not _output_file.exists():\n        # Set the URL to the dataset\n        _url = \"doi:10.5281/zenodo.7547125/Mobilise-D dataset_1-18-2023.zip\"\n\n        # Instantiate a downloader object\n        downloader = DOIDownloader(progressbar=progressbar)\n        downloader(url=_url, output_file=_output_file, pooch=None)\n\n    # Extract the dataset\n    with ZipFile(_output_file, \"r\") as zip_ref:\n        zip_ref.extractall(dataset_path)\n    return\n</code></pre>"},{"location":"datasets/mobilised/#datasets.mobilised.load_recording","title":"<code>load_recording(cohort='PFF', file_name='data.mat', dataset_path=Path(__file__).parent / '_mobilised', progressbar=True)</code>","text":"<p>Load a recording from the Mobilise-D dataset.</p> <p>If the dataset has not yet been downloaded, then is fetched from the Zenodo repository using the pooch package.</p> <p>Parameters:</p> Name Type Description Default <code>cohort</code> <code>Literal['PFF', 'PD', 'MS', 'HA', 'COPD', 'CHF']</code> <p>The cohort from which data should be loaded. Defaults to \"PFF\".</p> <code>'PFF'</code> <code>file_name</code> <code>str</code> <p>The filename of the data file. Defaults to \"data.mat\".</p> <code>'data.mat'</code> <code>dataset_path</code> <code>str | Path</code> <p>The path to the dataset. Defaults to Path(file).parent/\"_mobilised\".</p> <code>parent / '_mobilised'</code> <code>progressbar</code> <code>bool</code> <p>Whether to display a progressbar when fetching the data. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>KielMATRecording</code> <code>KielMATRecording</code> <p>An instance of the KielMATRecording dataclass containing the loaded data and channels.</p> Source code in <code>kielmat/datasets/mobilised.py</code> <pre><code>def load_recording(\n    cohort: Literal[\"PFF\", \"PD\", \"MS\", \"HA\", \"COPD\", \"CHF\"] = \"PFF\",\n    file_name: str = \"data.mat\",\n    dataset_path: str | Path = Path(__file__).parent / \"_mobilised\",\n    progressbar: bool = True,\n) -&gt; KielMATRecording:\n    \"\"\"Load a recording from the Mobilise-D dataset.\n\n    If the dataset has not yet been downloaded, then is fetched from the Zenodo repository using the pooch package.\n\n    Args:\n        cohort (Literal[\"PFF\", \"PD\", \"MS\", \"HA\", \"COPD\", \"CHF\"], optional): The cohort from which data should be loaded. Defaults to \"PFF\".\n        file_name (str, optional): The filename of the data file. Defaults to \"data.mat\".\n        dataset_path (str | Path, optional): The path to the dataset. Defaults to Path(__file__).parent/\"_mobilised\".\n        progressbar (bool, optional): Whether to display a progressbar when fetching the data. Defaults to True.\n\n    Returns:\n        KielMATRecording: An instance of the KielMATRecording dataclass containing the loaded data and channels.\n    \"\"\"\n\n    # Fetch the dataset if it does not exist\n    progressbar = False if not progressbar else progressbar\n    file_path = Path(dataset_path) / cohort / file_name\n    if not file_path.exists():\n        fetch_dataset(progressbar=progressbar, dataset_path=dataset_path)\n\n    # Load the data from the file path\n    data_dict = matlab_loader.load_matlab(file_path, top_level=\"data\")\n    data_dict = data_dict[\"TimeMeasure1\"][\n        \"Recording4\"\n    ]  # to simplify the data structure\n\n    # Get the data into a numpy ndarray\n    track_sys = \"SU\"\n    recording_data = {\"SU\": None}\n    channel_data = {\n        \"SU\": {\n            \"name\": [],\n            \"component\": [],\n            \"type\": [],\n            \"tracked_point\": [],\n            \"units\": [],\n            \"sampling_frequency\": [],\n        }\n    }\n    for tracked_point in data_dict[track_sys].keys():\n        for ch_type in data_dict[track_sys][tracked_point].keys():\n            if ch_type not in MAP_CHANNEL_TYPES.keys():\n                continue  # to next channel type\n\n            # Accumulate the data\n            if recording_data[track_sys] is None:\n                recording_data[track_sys] = data_dict[track_sys][tracked_point][ch_type]\n            else:\n                recording_data[track_sys] = np.column_stack(\n                    (recording_data[track_sys], data_dict[track_sys][tracked_point][ch_type])  # type: ignore\n                )  # type: ignore\n\n            # Accumulate the channel data\n            channel_data[track_sys][\"name\"] += [\n                f\"{tracked_point}_{MAP_CHANNEL_TYPES[ch_type]}_{ch_comp}\"\n                for ch_comp in MAP_CHANNEL_COMPONENTS[ch_type]\n            ]\n            channel_data[track_sys][\"type\"] += [\n                MAP_CHANNEL_TYPES[ch_type]\n                for _ in range(len(MAP_CHANNEL_COMPONENTS[ch_type]))\n            ]\n            channel_data[track_sys][\"component\"] += [\n                ch_comp for ch_comp in MAP_CHANNEL_COMPONENTS[ch_type]\n            ]\n            channel_data[track_sys][\"tracked_point\"] += [\n                tracked_point for ch_comp in range(len(MAP_CHANNEL_COMPONENTS[ch_type]))\n            ]\n            channel_data[track_sys][\"units\"] += [\n                MAP_CHANNEL_UNITS[ch_type]\n                for _ in range(len(MAP_CHANNEL_COMPONENTS[ch_type]))\n            ]\n            channel_data[track_sys][\"sampling_frequency\"] += [\n                data_dict[track_sys][tracked_point][\"Fs\"][ch_type]\n                for _ in range(len(MAP_CHANNEL_COMPONENTS[ch_type]))\n            ]\n\n    return KielMATRecording(\n        data={\n            track_sys: pd.DataFrame(\n                data=recording_data[track_sys], columns=channel_data[track_sys][\"name\"]\n            )\n        },\n        channels={track_sys: pd.DataFrame(channel_data[track_sys])},\n    )\n</code></pre>"},{"location":"examples/","title":"Overview","text":"<p>This section contains a series of examples designed to demonstrate key features and functionalities within the KielMAT toolbox. These examples will guide users through common workflows and illustrate how to apply different modules to motion analysis data.</p>"},{"location":"examples/#construct-your-dataclass","title":"Construct Your DataClass","text":"<p>The <code>DataClass</code> is the central data structure in KielMAT, which stores and organizes motion data along with associated events. The following examples guide you through the process of loading and structuring your data.</p>"},{"location":"examples/#example-1-load-data-into-kielmat","title":"Example 1: Load data into KielMAT","text":"<p>In this example, you will learn how to load motion data into <code>KielMAT</code>'s <code>DataClass</code>. This step is essential for processing any motion capture data, whether it's from IMUs, C3D files, or other data formats.</p>"},{"location":"examples/#example-2-load-datasets","title":"Example 2: Load datasets","text":"<p>This example demonstrates how to load datasets into <code>KielMAT</code>. You will learn how to import data from different sources, handle multiple datasets, and integrate them into a unified structure for analysis.</p>"},{"location":"examples/#example-3-events-in-dataclass","title":"Example 3: Events in DataClass","text":"<p>The <code>DataClass</code> not only stores motion data but also provides functionality to mark and organize events (such as gait sequences, initial contacts, or other notable movement occurrences). This example shows how to tag specific events within the <code>DataClass</code>, allowing you to analyze them in the context of the motion data.</p>"},{"location":"examples/#run-modules","title":"Run Modules","text":"<p>KielMAT includes several pre-built modules to analyze motion data for different tasks. The following examples demonstrate how to apply each module to extract meaningful information from your data.</p>"},{"location":"examples/#example-4-gait-sequence-detection","title":"Example 4: Gait Sequence Detection","text":"<p>This example introduces the Gait Sequence Detection module. This module identifies gait sequences using 3D accelerometer data from a lower back sensor.</p>"},{"location":"examples/#example-5-initial-contact-detection","title":"Example 5: Initial Contact Detection","text":"<p>This example introduces the Initial Contact Detection module. It identifies and characterizes initial contacts within each detected gait sequence using the gait sequence detection module.</p>"},{"location":"examples/#example-6-physical-activity-monitoring","title":"Example 6: Physical Activity Monitoring","text":"<p>This example introduces the Physical Activity Monitoring module. The example shows how the module is implemented on sample 3D acceleration data from an IMU sensor to monitor physical activity levels.</p>"},{"location":"examples/#example-7-postural-transition-detection","title":"Example 7: Postural Transition Detection","text":"<p>This example introduces the Postural Transition Detection module. It demonstrates how the module is implemented on sample 3D acceleration and 3D angular velocity data from a lower back IMU sensor to detect postural transitions, such as sit-to-stand or stand-to-sit.</p>"},{"location":"examples/#example-8-turn-detection","title":"Example 8: Turn Detection","text":"<p>This example introduces the Turn Detection module. It demonstrates how the module is implemented on sample 3D acceleration and 3D angular velocity data from a lower back IMU sensor to detect turns.</p>"},{"location":"examples/basic_01_load_Data_into_KielMAT/","title":"Tutorial: Load data into an <code>KielMATRecording</code> object","text":"<p>Author: Julius Welzel</p> <p>Last update: Fri 22 Mar 2024</p>"},{"location":"examples/basic_01_load_Data_into_KielMAT/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial:</p> <ul> <li>you can load data and channel information into an <code>KielMATRecording</code> object</li> <li>you can add Recording specific information to the <code>KielMATRecording</code> object</li> <li>you are educated about the relationship between a <code>KielMATRecording</code> object and the BIDS standard.</li> </ul>"},{"location":"examples/basic_01_load_Data_into_KielMAT/#imports","title":"Imports","text":"<p>We start by importing some Python libraries. You should be familiar with most of them, and we will not discuss them here.</p> <pre><code>import pandas as pd\n\nfrom kielmat.utils.kielmat_dataclass import KielMATRecording # Import the KielMATRecording class\nfrom kielmat.modules.gsd import ParaschivIonescuGaitSequenceDetection # Import the Gait Sequence Detection module\n</code></pre>"},{"location":"examples/basic_01_load_Data_into_KielMAT/#read-the-raw-data-and-metadata-into-python","title":"Read the raw data and metadata into python","text":"<p>Let us consider a single recording, a accelerometer located at the lower back. The sensor only provided the raw data in a csv file without any metadata. We only know the metadata from the sensor manual and from setting up the sensor. Depending on the sensor, the metadata might be stored in a separate file or in the same file as the raw data as a header.</p> <p>To import data from your own devices, check if KielMAT already has a reader for your device. If not, you can write your own reader and contribute it to the KielMAT project.</p> <pre><code># Set the url for the raw data on GH\nfile_url = 'https://raw.githubusercontent.com/neurogeriatricskiel/KielMAT/main/examples/data/ExampleAccelDataRaw.csv'\n\n# read the csv data from the url\nacc_data = pd.read_csv(file_url)\n\n# specifiy the sampling rate\nfs = 100 # Hz\n</code></pre> <p>We have loaded the data for one tracking systems, <code>LB_ACCEL</code>. We know we have three channels: <code>x</code>, <code>y</code>, and <code>z</code>. We also know that the data is sampled at 100 Hz.</p> <p>Let's check if the data is loaded correctly. We know we have a good 15 minutes of data with three channels representing acceleration.</p> <pre><code>n_channels = acc_data.shape[1]\nn_samples = acc_data.shape[0]\n\n# check how many minutes of data we have\nn_minutes = n_samples/fs/60\nprint(f\"Minutes of data: {n_minutes:.2f}\")\n</code></pre> <pre><code>Minutes of data: 18.33\n</code></pre> <p>Now we can load the data into an <code>KielMATRecording</code> object. For this we have to construct the channel information oursleves. We know that the data is sampled at 100 Hz and we have three channels: <code>x</code>, <code>y</code>, and <code>z</code>. For more information in the channel information, see the BIDS standard.</p> <p>CAVE: If the naming of the channels df is not following the BIDS standard, you will receive an error.</p> <pre><code># construct the channel information\n\ntracked_point = \"lowerBack\"\n\nn_channels = acc_data.shape[1] # second dimension of the data represents the number of channels\n\ncol_names = [\n    f\"{tracked_point}_{s}_{x}\"\n    for s in [\"ACCEL\"]\n    for x in [\"x\", \"y\", \"z\"]\n]\n\n# Make the channel dictionary following the BIDS naming conventions\nchannels_dict = {\n    \"name\": col_names,\n    \"component\": [\"x\", \"y\", \"z\"] * (n_channels // 3),\n    \"type\": [\"ACCEL\"] * (n_channels),\n    \"tracked_point\": [tracked_point] * n_channels,\n    \"units\": [\"m/s^2\"] * n_channels,\n    \"sampling_frequency\": [fs] * n_channels,\n}\n\nrecording =  KielMATRecording(\n    data={\"imu\": acc_data}, channels={\"lb_imu\": pd.DataFrame(channels_dict)}\n)\n</code></pre> <p>Ahh, perfect. Let's first inspect the channels in the dataclass.</p> <pre><code>recording.channels\n</code></pre> <pre><code>{'lb_imu':                 name component   type tracked_point  units  sampling_frequency\n 0  lowerBack_ACCEL_x         x  ACCEL     lowerBack  m/s^2                 100\n 1  lowerBack_ACCEL_y         y  ACCEL     lowerBack  m/s^2                 100\n 2  lowerBack_ACCEL_z         z  ACCEL     lowerBack  m/s^2                 100}\n</code></pre> <p>Now we can run some of our modules on this data. For example, we find gait sequences in our data.</p> <pre><code># Create an instance of the ParaschivIonescuGaitSequenceDetection class\ngsd = ParaschivIonescuGaitSequenceDetection()\n\n# Call the gait sequence detection using gsd.detect\ngsd = gsd.detect(\n    data=recording.data[\"imu\"], sampling_freq_Hz=fs, plot_results=True, dt_data=None\n)\n\n# Gait sequences are stored in gait_sequences_ attribute of gsd\ngait_sequences = gsd.gait_sequences_\n\n# Add events to the recording as a dictionary including tracking system and events\ngait_sequence_events = gait_sequences\nrecording.add_events(tracking_system=tracked_point, new_events=gait_sequence_events)\n\n# Show events and their corresponding information\nprint(recording.events)\n</code></pre> <pre><code>20 gait sequence(s) detected.\n</code></pre> <p></p> <pre><code>{'lowerBack':        onset  duration     event_type tracking_system\n0     90.175    10.400  gait sequence            None\n1    106.075     5.600  gait sequence            None\n2    121.750     4.250  gait sequence            None\n3    141.275     5.525  gait sequence            None\n4    195.025     7.100  gait sequence            None\n5    207.850    12.325  gait sequence            None\n6    256.925     5.900  gait sequence            None\n7    291.175    16.650  gait sequence            None\n8    319.450     7.100  gait sequence            None\n9    360.350    32.375  gait sequence            None\n10   408.125    58.650  gait sequence            None\n11   470.975     4.275  gait sequence            None\n12   479.150     3.600  gait sequence            None\n13   488.100     4.650  gait sequence            None\n14   495.875   327.350  gait sequence            None\n15   848.875    14.300  gait sequence            None\n16   867.025    47.975  gait sequence            None\n17   940.975    14.025  gait sequence            None\n18   967.575    38.800  gait sequence            None\n19  1047.625    12.625  gait sequence            None}\n</code></pre> <p>That seemed to work. Let's see how many gait sequences we found and how long they lasted on average.</p> <pre><code>n_gs = len(recording.events[\"lowerBack\"])\nmean_dur = recording.events[\"lowerBack\"][\"duration\"].mean()\nprint(f\"Mean duration of gait {n_gs:.0f} sequences: {mean_dur:.2f} seconds\")\n\n# also check the longest gait sequence\nmax_dur = recording.events[\"lowerBack\"][\"duration\"].max()\nmax_dur_onset = recording.events[\"lowerBack\"][\"onset\"][recording.events[\"lowerBack\"][\"duration\"].idxmax()]\nprint(f\"Longest gait sequence: {max_dur:.2f} seconds starting at about {max_dur_onset/60:.2f} minutes into the recording.\")\n</code></pre> <pre><code>Mean duration of gait 20 sequences: 31.67 seconds\nLongest gait sequence: 327.35 seconds starting at about 8.26 minutes into the recording.\n</code></pre> <p>That's it for this tutorial. You have learned how to load data and channel information into an <code>KielMATRecording</code> object and how to add Recording specific information to the <code>KielMATRecording</code> object. </p>"},{"location":"examples/basic_02_load_dataset/","title":"Tutorial: load datasets","text":"<p>Author: Robbin Romijnders Last update: Tue 16 Jan 2024</p>"},{"location":"examples/basic_02_load_dataset/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial:</p> <ul> <li>you can load data from a recording that belongs to one of the available datasets,</li> <li>you know which attributes are available for an instance of the <code>KielMATRecording</code></li> <li>you can do some basic selecting and slicing of data</li> </ul>"},{"location":"examples/basic_02_load_dataset/#imports","title":"Imports","text":"<p>We start by importing some Python libraries. You should be familiar with most of them, and we will not discuss them here.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom pathlib import Path\nfrom kielmat.datasets import mobilised\n</code></pre>"},{"location":"examples/basic_02_load_dataset/#import-data","title":"Import data","text":"<p>Let us consider a single recording, namely of the randomly selected subject <code>sub-3011</code> from the <code>Mobilise-D</code> dataset, and load the data. For that we use the <code>load_recording()</code> function that is available in the <code>kielmat.datasets.mobilised</code> module.</p> <pre><code># load the data\nrecording = mobilised.load_recording()\n</code></pre> <p>We have loaded the data for two tracking systems, <code>SU</code> and <code>SU_INDIP</code>, and we have specified three tracked points. The data is assigned to the variable <code>recording</code>, so let us take a look at what we have got.</p> <pre><code>recording.__dict__\n</code></pre> <pre><code>{'data': {'SU':         LowerBack_ACCEL_x  LowerBack_ACCEL_y  LowerBack_ACCEL_z  \\\n  0                0.933334           0.084820          -0.302665   \n  1                0.932675           0.084844          -0.300591   \n  2                0.932350           0.082886          -0.310576   \n  3                0.929716           0.081786          -0.303551   \n  4                0.932825           0.077879          -0.308859   \n  ...                   ...                ...                ...   \n  693471          -0.192553          -0.016052          -0.984290   \n  693472          -0.189575          -0.016449          -0.988130   \n  693473          -0.191176          -0.017954          -0.983820   \n  693474          -0.189691          -0.014539          -0.986376   \n  693475          -0.192993          -0.015306          -0.989452\n\n          LowerBack_GYRO_x  LowerBack_GYRO_y  LowerBack_GYRO_z  \\\n  0               5.600066          1.120697          0.489152   \n  1               5.440734          1.401663          0.279477   \n  2               5.196312          1.168802          0.435765   \n  3               5.553083          1.116346          0.383447   \n  4               5.437505          0.892803         -0.150115   \n  ...                  ...               ...               ...   \n  693471         -0.225874          0.832856          0.704711   \n  693472         -0.393438          0.598116          0.522755   \n  693473         -0.430749          0.417541          0.282336   \n  693474         -0.279277          0.559122          0.418693   \n  693475         -0.563741          0.478618          0.411295\n\n          LowerBack_MAGN_x  LowerBack_MAGN_y  LowerBack_MAGN_z  \\\n  0             -93.972011        -25.023998         44.675028   \n  1             -93.958012        -25.016007         44.610055   \n  2             -93.946010        -25.000014         44.520078   \n  3             -93.938007        -24.980018         44.411097   \n  4             -93.935003        -24.957021         44.287113   \n  ...                  ...               ...               ...   \n  693471        -50.718928        -36.997006         34.111960   \n  693472        -50.649929        -37.003005         34.072972   \n  693473        -50.579936        -37.008003         34.044986   \n  693474        -50.515946        -37.011000         34.031004   \n  693475        -50.460961        -37.010996         34.035025\n\n          LowerBack_BARO_n/a  \n  0               990.394600  \n  1               990.395100  \n  2               990.395600  \n  3               990.396199  \n  4               990.396700  \n  ...                    ...  \n  693471          990.204600  \n  693472          990.204900  \n  693473          990.205200  \n  693474          990.205500  \n  693475          990.205800\n\n  [693476 rows x 10 columns]},\n 'channels': {'SU':                  name component   type tracked_point  units  \\\n  0   LowerBack_ACCEL_x         x  ACCEL     LowerBack      g   \n  1   LowerBack_ACCEL_y         y  ACCEL     LowerBack      g   \n  2   LowerBack_ACCEL_z         z  ACCEL     LowerBack      g   \n  3    LowerBack_GYRO_x         x   GYRO     LowerBack  deg/s   \n  4    LowerBack_GYRO_y         y   GYRO     LowerBack  deg/s   \n  5    LowerBack_GYRO_z         z   GYRO     LowerBack  deg/s   \n  6    LowerBack_MAGN_x         x   MAGN     LowerBack     \u00b5T   \n  7    LowerBack_MAGN_y         y   MAGN     LowerBack     \u00b5T   \n  8    LowerBack_MAGN_z         z   MAGN     LowerBack     \u00b5T   \n  9  LowerBack_BARO_n/a       n/a   BARO     LowerBack    hPa\n\n     sampling_frequency  \n  0               100.0  \n  1               100.0  \n  2               100.0  \n  3               100.0  \n  4               100.0  \n  5               100.0  \n  6               100.0  \n  7               100.0  \n  8               100.0  \n  9               100.0  },\n 'info': None,\n 'events': None,\n 'events_info': None}\n</code></pre> <p>That is a whole lot of output, so let us take a look at the attributes of instance one by one. First, print a list of all available attributes.</p> <pre><code>print(recording.__dict__.keys())\n</code></pre> <pre><code>dict_keys(['data', 'channels', 'info', 'events', 'events_info'])\n</code></pre> <p>The contents of any individual attribute can be accessed in two ways, namely via the <code>__dict__</code> or with <code>dot</code> indexing.</p> <pre><code>print(recording.data)  # print(recording.__dict__[\"data\"])\n</code></pre> <pre><code>{'SU':         LowerBack_ACCEL_x  LowerBack_ACCEL_y  LowerBack_ACCEL_z  \\\n0                0.933334           0.084820          -0.302665   \n1                0.932675           0.084844          -0.300591   \n2                0.932350           0.082886          -0.310576   \n3                0.929716           0.081786          -0.303551   \n4                0.932825           0.077879          -0.308859   \n...                   ...                ...                ...   \n693471          -0.192553          -0.016052          -0.984290   \n693472          -0.189575          -0.016449          -0.988130   \n693473          -0.191176          -0.017954          -0.983820   \n693474          -0.189691          -0.014539          -0.986376   \n693475          -0.192993          -0.015306          -0.989452\n\n        LowerBack_GYRO_x  LowerBack_GYRO_y  LowerBack_GYRO_z  \\\n0               5.600066          1.120697          0.489152   \n1               5.440734          1.401663          0.279477   \n2               5.196312          1.168802          0.435765   \n3               5.553083          1.116346          0.383447   \n4               5.437505          0.892803         -0.150115   \n...                  ...               ...               ...   \n693471         -0.225874          0.832856          0.704711   \n693472         -0.393438          0.598116          0.522755   \n693473         -0.430749          0.417541          0.282336   \n693474         -0.279277          0.559122          0.418693   \n693475         -0.563741          0.478618          0.411295\n\n        LowerBack_MAGN_x  LowerBack_MAGN_y  LowerBack_MAGN_z  \\\n0             -93.972011        -25.023998         44.675028   \n1             -93.958012        -25.016007         44.610055   \n2             -93.946010        -25.000014         44.520078   \n3             -93.938007        -24.980018         44.411097   \n4             -93.935003        -24.957021         44.287113   \n...                  ...               ...               ...   \n693471        -50.718928        -36.997006         34.111960   \n693472        -50.649929        -37.003005         34.072972   \n693473        -50.579936        -37.008003         34.044986   \n693474        -50.515946        -37.011000         34.031004   \n693475        -50.460961        -37.010996         34.035025\n\n        LowerBack_BARO_n/a  \n0               990.394600  \n1               990.395100  \n2               990.395600  \n3               990.396199  \n4               990.396700  \n...                    ...  \n693471          990.204600  \n693472          990.204900  \n693473          990.205200  \n693474          990.205500  \n693475          990.205800\n\n[693476 rows x 10 columns]}\n</code></pre> <p>We see that that <code>data</code> attribute is in the form of a Python <code>dict</code>, where the keys correspond to the tracking systems that we have requested when calling the <code>load_recording()</code> function. KielMAT is setup so that the keys of the <code>channels</code> attribute match with these keys, so that the channel descriptions are availbale per tracking system.</p> <pre><code>print(f\"We have the following keys in recording.data: {recording.data.keys()}\")\n\nprint(f\"We have the same keys in recordings.channels: {recording.channels.keys()}\")\n</code></pre> <pre><code>We have the following keys in recording.data: dict_keys(['SU'])\nWe have the same keys in recordings.channels: dict_keys(['SU'])\n</code></pre>"},{"location":"examples/basic_03_events/","title":"Tutorial: Events in data classes","text":"<p>Author: Masoud Abedinifar &amp; Julius Welzel</p> <p>Last update: Thu 14 Mar 2024</p>"},{"location":"examples/basic_03_events/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial:</p> <ul> <li>Load data from a recording that belongs to one of the available datasets.</li> <li>Store events from algorithms in the datclass per recording file.</li> <li>Export events to BIDS format.</li> </ul>"},{"location":"examples/basic_03_events/#import-libraries","title":"Import libraries","text":"<p>The necessary libraries such as numpy, matplotlib.pyplot, dataset (mobilised), Paraschiv-Ionescu gait sequence detection, and Paraschiv-Ionescu initial contact detection algorithms are imported from their corresponding modules. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the 'kielmat' library and its dependencies if you haven't already.</p> <pre><code>from kielmat.datasets import mobilised\nfrom kielmat.modules.gsd import ParaschivIonescuGaitSequenceDetection\n</code></pre> <p>First load the data and put in the desired dataclasses.</p> <pre><code># load the data from mobilised dataset\nrecording = mobilised.load_recording()\n\n# specify which tracking system you want to use\ntracking_sys = 'SU'\n</code></pre> <pre><code># Load lower back acceleration data\nacceleration_data = recording.data[tracking_sys][\n    [\"LowerBack_ACCEL_x\", \"LowerBack_ACCEL_y\", \"LowerBack_ACCEL_z\"]\n]\n</code></pre> <pre><code># Get the corresponding sampling frequency directly from the recording\nsampling_frequency = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n][\"sampling_frequency\"].values[0]\nprint(f\"Sampling frequency: {sampling_frequency} Hz\")\n</code></pre> <pre><code>Sampling frequency: 100.0 Hz\n</code></pre> <p>The events are put into a pandas DataFrame, and follow the conventions outlined in the BIDS documentation (i.e. https://bids-specification.readthedocs.io/en/stable/modality-specific-files/task-events.html).</p>"},{"location":"examples/basic_03_events/#gait-sequence-events-in-dataclass","title":"Gait sequence events in dataclass","text":"<pre><code># Create an instance of the ParaschivIonescuGaitSequenceDetection class\ngsd = ParaschivIonescuGaitSequenceDetection()\n\n# Call the gait sequence detection using gsd.detect to detect gait sequences\ngsd = gsd.detect(\n    data=acceleration_data, sampling_freq_Hz=sampling_frequency, plot_results=False\n)\n</code></pre> <pre><code>36 gait sequence(s) detected.\n</code></pre> <pre><code># Add events to the recording as a dictionary including tracking system and events\ngait_sequence_events = gsd.gait_sequences_\nrecording.add_events(tracking_system=tracking_sys, new_events=gait_sequence_events)\nprint(f\"events: {recording.events}\")\n</code></pre> <pre><code>events: {'SU':        onset  duration     event_type tracking_system\n0     22.650    17.075  gait sequence            None\n1     49.150     7.475  gait sequence            None\n2     97.025   120.400  gait sequence            None\n3    229.550     9.225  gait sequence            None\n4    247.900    29.075  gait sequence            None\n5    296.225   189.600  gait sequence            None\n6    490.300    25.575  gait sequence            None\n7    562.925    15.075  gait sequence            None\n8    581.900    18.875  gait sequence            None\n9    607.050    56.600  gait sequence            None\n10   667.325   101.900  gait sequence            None\n11   784.500    42.775  gait sequence            None\n12   835.675   174.675  gait sequence            None\n13  1034.900    42.050  gait sequence            None\n14  1103.075    39.475  gait sequence            None\n15  1153.750    13.125  gait sequence            None\n16  1184.900     5.775  gait sequence            None\n17  1219.175    21.225  gait sequence            None\n18  1244.450    40.675  gait sequence            None\n19  1480.025     5.250  gait sequence            None\n20  1500.625    47.275  gait sequence            None\n21  1582.600    13.375  gait sequence            None\n22  1605.600    10.700  gait sequence            None\n23  1624.700    36.275  gait sequence            None\n24  1674.075     6.700  gait sequence            None\n25  5301.850     9.525  gait sequence            None\n26  5412.575    10.500  gait sequence            None\n27  5481.150    12.550  gait sequence            None\n28  5498.500     6.500  gait sequence            None\n29  5528.475    23.200  gait sequence            None\n30  5593.175    39.650  gait sequence            None\n31  5676.900    13.200  gait sequence            None\n32  5723.425    32.125  gait sequence            None\n33  5770.050    13.575  gait sequence            None\n34  5796.100     6.700  gait sequence            None\n35  6762.300   125.400  gait sequence            None}\n</code></pre>"},{"location":"examples/basic_03_events/#store-events-to-eventstsv-file-following-the-bids-convention","title":"Store events to events.tsv file following the BIDS convention","text":"<p>Add some information about the recording first which is necessary for the BIDS file name convention. KielMAT has some implemented check on the information to make sure that the file name is in the correct format.</p> <pre><code>recording.add_info(\"Subject\", \"CHF01\")\nrecording.add_info(\"Task\", \"walking_outside\")\n</code></pre> <pre><code>Warning: The value of the key 'Subject' should be lower case. Converted to lower case.\nWarning: The value of the key 'Task' should be lower case. Converted to lower case.\nWarning: The value of the key 'Task' should not contain underscore or space. Removed underscore and space.\n</code></pre> <p>Please notice that we a not to strict with the user. We just give a warning if the file name is not in BIDS like format. However, the user can still continue with the process. But you better believe that the BIDS police will come and get you if you don't follow the rules.</p> <p>Now as we have the events in the dataclass, we can export them to a BIDS compatible events file.</p> <pre><code>recording.export_events(file_path = r'../examples/data', file_name='gait_sequence.csv')\n</code></pre>"},{"location":"examples/modules_04_gsd/","title":"Tutorial: Gait Sequence Detection","text":"<p>Author: Masoud Abedinifar</p> <p>Last update: Tue 01 Oct 2024</p>"},{"location":"examples/modules_04_gsd/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial:</p> <ul> <li>You can load data from a recording that belongs to one of the available datasets,</li> <li>Apply the Paraschiv-Ionescu gait sequence detection algorithm to accelerometer data.  </li> <li>Visualize the results of gait sequence detection.  </li> <li>Interpret the detected gait sequences for further analysis.</li> </ul>"},{"location":"examples/modules_04_gsd/#paraschiv-gait-sequence-detection","title":"Paraschiv Gait Sequence Detection","text":"<p>This example can be referenced by citing the package.</p> <p>The example illustrates how the Paraschiv-Ionescu gait sequence detection algorithm is used to detect gait sequences using body acceleration recorded with a triaxial accelerometer worn or fixed on the lower back. The gait sequence detection algorithm is implemented using <code>kielmat.modules.gsd._paraschiv</code>. This algorithm is based on the research of Paraschiv-Ionescu et al [<code>1</code>-<code>2</code>].</p> <p>The algorithm detects gait sequences based on identified steps. It starts by loading the accelerometer data, which includes three columns corresponding to the acceleration signals across the x, y, and z axes, along with the sampling frequency of the data. To simplify the analysis, the norm of acceleration across the x, y, and z axes is computed. Next, the signal is resampled at a 40 Hz sampling frequency using interpolation. Smoothing is then applied through a Savitzky-Golay filter and a Finite Impulse Response (FIR) low-pass filter to remove noise and drifts from the signal. The continuous wavelet transform is applied to capture gait-related features, followed by additional smoothing using successive Gaussian-weighted filters. The processed data is then analyzed to detect gait sequences.</p> <p>The algorithm continues by identifying the envelope of the processed acceleration signal. Active periods of the signal are identified using the Hilbert envelope. The statistical distribution of the amplitude of the peaks in these active periods is used to derive an adaptive threshold. In case the Hilbert envelope algorithm fails to detect active periods, a fixed threshold value (0.15 g) is used for peak detection in the signal. Mid-swing peaks are detected based on this threshold. Pulse trains in the local maximum and minimum of the peaks are identified, with those having fewer than four steps filtered out. The intersection of pulse trains from local maximum and minimum peaks is detected as walking periods. These periods are then organized and grouped to update the start and end times of detected walking bouts.</p> <p>Next, the algorithm takes the last steps to detect walking bouts in the signal. For this purpose, walking bouts with five or more steps are detected, and their start and end times are added to the list. Walking labels are generated as an array of zeros, and the intervals corresponding to the walking bouts are labeled as 1. Groups of consecutive zeros in the walking labels are identified, and if breaks between walking bouts are less than three seconds, they are merged. The output is then constructed as a DataFrame containing gait sequence information in BIDS format. If gait sequences are found, the output is printed; otherwise, a message indicating that no gait sequences are detected is displayed.</p>"},{"location":"examples/modules_04_gsd/#references","title":"References","text":"<p>[<code>1</code>] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer: validity for children with cerebral palsy in daily life-like conditions. Journal of NeuroEngineering and Rehabilitation, 16(1), 24. https://doi.org/10.1186/s12984-019-0494-z</p> <p>[<code>2</code>] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using a single trunk IMU: methodological challenges for impaired gait patterns. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. https://doi.org/10.1109/EMBC44109.2020.9176281</p>"},{"location":"examples/modules_04_gsd/#import-libraries","title":"Import libraries","text":"<p>The necessary libraries such as numpy, matplotlib.pyplot, dataset, and Paraschiv-Ionescu gait sequence detection algorithms are imported. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the 'kielmat' library and its dependencies if you haven't already.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom pathlib import Path\nfrom kielmat.datasets import mobilised\nfrom kielmat.modules.gsd import ParaschivIonescuGaitSequenceDetection\nfrom kielmat.config import cfg_colors\n</code></pre>"},{"location":"examples/modules_04_gsd/#data-preparation","title":"Data Preparation","text":"<p>To implement the Paraschiv-Ionescu gait sequence detection algorithm, we load example data from a publicly available on the Zenodo repository . </p> <p>The participant was assessed for 2.5 hours in the real-world while doing different daily life activities and also was asked to perform specific tasks such as outdoor walking, walking up and down a slope and stairs and moving from one room to another [<code>3</code>].</p>"},{"location":"examples/modules_04_gsd/#refertences","title":"Refertences","text":"<p>.. [<code>3</code>] Mazz\u00e0, Claudia, et al. \"Technical validation of real-world monitoring of gait: a multicentric observational study.\" BMJ open 11.12 (2021): e050785. http://dx.doi.org/10.1136/bmjopen-2021-050785</p> <pre><code># Set the dataset path\ndataset_path = Path(os.getcwd()) / \"_mobilised\"\n\n# Fetch and load the dataset\nmobilised.fetch_dataset(dataset_path=dataset_path)\n\n# In this example, we use \"SU\" as tracking_system and \"LowerBack\" as tracked points.\ntracking_sys = \"SU\"\ntracked_points = {tracking_sys: [\"LowerBack\"]}\n\n# The 'mobilised.load_recording' function is used to load the data from the specified file_path\nrecording = mobilised.load_recording(\n    cohort=\"PFF\",  # Choose the cohort\n    file_name=\"data.mat\", \n    dataset_path=dataset_path)\n\n# Load lower back acceleration data\naccel_data = recording.data[tracking_sys][\n    [\"LowerBack_ACCEL_x\", \"LowerBack_ACCEL_y\", \"LowerBack_ACCEL_z\"]\n]\n\n# Get the corresponding sampling frequency directly from the recording\nsampling_frequency = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n][\"sampling_frequency\"].values[0]\n</code></pre>"},{"location":"examples/modules_04_gsd/#data-units-and-conversion-to-si-units","title":"Data Units and Conversion to SI Units","text":"<p>All input data provided to the modules in this toolbox should adhere to SI units to maintain consistency and accuracy across analyses. This ensures compatibility with the underlying algorithms, which are designed to work with standard metric measurements.</p> <p>If any data is provided in non-SI units (e.g., acceleration in g instead of m/s\u00b2), it is needed that the data to be converted into the appropriate SI units before using it as input to the toolbox. Failure to convert non-SI units may lead to incorrect results or misinterpretation of the output.</p> <p>For instance:</p> <ul> <li>Acceleration: Convert from g to m/s\u00b2.</li> </ul> <pre><code># Get the corresponding unit of the acceleration data\naccel_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n][\"units\"].values[0]\n\n# Check unit of acceleration data\nif accel_unit in [\"m/s^2\"]:\n    pass  # No conversion needed\nelif accel_unit in [\"g\", \"G\"]:\n    # Convert acceleration data from \"g\" to \"m/s^2\"\n    accel_data *= 9.81\n    # Update unit of acceleration\n    accel_unit = [\"m/s^2\"]\n</code></pre>"},{"location":"examples/modules_04_gsd/#visualisation-of-the-data","title":"Visualisation of the Data","text":"<p>The raw acceleration data including components of x, y and z axis is represented.</p> <pre><code># Calculate the time values in minutes\n# The 'time_in_minute' array represents time values in minutes, computed based on the length of 'acceleration_data' and 'sampling_frequency'.\ntime_in_minute = np.arange(len(acceleration_data)) / (60 * sampling_frequency)\n\n# Create a figure with a specified size\nplt.figure(figsize=(22, 14))\n\n# Get colors for raw\ncolors = cfg_colors[\"raw\"]\n\n# A loop is used to plot data for each accelerometer axis, applying different colors from the color map.\nfor i in range(3):\n    plt.plot(\n        time_in_minute,\n        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n        color=colors[i],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\n\n# Add labels and legends\nplt.xlabel(\"Time (minute)\", fontsize=20)\nplt.ylabel(f\"Acceleration (m/s$^{2}$)\", fontsize=20)\nplt.legend(fontsize=18)\n\n# Add a title with a specified font size\nplt.title(\n    \"Accelerometer data from lower-back IMU sensor\",\n    fontsize=30,\n)\n\n# Customize tick font sizes\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\n# Display a grid for reference\nplt.grid(visible=None, which=\"both\", axis=\"both\")\n\n# Show the plot\nplt.show()\n</code></pre> <p></p> <p>Let's zoom in on specific time periods in the data, particularly the first 45 seconds, where clear blinks are evident.</p> <pre><code># Calculate the time values based on the length of the data\nnum_samples = len(acceleration_data)\ntime_seconds = np.arange(num_samples) / sampling_frequency\n\n# Create a figure with the specified size\nplt.figure(figsize=(22, 14))\n\n# Plot acceleration data for each axis with time on the x-axis\nfor i in range(3):\n    plt.plot(\n        time_seconds,\n        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n        color=colors[i],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\n\n# Add labels and legends\nplt.xlabel(\"Time (s)\", fontsize=20)\nplt.ylabel(\"Acceleration (m/s$^{2}$)\", fontsize=20)\nplt.legend(fontsize=18)\n\n# Add a title\nplt.title(\n    \"Accelerometer data from lower-back IMU sensor\",\n    fontsize=30,\n)\n\n# Customize font sizes\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\n# Set x-axis and y-axis limits for a specific duration (in seconds) and acceleration range\nplt.xlim(0, 10)\n\n# Display a grid for reference\nplt.grid(visible=None, which=\"both\", axis=\"both\")\n\n# Show the plot\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/modules_04_gsd/#applying-paraschiv-ionescu-gait-sequence-detection-algorithm","title":"Applying Paraschiv-Ionescu Gait Sequence Detection Algorithm","text":"<p>Now, we are running Paraschiv-Ionescu gait sequence detection algorithm from gsd module <code>KielMAT.kielmat.modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection</code> to detect gait sequences.</p> <p>In order to apply gait sequence detection algorithm, an instance of the ParaschivIonescuGaitSequenceDetection class is created using the constructor, <code>ParaschivIonescuGaitSequenceDetection()</code>. The <code>gsd</code> variable holds the instance, allowing us to access its methods. The inputs of the algorithm are as follows:</p> <ul> <li>Input Data: <code>accel_data</code> consist of accelerometer data (N, 3) for the x, y, and z axes in pandas Dataframe format. The data should be in SI unit as m/s\u00b2.</li> <li>Sampling Frequency: <code>sampling_freq_Hz</code> is the sampling frequency of the data, defined in Hz, with a default value of 100 Hz.</li> <li>Plot Results: <code>plot_results</code>, if set to True, generates a plot showing the detected gait sequences on the data. The default is False. The onset is represented with the vertical green line and the grey area represents the duration of gait sequence detected by the algorithm.</li> </ul> <pre><code># Create an instance of the ParaschivIonescuGaitSequenceDetection class\ngsd = ParaschivIonescuGaitSequenceDetection()\n\n# Call the gait sequence detection using gsd.detect\ngsd = gsd.detect(\n    accel_data=acceleration_data, sampling_freq_Hz=sampling_frequency, plot_results=True, dt_data=None\n)\n\n# Gait sequences are stored in gait_sequences_ attribute of gsd\ngait_sequences = gsd.gait_sequences_\n\n# Add events to the recording as a dictionary including tracking system and events\ngait_sequence_events = gait_sequences\nrecording.add_events(tracking_system=tracking_sys, new_events=gait_sequence_events)\n\n# Show events and their corresponding information\nprint(recording.events)\n</code></pre> <pre><code>36 gait sequence(s) detected.\n</code></pre> <p></p> <pre><code>{'SU':        \n    onset  duration     event_type  tracking_system\n0     22.650    17.075  gait sequence            None\n1     49.150     7.475  gait sequence            None\n2     97.025   120.400  gait sequence            None\n3    229.550     9.225  gait sequence            None\n4    247.900    29.075  gait sequence            None\n5    296.225   189.600  gait sequence            None\n6    490.300    25.575  gait sequence            None\n7    562.925    15.075  gait sequence            None\n8    581.900    18.875  gait sequence            None\n9    607.050    56.600  gait sequence            None\n10   667.325   101.900  gait sequence            None\n11   784.500    42.775  gait sequence            None\n12   835.675   174.675  gait sequence            None\n13  1034.900    42.050  gait sequence            None\n14  1103.075    39.475  gait sequence            None\n15  1153.750    13.125  gait sequence            None\n16  1184.900     5.775  gait sequence            None\n17  1219.175    21.225  gait sequence            None\n18  1244.450    40.675  gait sequence            None\n19  1480.025     5.250  gait sequence            None\n20  1500.625    47.275  gait sequence            None\n21  1582.600    13.375  gait sequence            None\n22  1605.600    10.700  gait sequence            None\n23  1624.700    36.275  gait sequence            None\n24  1674.075     6.700  gait sequence            None\n25  5301.850     9.525  gait sequence            None\n26  5412.575    10.500  gait sequence            None\n27  5481.150    12.550  gait sequence            None\n28  5498.500     6.500  gait sequence            None\n29  5528.475    23.200  gait sequence            None\n30  5593.175    39.650  gait sequence            None\n31  5676.900    13.200  gait sequence            None\n32  5723.425    32.125  gait sequence            None\n33  5770.050    13.575  gait sequence            None\n34  5796.100     6.700  gait sequence            None\n35  6762.300   125.400  gait sequence            None}\n</code></pre>"},{"location":"examples/modules_04_gsd/#detailed-visualization-of-the-detected-gait-sequences","title":"Detailed Visualization of the Detected Gait Sequences","text":"<p>In the following, the raw data of the lower back sensor is plotted with the detected events. The events are plotted as vertical lines. The events are: - Gait onset: Start of the gait sequence - Gait duration: Duration of the gait sequence</p> <p>The onset is represented with the vertical green line and the grey area represents the duration of gait sequence detected by the algorithm.</p> <pre><code># Access and print first detected gait sequence\nfirst_gait_sequence = recording.events[tracking_sys].iloc[0]\nprint(\"First gait sequence:\\n\", first_gait_sequence)\n\n# Plot the raw data from the lower back\nfig, ax = plt.subplots(figsize=(22, 14))\n\n# Plot raw acceleration data\nfor i in range(3):\n    ax.plot(\n        time_seconds,\n        acceleration_data[f\"LowerBack_ACCEL_{chr(120 + i)}\"],\n        color=colors[i],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\n\n# Plot the first element of gait sequences\nplt.axvline(first_gait_sequence[\"onset\"], color=\"g\", label=\"Gait onset\")\nax.axvspan(\n    first_gait_sequence[\"onset\"],\n    first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"],\n    alpha=0.2,\n    color=\"gray\",\n    label=\"Gait duration\",\n)\n\n# Customize plot\nstart_limit = first_gait_sequence[\"onset\"] - 2\nend_limit = first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"] + 2\nax.set_xlim(start_limit, end_limit)\nax.set_ylim(-1, 1.5)\nax.set_xlabel(\"Time (s)\", fontsize=20)\nax.set_ylabel(\"Acceleration (m/s$^{2}$)\", fontsize=20)\nax.legend(loc=\"upper right\", fontsize=20)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nplt.show()\n</code></pre> <pre><code>First gait sequence:\n onset                      22.65\nduration                  17.075\nevent_type         gait sequence\ntracking_system             None\nName: 0, dtype: object\n</code></pre> <p></p>"},{"location":"examples/modules_05_icd/","title":"Tutorial: Initial Contact Detection","text":"<p>Author: Masoud Abedinifar</p> <p>Last update: Tue 01 Oct 2024</p>"},{"location":"examples/modules_05_icd/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial, you will be able to: </p> <ul> <li>You can load data from a recording that belongs to one of the available datasets,</li> <li>Apply the Paraschiv-Ionescu initial contact detection algorithm to accelerometer data.  </li> <li>Visualize the results of initial contact detection.  </li> <li>Interpret the detected initial contacts for further analysis.</li> </ul>"},{"location":"examples/modules_05_icd/#paraschiv-initial-contact-detection","title":"Paraschiv Initial Contact Detection","text":"<p>This example can be referenced by citing the package.</p> <p>The example illustrates how the Paraschiv initial contact detection algorithm is used to detect initial contacts using body acceleration recorded with a triaxial accelerometer worn or fixed on the lower back. The initial contact detection algorithm is implemented in the main module <code>kielmat.modules.icd._paraschiv</code>. This algorithm is based on the research of Paraschiv-Ionescu et al [<code>1</code>-<code>2</code>].</p> <p>The algorithm takes accelerometer data as input, specifically the vertical acceleration component, and processes each specified gait sequence independently. The algorithm requires the start and duration of each gait sequence, in the format provided by the Paraschiv-Ionescu gait sequence detection algorithm (<code>kielmat.modules.gsd._paraschiv</code>). The sampling frequency of the accelerometer data is also required as another input. Detected gait sequence information is provided as a DataFrame, which consists of the onset and duration of the gait sequences. For each gait sequence, the algorithm applies the Signal Decomposition algorithm for initial contacts. The algorithm handles multiple gait sequences and ensures uniform output by padding the initial contacts lists with NaN values to match the length of the sequence with the maximum number of initial contacts detected among all sequences. Finally, initial contacts information is provided as a DataFrame with columns <code>onset</code>, <code>event_type</code>, <code>tracking_systems</code>, and <code>tracked_points</code>.</p>"},{"location":"examples/modules_05_icd/#references","title":"References","text":"<p>[<code>1</code>] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer: validity for children with cerebral palsy in daily life-like conditions. Journal of NeuroEngineering and Rehabilitation, 16(1), 24. https://doi.org/10.1186/s12984-019-0494-z</p> <p>[<code>2</code>] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using a single trunk IMU: methodological challenges for impaired gait patterns. Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. https://doi.org/10.1109/EMBC44109.2020.9176281</p>"},{"location":"examples/modules_05_icd/#import-libraries","title":"Import Libraries","text":"<p>The necessary libraries such as numpy, matplotlib.pyplot, dataset (mobilised), Paraschiv-Ionescu gait sequence detection, and Paraschiv-Ionescu initial contact detection algorithms are imported from their corresponding modules. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the <code>kielmat</code> library and its dependencies if you haven't already.</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nimport os\nfrom pathlib import Path\nfrom kielmat.datasets import keepcontrol\nfrom kielmat.modules.gsd import ParaschivIonescuGaitSequenceDetection\nfrom kielmat.modules.icd import ParaschivIonescuInitialContactDetection\nfrom kielmat.config import cfg_colors\n</code></pre>"},{"location":"examples/modules_05_icd/#data-preparation","title":"Data Preparation","text":"<p>To implement the Paraschiv-Ionescu initial contact algorithm, we load example data from a KeepControl, which is publicly available on OpenNeuro. </p> <p>The participant was walking at a slow speed for a distance of 20m.</p> <pre><code># Dataset path\ndataset_path = Path(os.getcwd()) / \"_keepcontrol\"\n\n# Fetch the dataset\nkeepcontrol.fetch_dataset(dataset_path)\n</code></pre> <pre><code># In this example, we use \"imu\" as tracking_system and \"pelvis\" as tracked points.\ntracking_sys = \"imu\"\ntracked_points = {tracking_sys: [\"pelvis\"]}\n\n# The 'keepcontrol.load_recording' function is used to load the data from the specified file_path\nrecording = keepcontrol.load_recording(\n    dataset_path=dataset_path,\n    id=\"pp002\",\n    task=\"walkSlow\",\n    tracking_systems=[tracking_sys], \n    tracked_points=tracked_points\n)\n\n# Load lower back acceleration data\naccel_data = recording.data[tracking_sys][\n    [\"pelvis_ACCEL_x\", \"pelvis_ACCEL_y\", \"pelvis_ACCEL_z\"]\n]\n\n# Get the corresponding sampling frequency directly from the recording\nsampling_frequency = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"pelvis_ACCEL_x\"\n][\"sampling_frequency\"].values[0]\n</code></pre>"},{"location":"examples/modules_05_icd/#data-units-and-conversion-to-si-units","title":"Data Units and Conversion to SI Units","text":"<p>All input data provided to the modules in this toolbox should adhere to SI units to maintain consistency and accuracy across analyses. This ensures compatibility with the underlying algorithms, which are designed to work with standard metric measurements.</p> <p>If any data is provided in non-SI units (e.g., acceleration in g instead of m/s\u00b2), it is needed that the data to be converted into the appropriate SI units before using it as input to the toolbox. Failure to convert non-SI units may lead to incorrect results or misinterpretation of the output.</p> <p>For instance:</p> <ul> <li>Acceleration: Convert from g to m/s\u00b2.</li> </ul> <pre><code># Get the corresponding unit of the acceleration data\naccel_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"].str.contains(\"ACCEL\", case=False)\n][\"units\"].iloc[0]\n\n# Check unit of acceleration data\nif accel_unit in [\"m/s^2\"]:\n    pass  # No conversion needed\nelif accel_unit in [\"g\", \"G\"]:\n    # Convert acceleration data from \"g\" to \"m/s^2\"\n    accel_data *= 9.81\n    # Update unit of acceleration\n    accel_unit = [\"m/s^2\"]\n</code></pre>"},{"location":"examples/modules_05_icd/#visualisation-of-the-data","title":"Visualisation of the Data","text":"<p>The raw acceleration data including components of x, y and z axis is represented.</p> <pre><code># Calculate the time values\ntime = np.arange(len(accel_data)) / (sampling_frequency)\n\n# Create a figure with a specified size\nplt.figure(figsize=(22, 14))\n\n# Get colors for raw\ncolors = cfg_colors[\"raw\"]\n\n# A loop is used to plot data for each accelerometer axis, applying different colors from the color map.\nfor i in range(3):\n    plt.plot(\n        time,\n        accel_data.iloc[:,i],\n        color=colors[i],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\n\n# Add labels and legends\nplt.xlabel(\"Time (s)\", fontsize=20)\nplt.ylabel(\"Acceleration (m/s$^{2}$)\", fontsize=20)\nplt.legend(fontsize=18)\n\n# Add a title with a specified font size\nplt.title(\n    \"Accelerometer data from lower-back IMU sensor\",\n    fontsize=30,\n)\n\n# Customize tick font sizes\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\n\n# Display a grid for reference\nplt.grid(visible=None, which=\"both\", axis=\"both\")\n\n# Show the plot\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/modules_05_icd/#applying-paraschiv-ionescu-initial-contact-detection-algorithm","title":"Applying Paraschiv-Ionescu Initial Contact Detection Algorithm","text":"<p>Now, we are running Paraschiv-Ionescu initial contact detection algorithm from icd module <code>KielMAT.kielmat.modules.icd._paraschiv.ParaschivIonescuInitialContactDetection</code> to detect initial contacts throughout the detected gait sequences. For this purpose, we have to first apply Paraschiv-Ionescu gait sequences detection algorithm to identify gait sequences using acceleration data. The gait sequences are detected by Paraschiv gait sequence detection (<code>KielMAT.kielmat.modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection</code>).</p> <p>Then, in order to apply Paraschiv-Ionescu initial contact detection algorithm, an instance of the ParaschivIonescuInitialContactDetection class is created using the constructor, <code>ParaschivIonescuInitialContactDetection()</code>. The <code>icd</code> variable holds the instance, allowing us to access its methods. The inputs of Paraschiv-Ionescu initial contact detection algorithm are as follows:</p> <ul> <li>Input Data: <code>accel_data</code> consist of accelerometer data (N, 3) for the x, y, and z axes in pandas Dataframe format. The data should be in SI unit as m/s\u00b2.</li> <li>Gait Sequences: <code>gait_sequences</code>, consist of gait sequences detected by Paraschiv gait sequence detection (<code>KielMAT.kielmat.modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection</code>).</li> <li>Sampling Frequency: <code>sampling_freq_Hz</code> is the sampling frequency of the data, defined in Hz, with a default value of 100 Hz.</li> </ul> <pre><code># Create an instance of the ParaschivIonescuGaitSequenceDetection class\ngsd = ParaschivIonescuGaitSequenceDetection()\n\n# Call the gait sequence detection using gsd.detect to detect gait sequences\ngsd = gsd.detect(\n    accel_data=acceleration_data, sampling_freq_Hz=200, plot_results=False\n)\n\n# Gait sequences are stored in gait_sequences_ attribute of gsd\ngait_sequences = gsd.gait_sequences_\n\n# Now, use Paraschiv-Ionescu initial contact detection algortihm to find initial contacts within detected gait sequences.\nicd = ParaschivIonescuInitialContactDetection()\n\n# Call the initial contact detection using icd.detect\nicd = icd.detect(\n    accel_data=accel_data,\n    gait_sequences=gait_sequences,\n    sampling_freq_Hz=200,\n    v_acc_col_name=\"pelvis_ACCEL_x\"\n)\n\n# Print initial contacts information\nprint(icd.initial_contacts_)\n</code></pre> <pre><code>1 gait sequence(s) detected.\n        onset   event_type        duration   tracking_systems\n0       3.425   initial contact   0          None\n1       4.000   initial contact   0          None\n2       4.650   initial contact   0          None\n3       5.350   initial contact   0          None\n4       6.050   initial contact   0          None\n5       6.825   initial contact   0          None\n6       7.500   initial contact   0          None\n7       8.250   initial contact   0          None\n8       8.950   initial contact   0          None\n9       9.700   initial contact   0          None\n10      10.425  initial contact   0          None\n11      11.150  initial contact   0          None\n12      11.900  initial contact   0          None\n</code></pre>"},{"location":"examples/modules_05_icd/#visualization-of-the-detected-initial-contacts","title":"Visualization of the Detected Initial Contacts","text":"<p>In the following, the raw data of the lower back sensor is plotted with the detected events. The events are plotted as vertical lines. The events are:</p> <ul> <li>Gait onset: Start of the gait sequence</li> <li>Gait duration: Duration of the gait sequence</li> <li>Initial contacts: Initial contacts</li> </ul> <p>The gait onset is represented with the vertical green line and the grey area represents the duration of gait sequence detected by the algorithm. The vertical dashed blue lines are representing detected initial contacts within first gait sequence.</p> <pre><code># Load lower back acceleration data\nacceleration_data = recording.data[tracking_sys][\n    [\"pelvis_ACCEL_x\", \"pelvis_ACCEL_y\", \"pelvis_ACCEL_z\"]\n]\n\n# Get the corresponding unit of the acceleration data\naccel_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"].str.contains(\"ACCEL\", case=False)\n][\"units\"].iloc[0]\n\n# Check unit of acceleration data\nif accel_unit in [\"m/s^2\"]:\n    pass  # No conversion needed\nelif accel_unit in [\"g\", \"G\"]:\n    # Convert acceleration data from \"g\" to \"m/s^2\"\n    acceleration_data *= 9.81\n    # Update unit of acceleration\n    accel_unit = [\"m/s^2\"]\n\n# Access the first detected gait sequence\nfirst_gait_sequence = gsd.gait_sequences_[gsd.gait_sequences_[\"event_type\"] == \"gait sequence\"].iloc[0]\n\n# Print information about the first gait sequence\nprint(\"First Gait Sequence:\", first_gait_sequence)\n\n# Print information about initial contacts within the first gait sequence\nic_within_gait = icd.initial_contacts_[\n    icd.initial_contacts_[\"onset\"].between(\n        first_gait_sequence[\"onset\"],\n        first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"],\n    )\n]\nprint(\"\\nInitial Contacts within the First Gait Sequence:\", ic_within_gait)\n\n# Plot the raw data from the lower back\nfig, ax = plt.subplots(figsize=(22, 14))\n\n# Plot raw acceleration data\nfor i in range(3):\n    ax.plot(\n        time,\n        accel_data.iloc[:,i],\n        color=colors[i],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\n\n# Plot the first element of gait sequences\nplt.axvline(first_gait_sequence[\"onset\"], color=\"g\", label=\"Gait onset\")\nax.axvspan(\n    first_gait_sequence[\"onset\"],\n    first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"],\n    alpha=0.2,\n    color=\"gray\",\n    label=\"Gait duration\",\n)\n\n# Plot the initial contacts within the first gait sequence\nfor ic_time in ic_within_gait[\"onset\"]:\n    ax.axvline(ic_time, color=\"blue\", linestyle=\"--\")\n\n# Customize plot\nstart_limit = first_gait_sequence[\"onset\"] - 1\nend_limit = first_gait_sequence[\"onset\"] + first_gait_sequence[\"duration\"] + 1\nax.set_xlim(start_limit, end_limit)\nax.set_xlabel(\"Time (s)\", fontsize=20)\nax.set_ylabel(\"Acceleration (m/s$^{2}$)\", fontsize=20)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nax.legend(\n    [\"ACCEL x\", \"ACCEL y\", \"ACCEL z\", \"Gait onset\", \"Gait duration\", \"Initial contacts\"],\n    fontsize=20,\n    loc=\"upper right\",\n)\nplt.show()\n</code></pre> <pre><code>First Gait Sequence: \nonset                      3.125\nduration                   9.775\nevent_type         gait sequence\ntracking_system             None\nName: 0, dtype: object\n\nInitial Contacts within the First Gait Sequence:      \n     onset  event_type          duration    tracking_systems\n0    3.425  initial contact     0           None\n1    4.000  initial contact     0           None\n2    4.650  initial contact     0           None\n3    5.350  initial contact     0           None\n4    6.050  initial contact     0           None\n5    6.825  initial contact     0           None\n6    7.500  initial contact     0           None\n7    8.250  initial contact     0           None\n8    8.950  initial contact     0           None\n9    9.700  initial contact     0           None\n10  10.425  initial contact     0           None\n11  11.150  initial contact     0           None\n12  11.900  initial contact     0           None\n</code></pre> <p></p>"},{"location":"examples/modules_06_pam/","title":"Tutorial: Physical Activity Monitoring","text":"<p>Author: Masoud Abedinifar</p> <p>Last update: Fri 09 August 2024</p>"},{"location":"examples/modules_06_pam/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial, you will be able to:  </p> <ul> <li>Load accelerometer data from a raw recording</li> <li>Apply the Physical Activity Monitoring algorithm to classify activity intensity levels.  </li> <li>Interpret the results of activity classification.  </li> </ul>"},{"location":"examples/modules_06_pam/#physical-activity-monitoring","title":"Physical Activity Monitoring","text":"<p>This example serves as a reference on how to use the physical activity monitoring algorithm. This example can be cited by referencing the package.</p> <p>The example illustrates how the physical activity monitoring algorithm determines the intensity level of sedentary, light, moderate, and vigorous physical activities using body acceleration recorded with a triaxial accelerometer worn on the lowerback. The physical activity monitoring algorithm is implemented in the main module <code>kielmat.modules.pam._pam</code>.</p> <p>The algorithm determines the intensity level of physical activities based on the following steps:</p> <ol> <li> <p>Loading Data: Start by loading the data, including a time index along with accelerometer data (N, 3) for x, y, and z axes. The other inputs are the sampling frequency of the data (sampling_freq_Hz), defaulting to 100 Hz, and thresholds (thresholds_mg), provided as a dictionary containing threshold values for physical activity detection in mg unit. Another input is the epoch duration (epoch_duration_sec) in seconds, defaulting to 5 seconds. The last input, plot_results, when set to True, generates a plot showing the average Euclidean Norm Minus One (ENMO) per hour for each date, with a default of True.</p> </li> <li> <p>Preprocessing: The input signal is preprocessed by calculating the sample-level Euclidean norm (EN) of the acceleration signal across the x, y, and z axes. A fourth-order Butterworth low-pass filter with a cut-off frequency of 20Hz is then applied to remove noise. This filter is applied to the vector magnitude scores. The ENMO index is calculated to separate the activity-related component of the acceleration signal. Negative ENMO values are truncated to zero. Finally, the indices are multiplied by 1000 to convert units from g to mg.</p> </li> <li> <p>Classification: The algorithm classifies the intensity of physical activities based on the calculated ENMO values. The activity_classification function expresses the ENMO time-series data in 5-second epochs for summarizing the data. Thresholds for categorization are as follows: sedentary activity &lt; 45 mg, light activity 45\u2013100 mg, moderate activity 100\u2013400 mg, vigorous activity &gt; 400 mg.</p> </li> <li> <p>Results: The algorithm classifies different levels of activities along with the time spent on each activity level for each day. If <code>plot_results</code> is set to True, the function generates a plot showing the averaged ENMO values for each day.</p> </li> </ol>"},{"location":"examples/modules_06_pam/#references","title":"References","text":"<p>[<code>1</code>] Doherty, Aiden, et al. (2017). Large scale population assessment of physical activity using wrist-worn accelerometers: the UK biobank study. PloS one 12.2. https://doi.org/10.1371/journal.pone.0169649</p> <p>[<code>2</code>] Van Hees, Vincent T., et al. (2013). Separating movement and gravity components in an acceleration signal and implications for the assessment of human daily physical activity. PloS one 8.4. https://doi.org/10.1371/journal.pone.0061691</p>"},{"location":"examples/modules_06_pam/#import-libraries","title":"Import Libraries","text":"<p>The necessary libraries such as pandas, physical activity monitoring and mobilised dataset are imported. Make sure that you have all the required libraries and modules installed before running this code. You may also need to install the <code>kielmat</code> library and its dependencies if you haven't already.</p> <pre><code>import pandas as pd\nimport os\nfrom pathlib import Path\nfrom kielmat.modules.pam import PhysicalActivityMonitoring\nfrom kielmat.datasets import mobilised\n</code></pre>"},{"location":"examples/modules_06_pam/#data-preparation","title":"Data Preparation","text":"<p>To implement the physical activity monitoring algorithm, we load example data from a participant who has worn a LowerBack IMU sensor for several hours during a day while performing daily life activities at home.</p> <p>The accelerometer data (N, 3) for the x, y, and z axes, is loaded as a pandas DataFrame.</p> <pre><code># Set the dataset path\ndataset_path = Path(os.getcwd()) / \"_mobilised\"\n\n# Fetch and load the dataset\nmobilised.fetch_dataset(dataset_path=dataset_path)\n</code></pre> <pre><code># In this example, we use \"SU\" as tracking_system and \"LowerBack\" as tracked points.\ntracking_sys = \"SU\"\ntracked_points = {tracking_sys: [\"LowerBack\"]}\n</code></pre> <pre><code># The 'mobilised.load_recording' function is used to load the data from the specified file_path\nrecording = mobilised.load_recording(\n    cohort=\"PFF\",  # Choose the cohort\n    file_name=\"data.mat\", \n    dataset_path=dataset_path)\n\n# Load lower back acceleration data\naccel_data = recording.data[tracking_sys][\n    [\"LowerBack_ACCEL_x\", \"LowerBack_ACCEL_y\", \"LowerBack_ACCEL_z\"]\n]\n\n# Get the corresponding sampling frequency directly from the recording\nsampling_frequency = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n][\"sampling_frequency\"].values[0]\n\n# Get the acceleration data unit from the recording\nacceleration_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"LowerBack_ACCEL_x\"\n][\"units\"].values[0]\n</code></pre>"},{"location":"examples/modules_06_pam/#apply-physical-activity-monitoring-algorithm","title":"Apply Physical Activity Monitoring Algorithm","text":"<p>Now, we are running the physical activity monitoring algorithm from the main module <code>kielmat.modules.pam._pam</code>. The inputs of the algorithm are as follows:</p> <ul> <li>Input Data: <code>data</code> Includes data with a time index along with accelerometer data (N, 3) for x, y, and z axes in pandas Dataframe format.</li> <li>Acceleration Unit: <code>acceleration_unit</code> is the unit of the acceleration data.</li> <li>Sampling Frequency: <code>sampling_freq_Hz</code> is the sampling frequency of the acceleration data, defined in Hz, with a default value of 100 Hz.</li> <li>Thresholds: <code>thresholds_mg</code> are provided as a dictionary containing threshold values for physical activity detection in mili-g.</li> <li>Epoch Duration: <code>epoch_duration_sec</code> is the epoch length in seconds, with a default value of 5 seconds.</li> <li>Plot Results: <code>plot_results</code>, if set to True, generates a plot showing the average Euclidean Norm Minus One (ENMO) per hour for each day.</li> </ul> <p>To apply the physical activity monitoring algorithm, an instance of the PhysicalActivityMonitoring class is created using the constructor, <code>PhysicalActivityMonitoring()</code>. The <code>pam</code> variable holds the instance, allowing us to access its methods. The output of the algorithm includes information regarding physical activity levels and the time spent on each activity for the provided date, including the mean of sedentary time, light, moderate, and vigorous activities, along with the time spent for each of them.</p> <p><pre><code># Initialize the PhysicalActivityMonitoring class\npam = PhysicalActivityMonitoring()\n\n# Detect physical activity\npam.detect(\n    data=accel_data,\n    acceleration_unit=acceleration_unit,\n    sampling_freq_Hz=sampling_frequency,\n    thresholds_mg={\n        \"sedentary_threshold\": 45,\n        \"light_threshold\": 100,\n        \"moderate_threshold\": 400,\n    },\n    epoch_duration_sec=5,\n    plot=False\n)\n\n# Print detected physical activities\nprint(pam.physical_activities_)\n</code></pre>         date        sedentary_mean_enmo  sedentary_time_min  light_mean_enmo     light_time_min  moderate_mean_enmo  moderate_time_min      vigorous_time_min  vigorous_mean_enmo     0  2023-01-01   0.824444             115.583333          NaN                 0               NaN                 0                      NaN                0           </p>"},{"location":"examples/modules_07_ptd/","title":"Tutorial: Postural Transition Detection","text":"<p>Author: Masoud Abedinifar</p> <p>Last update: Tue 01 October 2024</p>"},{"location":"examples/modules_07_ptd/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial:</p> <ul> <li>You can load data from <code>keepcontrol</code> which is one of available datasets.</li> <li>Apply the <code>Postural Transition Detection</code> algorithm.</li> <li>Visualize the results of the algorithm.</li> <li>Extract spatio-temporal parameters of the detected postural transitions.</li> <li>Interpret the detected postural transitions for further analysis.</li> </ul>"},{"location":"examples/modules_07_ptd/#pham-postural-transition-detection","title":"Pham Postural Transition Detection","text":"<p>This example can be referenced by citing the package.</p> <p>The example illustrates how to use Pham Postural Transition Detection algorithm to detect postural transitions (e.g., sit to stand and stand to sit movements) using body acceleration and gyro data recorded with a lower back IMU sensor. The Pham Postural Transition detection algorithm is implemented using <code>kielmat.modules.ptd._pham</code>. This algorithm is based on the research of Pham et al [1].</p> <p>This algorithm aims to detect postural transitions (e.g., sit to stand or stand to sit movements) using accelerometer and gyroscope data collected from a lower back inertial measurement unit (IMU) sensor.</p> <p>The algorithm is designed to be robust in detecting postural transitions using inertial sensor data  and provides detailed information about these transitions. It starts by loading the accelerometer and  gyro data, which includes three columns corresponding to the acceleration and gyro signals across  the x, y, and z axes, along with the sampling frequency of the data. It first checks the validity of  the input data. Then, it calculates the sampling period, selects accelerometer and gyro data. Tilt angle estimation is performed using gyro data in lateral or anteroposterior direction which represent movements or rotations in the mediolateral direction. The tilt angle is decomposed using wavelet transformation to  identify stationary periods. Stationary periods are detected using accelerometer variance and gyro variance. Then, peaks in the wavelet-transformed tilt signal are detected as potential postural transition events.</p> <p>If there's enough stationary data, further processing is done to estimate the orientation using quaternions and to identify the beginning and end of postural transitions using gyro data. Otherwise, if there's insufficient stationary data, direction changes in gyro data are used to infer postural transitions. Finally, the detected postural transitions along with their characteristics (onset, duration, etc.) are stored in a pandas DataFrame (postural_transitions_ attribute).</p> <p>In addition, spatial-temporal parameters are calculated using detected postural transitions and their characteristics by the <code>spatio_temporal_parameters</code> method. As a return, the postural transition id along with its spatial-temporal parameters including type of postural transition (sit to stand or stand to sit), angle of postural transition, maximum flexion velocity, and maximum extension velocity are stored in a pandas  DataFrame (<code>parameters_</code> attribute).</p> <p>If requested (<code>plot_results</code> set to True), it generates plots of the accelerometer and gyroscope data along with the detected postural transitions.</p>"},{"location":"examples/modules_07_ptd/#references","title":"References","text":"<p>[1] Pham et al. (2018). Validation of a Lower Back \"Wearable\"-Based Sit-to-Stand and  Stand-to-Sit Algorithm for Patients With Parkinson's Disease and Older Adults in a Home-Like  Environment. Frontiers in Neurology, 9, 652. https://doi.org/10.3389/fneur.2018.00652</p>"},{"location":"examples/modules_07_ptd/#import-libraries","title":"Import libraries","text":"<p>The necessary libraries such as numpy, matplotlib.pyplot, dataset and Pham Postural Transition Detection algorithm are imported. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the <code>kielmat</code> library and its dependencies if you haven't already.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom kielmat.datasets import keepcontrol\nfrom kielmat.modules.ptd import PhamPosturalTransitionDetection\nfrom pathlib import Path\n</code></pre>"},{"location":"examples/modules_07_ptd/#data-preparation","title":"Data Preparation","text":"<p>To implement Pham Postural Transition Detection algorithm, we load example data.</p> <p><pre><code># Dataset path\ndataset_path = Path(os.getcwd()) / \"_keepcontrol\"\n\n# Fetch the dataset\nkeepcontrol.fetch_dataset(dataset_path)\n\n# In this example, we use \"imu\" as tracking_system and \"pelvis\" as tracked points.\ntracking_sys = \"imu\"\ntracked_points = {tracking_sys: [\"pelvis\"]}\n\n# The 'keepcontrol.load_recording' function is used to load the data from the specified file_path\nrecording = keepcontrol.load_recording(\n    dataset_path=dataset_path,\n    id=\"pp002\",\n    task=\"tug\",\n    tracking_systems=[tracking_sys], \n    tracked_points=tracked_points\n)\n\n# Load lower back acceleration data\naccel_data = recording.data[tracking_sys][\n    [\"pelvis_ACCEL_x\", \"pelvis_ACCEL_y\", \"pelvis_ACCEL_z\"]\n]\n\n# Get the acceleration data unit from the recording\naccel_data_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"].str.contains(\"ACCEL\", case=False)\n][\"units\"].iloc[0]\n\n# Load lower back gyro data\ngyro_data = recording.data[tracking_sys][\n    [\"pelvis_GYRO_x\", \"pelvis_GYRO_y\", \"pelvis_GYRO_z\"]\n]\n\n# Get the gyro data unit from the recording\ngyro_data_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"].str.contains(\"GYRO\", case=False)\n][\"units\"].iloc[0]\n\n# Print acceleration and gyro data\nprint(f\"accel_data ({accel_unit}): {accel_data}\")\nprint(f\"gyro_data ({gyro_unit}): {gyro_data}\")\n</code></pre> accel_data (g):</p> <pre><code>                    pelvis_ACCEL_x      pelvis_ACCEL_y      pelvis_ACCEL_z\n        0           0.920901           -0.047850           -0.400888\n        1           0.919441           -0.051282           -0.392583\n        2           0.922828           -0.047359           -0.392093\n        3           0.926741           -0.048830           -0.384279\n        4           0.918973           -0.053218           -0.397947\n        ...         ...                 ...                 ...\n        2903        0.966803           -0.027822           -0.279782\n        2904        0.957517           -0.035152           -0.285636\n        2905        0.960437           -0.034171           -0.291979\n        2906        0.962890           -0.036623           -0.299794\n        2907        0.963883           -0.038584           -0.294921\n</code></pre> <p>[2908 rows x 3 columns]</p> <p>gyro_data (deg/s):        </p> <pre><code>                    pelvis_GYRO_x     pelvis_GYRO_y     pelvis_GYRO_z\n        0           0.000000         -0.614677          0.436291\n        1           0.000000         -0.700049          0.176093\n        2          -0.172905         -0.261807         -0.262826\n        3           0.262815         -0.261807          0.000000\n        4           0.608625         -0.614677         -0.349559\n        ...         ...               ...               ...\n        2903       -0.089911         -1.309034          0.000000\n        2904        0.525631         -0.438242         -0.436291\n        2905        0.871441         -0.961855          0.086733\n        2906        1.051262         -0.700049          0.176093\n        2907        1.134256         -0.347179         -0.525652\n</code></pre> <p>[2908 rows x 3 columns]</p> <p><pre><code># Get the corresponding sampling frequency directly from the recording\nsampling_frequency = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"pelvis_ACCEL_x\"\n][\"sampling_frequency\"].values[0]\n\n# Print sampling frequency\nprint(f\"sampling frequency: {sampling_frequency} Hz\")\n</code></pre> sampling frequency: 200 Hz</p>"},{"location":"examples/modules_07_ptd/#data-units-and-conversion-to-si-units","title":"Data Units and Conversion to SI Units","text":"<p>All input data provided to the modules in this toolbox should adhere to SI units to maintain consistency and accuracy across analyses. This ensures compatibility with the underlying algorithms, which are designed to work with standard metric measurements.</p> <p>If any data is provided in non-SI units (e.g., acceleration in g instead of m/s\u00b2), it is needed that the data to be converted into the appropriate SI units before using it as input to the toolbox. Failure to convert non-SI units may lead to incorrect results or misinterpretation of the output.</p> <p>For instance:</p> <ul> <li>Acceleration: Convert from g to m/s\u00b2.</li> </ul> <pre><code># Check unit of acceleration data\nif accel_unit in [\"m/s^2\"]:\n    pass  # No conversion needed\nelif accel_unit in [\"g\", \"G\"]:\n    # Convert acceleration data from \"g\" to \"m/s^2\"\n    accel_data *= 9.81\n    # Update unit of acceleration\n    accel_unit = [\"m/s^2\"]\n\n# Check unit of gyro data\nif gyro_unit in [\"deg/s\", \"\u00b0/s\"]:\n    pass  # No conversion needed\nelif gyro_unit == \"rad/s\":\n    # Convert gyro data from \"rad/s\" to \"deg/s\"\n    gyro_data = np.rad2deg(gyro_data)\n    # Update unit of gyro\n    gyro_unit = [\"deg/s\"]\n</code></pre>"},{"location":"examples/modules_07_ptd/#visualisation-of-the-data","title":"Visualisation of the Data","text":"<p>The raw acceleration and gyro data including components of x, y and z axis are plotted.</p> <pre><code># Plot acceleration and gyro in subplots\nfig = plt.figure(figsize=(12, 6))\n\n# Font size for all text elements\nfont_size = 14\n\n# Subplot 1: Acceleration data\nax1 = plt.subplot(211)\nfor i in range(3):\n    ax1.plot(\n        np.arange(len(accel_data)) / sampling_frequency,\n        accel_data[f\"pelvis_ACCEL_{chr(120 + i)}\"],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\nax1.set_ylabel(f\"Acceleration (m/s$^{2}$)\", fontsize=font_size)\nax1.set_xlabel(f\"Time (s)\", fontsize=font_size)\nax1.legend(loc=\"upper left\", fontsize=font_size)\naccel_min = np.min(accel_data)\naccel_max = np.max(accel_data)\nbuffer = (accel_max - accel_min) * 0.1\nax1.set_ylim(accel_min - buffer, accel_max + buffer)\nplt.xticks(fontsize=font_size)\nplt.yticks(fontsize=font_size)\n\n# Subplot 2: Gyro data\nax2 = plt.subplot(212)\nfor i in range(3):\n    ax2.plot(\n        np.arange(len(gyro_data)) / sampling_frequency,\n        gyro_data[f\"pelvis_GYRO_{chr(120 + i)}\"],\n        label=f\"GYRO {'xyz'[i]}\",\n    )\nax2.set_ylabel(f\"Gyro (deg/s)\", fontsize=font_size)\nax2.set_xlabel(f\"Time (s)\", fontsize=font_size)\nax2.legend(loc=\"upper left\", fontsize=font_size)\ngyro_min = np.min(gyro_data)\ngyro_max = np.max(gyro_data)\nbuffer = (gyro_max - gyro_min) * 0.1\nax2.set_ylim(gyro_min - buffer, gyro_max + buffer)\nplt.xticks(fontsize=font_size)\nplt.yticks(fontsize=font_size)\nfig.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/modules_07_ptd/#applying-pham-postural-transition-detection-algorithm","title":"Applying Pham Postural Transition Detection Algorithm","text":"<p>Now, we are running Pham sit to stand and stand to sit detection algorithm from pham module <code>PhamPosturalTransitionDetection</code> to detect postural transitions.</p> <p>The following code first prepares the input data by combining acceleration and gyro data into a single DataFrame called <code>input_data</code>.</p> <p>Then, in order to apply pham postural transition algorithm, an instance of the PhamPosturalTransitionDetection class is created using the constructor, <code>PhamPosturalTransitionDetection()</code>. The <code>pham</code> variable holds this instance, allowing us to access its methods. The inputs of the algorithm are as follows:</p> <ul> <li>Acceleration data: <code>accel_data (pd.DataFrame)</code> includes accelerometer data (N, 3) for x, y, and z axes. in pandas Dataframe format.</li> <li>Gyro data: <code>gyro_data (pd.DataFrame)</code> includes gyro data (N, 3) for x, y, and z axes. in pandas Dataframe format.</li> <li>Sampling frequency: <code>sampling_freq_Hz</code> is the sampling frequency of the data, defined in Hz.</li> <li>Datetime: <code>dt_data (pd.Series, optional)</code> is the original datetime in the input data which is optional.</li> <li>Tracking system: <code>tracking_system (str, optional)</code> is the name of tracking system which is optional.</li> <li>Tracked Point: <code>tracked_point (str, optional)</code> is the tracked point name on the body which is optional.</li> <li>Plot Results: <code>plot_results (bool, optional)</code>, if set to True, generates a plot showing the detected turns on the data. The default is False. The onset is represented with the vertical red line and the grey area represents the duration of the turns detected by the algorithm.</li> </ul> <p><pre><code># Create an instance of the PhamPosturalTransitionDetection class\npham = PhamPosturalTransitionDetection()\n\n# Call the postural transition detection using pham.detect\npham = pham.detect(\n    accel_data=accel_data,\n    gyro_data=gyro_data,\n    sampling_freq_Hz=sampling_frequency,\n    tracking_system=\"imu\",\n    tracked_point=\"pelvis\",\n    plot_results=True,\n)\n</code></pre> </p> <p>The outputs are stored in the <code>postural_transitions_</code> attribute, which is a pandas DataFrame in BIDS format with the following columns:</p> <ul> <li>onset: Start of the turn event in seconds.</li> <li>duration: Duration of the turn event in seconds.</li> <li>event_type: Type of event which is postural transition.</li> <li>tracking_systems: Tracking system which is 'imu' for this example.</li> <li>tracked_points: Tracked points on the body which is 'pelvis' for this example.</li> </ul> <pre><code># Print events and their corresponding information\npostural_transition_events = pham.postural_transitions_\nprint(f\"postural_transition_events: {postural_transition_events}\")\n</code></pre> <pre><code>postural_transition_events:     \n        onset   duration    event_type              tracking_systems    tracked_points\n0       3.39    1.91        postural transition     imu                 pelvis\n1       11.54   2.96        postural transition     imu                 pelvis\n</code></pre>"},{"location":"examples/modules_07_ptd/#extraction-of-spatio-temporal-parameters","title":"Extraction of Spatio-temporal Parameters","text":"<p>Next, the spatial-temporal parameters could be extracted using the spatio_temporal_parameters method. The outputs are stored in the <code>parameters_</code> attribute, which is a pandas DataFrame and icnlues postural transition id along with the following parameters:</p> <ul> <li>type_of_postural_transition: Type of postural transition which is either \"sit to stand\" or \"stand to sit\".</li> <li>angel_of_postural_transition: Angle of the postural transition in degrees.</li> <li>maximum_flexion_velocity: Maximum flexion velocity in deg/s.</li> <li>maximum_extension_velocity: Maximum extension velocity deg/s.</li> </ul> <pre><code># Call the spatio-temporal parameters object for extracting the temporal parameters\npham.spatio_temporal_parameters()\n\n# Print temporal parameters for each turn\nprint(pham.parameters_)\n</code></pre> <pre><code>                        type_of_postural_transition     angle_of_postural_transition        maximum_flexion_velocity        maximum_extension_velocity  \npostural transition id                               \n0                       sit to stand                    71.62                               186                             78   \n1                       stand to sit                    28.25                               97                              113\n</code></pre>"},{"location":"examples/modules_08_td/","title":"Tutorial: turn detection algortihm","text":"<p>Author: Masoud Abedinifar</p> <p>Last update: Wed 02 October 2024</p>"},{"location":"examples/modules_08_td/#learning-objectives","title":"Learning Objectives","text":"<p>By the end of this tutorial:</p> <ul> <li>You can load data from <code>keepcontrol</code> which is one of available datasets.</li> <li>Apply the <code>Pham Turn Detection</code> algorithm.</li> <li>Visualize the results of the algorithm.</li> <li>Extract spatio-temporal parameters of the detected turns.</li> <li>Interpret the detected turns for further analysis.</li> </ul>"},{"location":"examples/modules_08_td/#pham-turn-detection","title":"Pham Turn Detection","text":"<p>This example can be referenced by citing the package.</p> <p>The example illustrates how to use PhamTurnDetection algorithm to detect turns using acceleration and gyro data recorded with a lower back IMU sensor. The turn detection algorithm is implemented using <code>kielmat.modules.td._pham</code>. This algorithm is based on the research of Pham et al [<code>1</code>].</p> <p>This algorithm aims to detect turns using accelerometer and gyroscope data collected from a lower back inertial measurement unit (IMU) sensor. The core of the algorithm lies in the detect method, where turns are identified using accelerometer and gyroscope data. The method first processes the gyro data, converting it to rad/s and computing the variance to identify periods of low variance, which may indicate bias. It then calculates the gyro bias and subtracts it from the original gyro signal to remove any biases. Next, the yaw angle is computed by integrating the gyro data, and zero-crossings indices are found to detect turns. Then, turns are identified based on significant changes in the yaw angle.</p> <p>The algorithm also accounts for hesitations, which are brief pauses or fluctuations in the signal that may occur within a turn. Hesitations are marked based on specific conditions related to the magnitude and continuity of the yaw angle changes.</p> <p>Then, the detected turns are characterized by their onset and duration. Turns with angles equal to or greater than 90 degrees and durations between 0.5 and 10 seconds are selected for further analysis. Finally, the detected turns along with their characteristics (onset, duration, etc.) are stored in a pandas DataFrame (<code>turns_</code> attribute).</p> <p>In addition, spatial-temporal parameters are calculated using detected turns and their characteristics by the <code>spatio_temporal_parameters</code> method. As a return, the turn id along with its spatial-temporal parameters including direction (left or right), angle of turn and peak angular velocity are stored in a pandas DataFrame (<code>parameters_</code> attribute).</p> <p>Optionally, if <code>plot_results</code> is set to True, the algorithm generates a plot visualizing the accelerometer and gyroscope data alongside the detected turns. This visualization aids in the qualitative assessment of the algorithm's performance and provides insights into the dynamics of the detected turns.</p>"},{"location":"examples/modules_08_td/#references","title":"References","text":"<p>[<code>1</code>] Pham et al. (2017). Algorithm for Turning Detection and Analysis Validated under Home-Like Conditions in Patients with Parkinson's Disease and Older Adults using a 6 Degree-of-Freedom Inertial Measurement Unit at the Lower Back. Frontiers in Neurology, 8, 135. https://doi.org/10.3389/fneur.2017.00135</p>"},{"location":"examples/modules_08_td/#import-libraries","title":"Import Libraries","text":"<p>The necessary libraries such as numpy, matplotlib.pyplot, dataset and PhamTurnDetection turn detection algortihm are imported. Make sure that you have all the required libraries and modules installed before running this code. You also may need to install the <code>kielmat</code> library and its dependencies if you haven't already.</p> <pre><code>import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom kielmat.datasets import keepcontrol\nfrom kielmat.modules.td import PhamTurnDetection\nfrom pathlib import Path\n</code></pre>"},{"location":"examples/modules_08_td/#data-preparation","title":"Data Preparation","text":"<p>To implement Pham Turn Detection algorithm, we load example data.</p> <p><pre><code># Dataset path\ndataset_path = Path(os.getcwd()) / \"_keepcontrol\"\n\n# Fetch the dataset\nkeepcontrol.fetch_dataset(dataset_path)\n\n# In this example, we use \"imu\" as tracking_system and \"pelvis\" as tracked points.\ntracking_sys = \"imu\"\ntracked_points = {tracking_sys: [\"pelvis\"]}\n\n# The 'keepcontrol.load_recording' function is used to load the data from the specified file_path\nrecording = keepcontrol.load_recording(\n    dataset_path=dataset_path,\n    id=\"pp002\",\n    task=\"tug\",\n    tracking_systems=[tracking_sys], \n    tracked_points=tracked_points\n)\n\n# Load lower back acceleration data\naccel_data = recording.data[tracking_sys][\n    [\"pelvis_ACCEL_x\", \"pelvis_ACCEL_y\", \"pelvis_ACCEL_z\"]\n]\n\n# Get the acceleration data unit from the recording\naccel_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"].str.contains(\"ACCEL\", case=False)\n][\"units\"].iloc[0]\n\n# Load lower back gyro data\ngyro_data = recording.data[tracking_sys][\n    [\"pelvis_GYRO_x\", \"pelvis_GYRO_y\", \"pelvis_GYRO_z\"]\n]\n\n# Get the gyro data unit from the recording\ngyro_unit = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"].str.contains(\"GYRO\", case=False)\n][\"units\"].iloc[0]\n\n# Print acceleration and gyro data\nprint(f\"accel_data ({accel_unit}): {accel_data}\")\nprint(f\"gyro_data ({gyro_unit}): {gyro_data}\")\n</code></pre> accel_data (g):</p> <pre><code>                    pelvis_ACCEL_x      pelvis_ACCEL_y      pelvis_ACCEL_z\n        0           0.920901           -0.047850           -0.400888\n        1           0.919441           -0.051282           -0.392583\n        2           0.922828           -0.047359           -0.392093\n        3           0.926741           -0.048830           -0.384279\n        4           0.918973           -0.053218           -0.397947\n        ...         ...                 ...                 ...\n        2903        0.966803           -0.027822           -0.279782\n        2904        0.957517           -0.035152           -0.285636\n        2905        0.960437           -0.034171           -0.291979\n        2906        0.962890           -0.036623           -0.299794\n        2907        0.963883           -0.038584           -0.294921\n</code></pre> <p>[2908 rows x 3 columns]</p> <p>gyro_data (deg/s):        </p> <pre><code>                    pelvis_GYRO_x     pelvis_GYRO_y     pelvis_GYRO_z\n        0           0.000000         -0.614677          0.436291\n        1           0.000000         -0.700049          0.176093\n        2          -0.172905         -0.261807         -0.262826\n        3           0.262815         -0.261807          0.000000\n        4           0.608625         -0.614677         -0.349559\n        ...         ...               ...               ...\n        2903       -0.089911         -1.309034          0.000000\n        2904        0.525631         -0.438242         -0.436291\n        2905        0.871441         -0.961855          0.086733\n        2906        1.051262         -0.700049          0.176093\n        2907        1.134256         -0.347179         -0.525652\n</code></pre> <p>[2908 rows x 3 columns]</p>"},{"location":"examples/modules_08_td/#load-and-print-sampling-frequency-of-the-data","title":"Load and print sampling frequency of the data","text":"<p><pre><code># Get the corresponding sampling frequency directly from the recording\nsampling_frequency = recording.channels[tracking_sys][\n    recording.channels[tracking_sys][\"name\"] == \"pelvis_ACCEL_x\"\n][\"sampling_frequency\"].values[0]\n\n# Print sampling frequency and its type\nprint(f\"sampling frequency: {sampling_frequency} Hz\")\n</code></pre> sampling frequency: 200 Hz</p>"},{"location":"examples/modules_08_td/#data-units-and-conversion-to-si-units","title":"Data Units and Conversion to SI Units","text":"<p>All input data provided to the modules in this toolbox should adhere to SI units to maintain consistency and accuracy across analyses. This ensures compatibility with the underlying algorithms, which are designed to work with standard metric measurements.</p> <p>If any data is provided in non-SI units (e.g., acceleration in g instead of m/s\u00b2), it is needed that the data to be converted into the appropriate SI units before using it as input to the toolbox. Failure to convert non-SI units may lead to incorrect results or misinterpretation of the output.</p> <p>For instance:</p> <ul> <li>Acceleration: Convert from g to m/s\u00b2.</li> </ul> <pre><code># Check unit of acceleration data\nif accel_unit in [\"m/s^2\"]:\n    pass  # No conversion needed\nelif accel_unit in [\"g\", \"G\"]:\n    # Convert acceleration data from \"g\" to \"m/s^2\"\n    accel_data *= 9.81\n    # Update unit of acceleration\n    accel_unit = [\"m/s^2\"]\n\n# Check unit of gyro data\nif gyro_unit in [\"deg/s\", \"\u00b0/s\"]:\n    pass  # No conversion needed\nelif gyro_unit == \"rad/s\":\n    # Convert gyro data from \"rad/s\" to \"deg/s\"\n    gyro_data = np.rad2deg(gyro_data)\n    # Update unit of gyro\n    gyro_unit = [\"deg/s\"]\n</code></pre>"},{"location":"examples/modules_08_td/#visualisation-of-the-data","title":"Visualisation of the Data","text":"<p>The raw acceleration and gyro data including components of x, y and z axis are plotted using following code.</p> <pre><code># Plot acceleration and gyro in subplots\nfig = plt.figure(figsize=(12, 6))\n\n# Font size for all text elements\nfont_size = 14\n\n# Subplot 1: Acceleration data\nax1 = plt.subplot(211)\nfor i in range(3):\n    ax1.plot(\n        np.arange(len(accel_data)) / sampling_frequency,\n        accel_data[f\"pelvis_ACCEL_{chr(120 + i)}\"],\n        label=f\"ACCEL {'xyz'[i]}\",\n    )\nax1.set_ylabel(f\"Acceleration (m/s$^{2}$)\", fontsize=font_size)\nax1.set_xlabel(f\"Time (s)\", fontsize=font_size)\nax1.legend(loc=\"upper right\", fontsize=font_size)\naccel_min = np.min(accel_data)\naccel_max = np.max(accel_data)\nbuffer = (accel_max - accel_min) * 0.1\nax1.set_ylim(accel_min - buffer, accel_max + buffer)\nplt.xticks(fontsize=font_size)\nplt.yticks(fontsize=font_size)\n\n# Subplot 2: Gyro data\nax2 = plt.subplot(212)\nfor i in range(3):\n    ax2.plot(\n        np.arange(len(gyro_data)) / sampling_frequency,\n        gyro_data[f\"pelvis_GYRO_{chr(120 + i)}\"],\n        label=f\"GYRO {'xyz'[i]}\",\n    )\nax2.set_ylabel(f\"Gyro (deg/s)\", fontsize=font_size)\nax2.set_xlabel(f\"Time (s)\", fontsize=font_size)\nax2.legend(loc=\"upper right\", fontsize=font_size)\ngyro_min = np.min(gyro_data)\ngyro_max = np.max(gyro_data)\nbuffer = (gyro_max - gyro_min) * 0.1\nax2.set_ylim(gyro_min - buffer, gyro_max + buffer)\nplt.xticks(fontsize=font_size)\nplt.yticks(fontsize=font_size)\nfig.tight_layout()\nplt.show()\n</code></pre> <p></p>"},{"location":"examples/modules_08_td/#applying-pham-turn-detection-algorithm","title":"Applying Pham Turn Detection Algorithm","text":"<p>Now, we are running Pham turn detection algorithm from pham module <code>PhamTurnDetection</code> to detect turns.</p> <p>The following code first prepares the input data by combining acceleration and gyro data into a single DataFrame called <code>input_data</code>.</p> <p>Then, in order to apply turn detection algorithm, an instance of the PhamTurnDetection class is created using the constructor, <code>PhamTurnDetection()</code>. The <code>pham</code> variable holds this instance, allowing us to access its methods. The inputs of the algorithm are as follows:</p> <ul> <li>Acceleration data: <code>accel_data (pd.DataFrame)</code> includes accelerometer data (N, 3) for x, y, and z axes. in pandas Dataframe format. The unit of acceleration data should be in SI as m/s\u00b2.</li> <li>Gyro data: <code>gyro_data (pd.DataFrame)</code> includes gyro data (N, 3) for x, y, and z axes. in pandas Dataframe format. The unit of Gyro data should be in deg/s.</li> <li>Vertical gyro: <code>gyro_vertical (str)</code> corresponds to the name of the vertical component of gyro.</li> <li>Sampling Frequency: <code>sampling_freq_Hz</code> is the sampling frequency of the data, defined in Hz.</li> <li>Datetime: <code>dt_data (pd.Series, optional)</code> is the original datetime in the input data which is optional.</li> <li>Tracking system: <code>tracking_system (str, optional)</code> is the name of tracking system which is optional.</li> <li>Tracked Point: <code>tracked_point (str, optional)</code> is the tracked point name on the body which is optional.</li> <li>Plot Results: <code>plot_results (bool, optional)</code>, if set to True, generates a plot showing the detected turns on the data. The default is False. The onset is represented with the vertical red line and the grey area represents the duration of the turns detected by the algorithm.</li> </ul> <p><pre><code># Create an instance of the PhamTurnDetection class\npham = PhamTurnDetection()\n\n# Call the turn detection using pham.detect\npham = pham.detect(\n    accel_data=accel_data,\n    gyro_data=gyro_data,\n    gyro_vertical=\"pelvis_GYRO_x\",\n    sampling_freq_Hz=sampling_frequency,\n    tracking_system=\"imu\",\n    tracked_point=\"pelvis\",\n    plot_results=True,\n)\n</code></pre> </p> <p>The outputs are stored in the 'turns_' attribute, which is a pandas DataFrame in BIDS format with the following columns:</p> <ul> <li>onset: Start of the turn event in seconds.</li> <li>duration: Duration of the turn event in seconds.</li> <li>event_type: Type of event which is turn.</li> <li>tracking_systems: Tracking system which is 'imu' for this example.</li> <li>tracked_points: Tracked points on the body which is 'pelvis' for this example.</li> </ul> <pre><code># Print events and their corresponding information\nprint(f\"turn id: {pham.turns_}\")\n</code></pre> <pre><code>turn id:    onset   duration    event_type  tracking_systems    tracked_points\n0           7.17    2.14        turn        imu                 pelvis\n1          10.65    1.77        turn        imu                 pelvis\n</code></pre>"},{"location":"examples/modules_08_td/#extraction-of-spatio-temporal-parameters","title":"Extraction of spatio-temporal parameters","text":"<p>Next, the spatial-temporal parameters could be extracted using the spatio_temporal_parameters method. The outputs are stored in the 'parameters_' attribute, which is a pandas DataFrame and icnlues trun id along with following parameters:</p> <ul> <li>direction of turn: Direction of turn which is either left or right.</li> <li>angle of turn: Angle of turns in degrees.</li> <li>peak angular velocity: Peak angular velocity (deg/s).</li> </ul> <pre><code># Call the spatio-temporal parameters object for extracting the temporal parameters\npham.spatio_temporal_parameters()\n\n# Print temporal parameters for each turn\nprint(pham.parameters_)\n</code></pre> <pre><code>            direction of turn  angle of turn [deg]  peak angular velocity [deg/s]\nturn id                                                                      \n0           right              191.67               162.25\n1           right              175.47               226.29\n</code></pre>"},{"location":"modules/","title":"Overview","text":"<p>This section of the project documentation presents the available modules within the KielMAT toolbox. These modules are developed to analyze motion data and assist in movement analysis-related activities. Each module is briefly introduced below, with links to more comprehensive guides.</p>"},{"location":"modules/#gait-sequence-detection-paraschiv-ionescu","title":"Gait Sequence Detection (Paraschiv-Ionescu)","text":"<p>The Gait Sequence Detection module is based on the Paraschiv-Ionescu algorithm, which aims to identify gait sequences from motion data. Specifically, it uses 3D accelerometer data from lower back IMU sensors to detect these gait sequences.</p>"},{"location":"modules/#initial-contact-detection-paraschiv-ionescu","title":"Initial Contact Detection (Paraschiv-Ionescu)","text":"<p>The Initial Contact Detection module is also based on the Paraschiv-Ionescu algorithm and is designed to identify the initial contact in each gait sequence. The outputs of this module are essential for accurately measuring temporal gait parameters, such as stride time and gait symmetry.</p>"},{"location":"modules/#physical-activity-monitoring","title":"Physical Activity Monitoring","text":"<p>The Physical Activity Monitoring module tracks and analyzes physical activity levels using 3D acceleration data from IMU sensors. It provides outputs such as activity intensity and duration, enabling a comprehensive assessment of an individual's movement behavior throughout the day.</p>"},{"location":"modules/#postural-transition-detection-pham","title":"Postural Transition Detection (Pham)","text":"<p>The Postural Transition Detection module is based on the work of Pham and aims to identify and analyze postural transitions, such as sit-to-stand or stand-to-sit movements. The module detects these transitions using 3D acceleration and 3D angular velocity data from lower back IMU sensors. It also calculates key spatial-temporal parameters, such as the angle of postural transition and maximum flexion velocity.</p>"},{"location":"modules/#turn-detection-pham","title":"Turn Detection (Pham)","text":"<p>The Turn Detection module is based on the work of Pham and aims to identify and characterize body turns using 3D acceleration and angular velocity data from lower back IMU sensors. The module also calculates key spatial-temporal parameters, such as the angle of turn and peak angular velocity.</p>"},{"location":"modules/gsd/","title":"Gait Sequence Detection","text":""},{"location":"modules/gsd/#gait-sequence-detection-paraschiv-ionescu","title":"Gait Sequence Detection (Paraschiv-Ionescu)","text":"<p>The Paraschiv-Ionescu gait sequence detection algorithm identifies gait sequences in accelerometer data from a lower back sensor.</p> <p>The algorithm detects gait sequences based on identified steps. It starts by loading the accelerometer data, which includes three columns corresponding to the acceleration signals across the x, y, and z axes, along with the sampling frequency of the data. To simplify the analysis, the norm of acceleration is computed. Next, the signal is resampled at a 40 Hz sampling frequency using interpolation. Smoothing is then applied through a Savitzky-Golay filter and a Finite Impulse Response (FIR) low-pass filter to remove noise and drifts from the signal. The continuous wavelet transform is applied to capture gait-related features, followed by additional smoothing using successive Gaussian-weighted filters. The processed data is then analyzed to detect gait sequences.</p> <p>The algorithm continues by identifying the envelope of the processed acceleration signal. Active periods of the signal are identified using the Hilbert envelope. The statistical distribution of the amplitude of the peaks in these active periods is used to derive an adaptive threshold. In case the Hilbert envelope algorithm fails to detect active periods, a fixed threshold value (0.15 g) is used for peak detection in the signal. Mid-swing peaks are detected based on this threshold. Pulse trains in the local maximum and minimum of the peaks are identified, with those having fewer than four steps filtered out. The intersection of pulse trains from local maximum and minimum peaks is detected as walking periods. These periods are then organized and grouped to update the start and end times of detected walking bouts.</p> <p>Next, the algorithm takes the last steps to detect walking bouts in the signal. For this purpose, walking bouts with five or more steps are detected, and their start and end times are added to the list. Walking labels are generated as an array of zeros, and the intervals corresponding to the walking bouts are labeled as 1. Groups of consecutive zeros in the walking labels are identified, and if breaks between walking bouts are less than three seconds, they are merged. If gait sequences are found, the output is printed; otherwise, a message indicating that no gait sequences are detected is displayed.</p> <p>Finally, the gait sequence information is stored in the 'gait_sequences_' attribute in BIDS compatible format with columns <code>onset</code>, <code>duration</code>, <code>event_type</code>, <code>tracking_system</code> as Pandas DataFrame.</p> <p>Methods:</p> Name Description <code>detect</code> <p>Detects gait sequences in the provided accelerometer data.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; gsd = ParaschivIonescuGaitSequenceDetection()\n&gt;&gt;&gt; gsd.detect(accel_data=acceleration_data, sampling_freq_Hz=100, plot_results=True)\n&gt;&gt;&gt; print(gsd.gait_sequences_)\n        onset   duration    event_type      tracking_systems\n    0   4.500   5.25        gait sequence   SU\n    1   90.225  10.30       gait sequence   SU\n</code></pre> References <p>[1] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer...</p> <p>[2] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using single trunk IMU...</p> Source code in <code>kielmat/modules/gsd/_paraschiv.py</code> <pre><code>class ParaschivIonescuGaitSequenceDetection:\n    \"\"\"\n    The Paraschiv-Ionescu gait sequence detection algorithm identifies gait sequences in accelerometer data from a lower back sensor.\n\n    The algorithm detects gait sequences based on identified steps. It starts by loading the accelerometer data, which includes three\n    columns corresponding to the acceleration signals across the x, y, and z axes, along with the sampling frequency of the data. To\n    simplify the analysis, the norm of acceleration is computed. Next, the signal is resampled at a 40 Hz sampling frequency using\n    interpolation. Smoothing is then applied through a Savitzky-Golay filter and a Finite Impulse Response (FIR) low-pass filter to\n    remove noise and drifts from the signal. The continuous wavelet transform is applied to capture gait-related features, followed by\n    additional smoothing using successive Gaussian-weighted filters. The processed data is then analyzed to detect gait sequences.\n\n    The algorithm continues by identifying the envelope of the processed acceleration signal. Active periods of the signal are identified\n    using the Hilbert envelope. The statistical distribution of the amplitude of the peaks in these active periods is used to derive an\n    adaptive threshold. In case the Hilbert envelope algorithm fails to detect active periods, a fixed threshold value (0.15 g) is used\n    for peak detection in the signal. Mid-swing peaks are detected based on this threshold. Pulse trains in the local maximum and minimum\n    of the peaks are identified, with those having fewer than four steps filtered out. The intersection of pulse trains from local maximum\n    and minimum peaks is detected as walking periods. These periods are then organized and grouped to update the start and end times of\n    detected walking bouts.\n\n    Next, the algorithm takes the last steps to detect walking bouts in the signal. For this purpose, walking bouts with five or more steps\n    are detected, and their start and end times are added to the list. Walking labels are generated as an array of zeros, and the intervals\n    corresponding to the walking bouts are labeled as 1. Groups of consecutive zeros in the walking labels are identified, and if breaks\n    between walking bouts are less than three seconds, they are merged. If gait sequences are found, the output is printed; otherwise, a\n    message indicating that no gait sequences are detected is displayed.\n\n    Finally, the gait sequence information is stored in the 'gait_sequences_' attribute in BIDS compatible format with columns `onset`,\n    `duration`, `event_type`, `tracking_system` as Pandas DataFrame.\n\n    Methods:\n        detect(accel_data, sampling_freq_Hz, plot_results=False):\n            Detects gait sequences in the provided accelerometer data.\n\n    Examples:\n        &gt;&gt;&gt; gsd = ParaschivIonescuGaitSequenceDetection()\n        &gt;&gt;&gt; gsd.detect(accel_data=acceleration_data, sampling_freq_Hz=100, plot_results=True)\n        &gt;&gt;&gt; print(gsd.gait_sequences_)\n                onset   duration    event_type      tracking_systems\n            0   4.500   5.25        gait sequence   SU\n            1   90.225  10.30       gait sequence   SU\n\n    References:\n        [1] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer...\n\n        [2] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using single trunk IMU...\n    \"\"\"\n\n    def __init__(\n        self,\n    ):\n        \"\"\"\n        Initializes the ParaschivIonescuGaitSequenceDetection instance.\n        \"\"\"\n        self.gait_sequences_ = None\n\n    def detect(\n        self,\n        accel_data: pd.DataFrame,\n        sampling_freq_Hz: float,\n        plot_results: bool = False,\n        dt_data: Optional[pd.Series] = None,\n        tracking_system: Optional[str] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Detects gait sequences based on the input accelerometer data.\n\n        Args:\n            accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n            sampling_freq_Hz (float): Sampling frequency of the accelerometer data.\n            plot_results (bool, optional): If True, generates a plot showing the pre-processed acceleration data\n                and the detected gait sequences. Default is False.\n            dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n            tracking_system (str, optional): Tracking system the data is from to be used for events df. Default is None.\n\n        Returns:\n            pd.DataFrame: The gait sequence information stored in the 'gait_sequences_' attribute,\n                which is a pandas DataFrame in BIDS format with the following columns:\n                    - onset: Start time of the gait sequence.\n                    - duration: Duration of the gait sequence.\n                    - event_type: Type of the event (default is 'gait sequence').\n                    - tracking_system: Tracking systems used the events are derived from.\n        \"\"\"\n        # Error handling for invalid input data\n        if not isinstance(accel_data, pd.DataFrame) or accel_data.shape[1] != 3:\n            raise ValueError(\n                \"Input accelerometer data must be a DataFrame with 3 columns for x, y, and z axes.\"\n            )\n\n        if not isinstance(sampling_freq_Hz, (int, float)) or sampling_freq_Hz &lt;= 0:\n            raise ValueError(\"Sampling frequency must be a positive float.\")\n\n        if not isinstance(plot_results, bool):\n            raise ValueError(\"Plot results must be a boolean (True or False).\")\n\n        # check if tracking_system is a string\n        if tracking_system is not None and not isinstance(tracking_system, str):\n            raise ValueError(\"tracking_system must be a string\")\n\n        # check if dt_data is a pandas Series with datetime values\n        if dt_data is not None and (\n            not isinstance(dt_data, pd.Series)\n            or not pd.api.types.is_datetime64_any_dtype(dt_data)\n        ):\n            raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n        # check if dt_data is provided and if it is a series with the same length as data\n        if dt_data is not None and len(dt_data) != len(accel_data):\n            raise ValueError(\"dt_data must be a series with the same length as data\")\n\n        # Convert acceleration data from \"m/s^2\" to \"g\"\n        accel_data /= 9.81\n\n        # Calculate the norm of acceleration\n        acceleration_norm = np.linalg.norm(accel_data, axis=1)\n\n        # Resample acceleration_norm to target sampling frequency\n        initial_sampling_frequency = sampling_freq_Hz\n        target_sampling_freq_Hz = 40\n        resampled_acceleration = preprocessing.resample_interpolate(\n            acceleration_norm, initial_sampling_frequency, target_sampling_freq_Hz\n        )\n\n        # Applying low-pass Savitzky-Golay filter to smoothen the resampled data\n        smoothed_acceleration = preprocessing.lowpass_filter(\n            resampled_acceleration,\n            method=\"savgol\",\n            window_length=21,\n            polynomial_order=7,\n        )\n\n        # Remove 40Hz drift from the filtered data\n        drift_removed_acceleration = preprocessing.highpass_filter(\n            signal=smoothed_acceleration,\n            sampling_frequency=target_sampling_freq_Hz,\n            method=\"iir\",\n        )\n\n        # Filter data using the fir low-pass filter\n        filtered_acceleration = preprocessing.lowpass_filter(\n            drift_removed_acceleration, method=\"fir\"\n        )\n\n        # Perform the continuous wavelet transform on the filtered acceleration data\n        wavelet_transform_result = preprocessing.apply_continuous_wavelet_transform(\n            filtered_acceleration,\n            scales=10,\n            desired_scale=10,\n            wavelet=\"gaus2\",\n            sampling_frequency=target_sampling_freq_Hz,\n        )\n\n        # Applying Savitzky-Golay filter to further smoothen the wavelet transformed data\n        smoothed_wavelet_result = preprocessing.lowpass_filter(\n            wavelet_transform_result, window_length=11, polynomial_order=5\n        )\n\n        # Perform continuous wavelet transform\n        further_smoothed_wavelet_result = (\n            preprocessing.apply_continuous_wavelet_transform(\n                smoothed_wavelet_result,\n                scales=10,\n                desired_scale=10,\n                wavelet=\"gaus2\",\n                sampling_frequency=target_sampling_freq_Hz,\n            )\n        )\n        further_smoothed_wavelet_result = further_smoothed_wavelet_result.T\n\n        # Smoothing the data using successive Gaussian filters\n        filtered_signal = preprocessing.apply_successive_gaussian_filters(\n            further_smoothed_wavelet_result\n        )\n\n        # Use pre-processsed signal for post-processing purposes\n        detected_activity_signal = filtered_signal\n\n        # Compute the envelope of the processed acceleration data\n        envelope, _ = preprocessing.calculate_envelope_activity(\n            detected_activity_signal,\n            int(round(target_sampling_freq_Hz)),\n            1,\n            int(round(target_sampling_freq_Hz)),\n        )\n\n        # Initialize a list for walking bouts\n        walking_bouts = [0]\n\n        # Process alarm data to identify walking bouts\n        if envelope.size &gt; 0:\n            index_ranges = preprocessing.find_consecutive_groups(envelope &gt; 0)\n            for j in range(len(index_ranges)):\n                if (\n                    index_ranges[j, 1] - index_ranges[j, 0]\n                    &lt;= 3 * target_sampling_freq_Hz\n                ):\n                    envelope[index_ranges[j, 0] : index_ranges[j, 1] + 1] = 0\n                else:\n                    walking_bouts.extend(\n                        detected_activity_signal[\n                            index_ranges[j, 0] : index_ranges[j, 1] + 1\n                        ]\n                    )\n\n            # Convert walk_low_back list to a NumPy array\n            walking_bouts_array = np.array(walking_bouts)\n\n            # Find positive peaks in the walk_low_back_array\n            positive_peak_indices, _ = scipy.signal.find_peaks(walking_bouts_array)\n\n            # Get the corresponding y-axis data values for the positive peak\n            positive_peaks = walking_bouts_array[positive_peak_indices]\n\n            # Find negative peaks in the inverted walk_low_back array\n            negative_peak_indices, _ = scipy.signal.find_peaks(-walking_bouts_array)\n\n            # Get the corresponding y-axis data values for the positive peak\n            negative_peaks = -walking_bouts_array[negative_peak_indices]\n\n            # Combine positive and negative peaks\n            combined_peaks = [x for x in positive_peaks if x &gt; 0] + [\n                x for x in negative_peaks if x &gt; 0\n            ]\n\n            # Calculate the data adaptive threshold using the 5th percentile of the combined peaks\n            try:\n                threshold = np.percentile(combined_peaks, 5)\n\n            except IndexError:\n                # If combined_peaks is empty, set threshold to default value\n                threshold = 0.15\n                selected_signal = smoothed_wavelet_result\n\n            # Set selected_signal to detected_activity_signal\n            selected_signal = detected_activity_signal\n\n        # Detect mid-swing peaks\n        min_peaks, max_peaks = preprocessing.find_local_min_max(\n            selected_signal, threshold\n        )\n\n        # Find pulse trains in max_peaks and remove ones with steps less than 4\n        pulse_trains_max = preprocessing.identify_pulse_trains(max_peaks)\n\n        # Access the fields of the struct-like array\n        pulse_trains_max = [train for train in pulse_trains_max if train[\"steps\"] &gt;= 4]\n\n        # Find pulse trains in min_peaks and remove ones with steps less than 4\n        pulse_trains_min = preprocessing.identify_pulse_trains(min_peaks)\n\n        # Access the fields of the struct-like array\n        pulse_trains_min = [train for train in pulse_trains_min if train[\"steps\"] &gt;= 4]\n\n        # Convert t1 and t2 to sets and find their intersection\n        walking_periods = preprocessing.find_interval_intersection(\n            preprocessing.convert_pulse_train_to_array(pulse_trains_max),\n            preprocessing.convert_pulse_train_to_array(pulse_trains_min),\n        )\n\n        # Check if walking_periods is empty\n        if walking_periods is None:\n            walking_bouts = []\n\n        else:\n            # Call the organize_and_pack_results function with walking_periods and MaxPeaks\n            walking_bouts, _ = preprocessing.organize_and_pack_results(\n                walking_periods, max_peaks\n            )\n            if walking_bouts:\n                # Update the start value of the first element\n                walking_bouts[0][\"start\"] = max([1, walking_bouts[0][\"start\"]])\n\n                # Update the end value of the last element\n                walking_bouts[-1][\"end\"] = min(\n                    [walking_bouts[-1][\"end\"], len(detected_activity_signal)]\n                )\n\n        # Calculate the length of walking bouts\n        walking_bouts_length = len(walking_bouts)\n\n        # Initialize an empty list for filtered walking bouts\n        filtered_walking_bouts = []\n\n        # Initialize a counter variable to count walking bouts\n        counter = 0\n\n        # Iterate through walking bouts to filter those with steps less than 5\n        for j in range(walking_bouts_length):\n            if walking_bouts[j][\"steps\"] &gt;= 5:\n                counter += 1\n                filtered_walking_bouts.append(\n                    {\"start\": walking_bouts[j][\"start\"], \"end\": walking_bouts[j][\"end\"]}\n                )\n\n        # If no walking bouts are detected, print a message\n        if counter == 0:\n            print(\"No gait sequences detected due to insufficient steps in the data.\")\n            return self\n\n        # Initialize an array of zeros with the length of detected_activity_signal\n        walking_labels = np.zeros(len(detected_activity_signal))\n\n        # Calculate the length of the filtered_walking_bouts\n        filtered_walking_bouts_length = len(filtered_walking_bouts)\n\n        for j in range(filtered_walking_bouts_length):\n            walking_labels[\n                filtered_walking_bouts[j][\"start\"] : filtered_walking_bouts[j][\"end\"]\n                + 1\n            ] = 1\n\n        # Call the find_consecutive_groups function with the walking_labels variable\n        ind_noWk = []\n        ind_noWk = preprocessing.find_consecutive_groups(walking_labels == 0)\n\n        # Merge walking bouts if break less than 3 seconds\n        if ind_noWk.size &gt; 0:\n            for j in range(len(ind_noWk)):\n                if ind_noWk[j, 1] - ind_noWk[j, 0] &lt;= target_sampling_freq_Hz * 3:\n                    walking_labels[ind_noWk[j, 0] : ind_noWk[j, 1] + 1] = 1\n\n        # Merge walking bouts if break less than 3 seconds\n        ind_Wk = []\n        walkLabel_1_indices = np.where(walking_labels == 1)[0]\n        GSD_Output = []\n\n        if walkLabel_1_indices.size &gt; 0:\n            ind_Wk = preprocessing.find_consecutive_groups(walking_labels == 1)\n            # Create an empty list to store 'walk' dictionaries\n            walk = []\n            if ind_Wk.size &gt; 0:\n                for j in range(len(ind_Wk)):\n                    walk.append({\"start\": (ind_Wk[j, 0]), \"end\": ind_Wk[j, 1]})\n\n            n = len(walk)\n\n            for j in range(n):\n                GSD_Output.append(\n                    {\n                        \"Start\": walk[j][\"start\"] / target_sampling_freq_Hz,\n                        \"End\": walk[j][\"end\"] / target_sampling_freq_Hz,\n                        \"fs\": sampling_freq_Hz,\n                    }\n                )\n            print(f\"{n} gait sequence(s) detected.\")\n        else:\n            print(\"No gait sequence(s) detected.\")\n\n        # Create a DataFrame from the gait sequence data\n        gait_sequences_ = pd.DataFrame(GSD_Output)\n        gait_sequences_[\"onset\"] = gait_sequences_[\"Start\"]\n        gait_sequences_[\"duration\"] = gait_sequences_[\"End\"] - gait_sequences_[\"Start\"]\n        gait_sequences_[\"event_type\"] = \"gait sequence\"\n        gait_sequences_[\"tracking_system\"] = tracking_system\n\n        # Check if the indices in ind_Wk are within the range of dt_data's index\n        if ind_Wk.size &gt; 0 and dt_data is not None:\n            valid_indices = [index for index in ind_Wk[:, 0] if index &lt; len(dt_data)]\n            invalid_indices = len(ind_Wk[:, 0]) - len(valid_indices)\n\n            if invalid_indices &gt; 0:\n                print(f\"Warning: {invalid_indices} invalid index/indices found.\")\n\n            # Only use valid indices to access dt_data\n            valid_dt_data = dt_data.iloc[valid_indices]\n\n            # Create a DataFrame from the gait sequence data\n            gait_sequences_ = pd.DataFrame(GSD_Output)\n            gait_sequences_[\"onset\"] = gait_sequences_[\"Start\"]\n            gait_sequences_[\"duration\"] = (\n                gait_sequences_[\"End\"] - gait_sequences_[\"Start\"]\n            )\n            gait_sequences_[\"event_type\"] = \"gait sequence\"\n            gait_sequences_[\"tracking_system\"] = tracking_system\n\n            # If original datetime is available, update the 'onset' column\n            gait_sequences_[\"onset\"] = valid_dt_data.reset_index(drop=True)\n\n        # Create a DataFrame from the gait sequence data\n        gait_sequences_ = gait_sequences_[\n            [\"onset\", \"duration\", \"event_type\", \"tracking_system\"]\n        ]\n\n        # Return gait_sequences_ as an output\n        self.gait_sequences_ = gait_sequences_\n\n        # If Plot_results set to true\n        # currently no plotting for datetime values\n        if dt_data is not None and plot_results:\n            print(\"No plotting for datetime values.\")\n            plot_results = False\n            return self\n\n        # Plot results if set to true\n        if plot_results:\n            # Convert detected_activity_signal from g back to m/s^2 for consistency\n            detected_activity_signal *= 9.81\n\n            viz_utils.plot_gait(\n                target_sampling_freq_Hz, detected_activity_signal, gait_sequences_\n            )\n\n        return self\n</code></pre>"},{"location":"modules/gsd/#modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the ParaschivIonescuGaitSequenceDetection instance.</p> Source code in <code>kielmat/modules/gsd/_paraschiv.py</code> <pre><code>def __init__(\n    self,\n):\n    \"\"\"\n    Initializes the ParaschivIonescuGaitSequenceDetection instance.\n    \"\"\"\n    self.gait_sequences_ = None\n</code></pre>"},{"location":"modules/gsd/#modules.gsd._paraschiv.ParaschivIonescuGaitSequenceDetection.detect","title":"<code>detect(accel_data, sampling_freq_Hz, plot_results=False, dt_data=None, tracking_system=None)</code>","text":"<p>Detects gait sequences based on the input accelerometer data.</p> <p>Parameters:</p> Name Type Description Default <code>accel_data</code> <code>DataFrame</code> <p>Input accelerometer data (N, 3) for x, y, and z axes.</p> required <code>sampling_freq_Hz</code> <code>float</code> <p>Sampling frequency of the accelerometer data.</p> required <code>plot_results</code> <code>bool</code> <p>If True, generates a plot showing the pre-processed acceleration data and the detected gait sequences. Default is False.</p> <code>False</code> <code>dt_data</code> <code>Series</code> <p>Original datetime in the input data. If original datetime is provided, the output onset will be based on that.</p> <code>None</code> <code>tracking_system</code> <code>str</code> <p>Tracking system the data is from to be used for events df. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The gait sequence information stored in the 'gait_sequences_' attribute, which is a pandas DataFrame in BIDS format with the following columns:     - onset: Start time of the gait sequence.     - duration: Duration of the gait sequence.     - event_type: Type of the event (default is 'gait sequence').     - tracking_system: Tracking systems used the events are derived from.</p> Source code in <code>kielmat/modules/gsd/_paraschiv.py</code> <pre><code>def detect(\n    self,\n    accel_data: pd.DataFrame,\n    sampling_freq_Hz: float,\n    plot_results: bool = False,\n    dt_data: Optional[pd.Series] = None,\n    tracking_system: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects gait sequences based on the input accelerometer data.\n\n    Args:\n        accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n        sampling_freq_Hz (float): Sampling frequency of the accelerometer data.\n        plot_results (bool, optional): If True, generates a plot showing the pre-processed acceleration data\n            and the detected gait sequences. Default is False.\n        dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n        tracking_system (str, optional): Tracking system the data is from to be used for events df. Default is None.\n\n    Returns:\n        pd.DataFrame: The gait sequence information stored in the 'gait_sequences_' attribute,\n            which is a pandas DataFrame in BIDS format with the following columns:\n                - onset: Start time of the gait sequence.\n                - duration: Duration of the gait sequence.\n                - event_type: Type of the event (default is 'gait sequence').\n                - tracking_system: Tracking systems used the events are derived from.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(accel_data, pd.DataFrame) or accel_data.shape[1] != 3:\n        raise ValueError(\n            \"Input accelerometer data must be a DataFrame with 3 columns for x, y, and z axes.\"\n        )\n\n    if not isinstance(sampling_freq_Hz, (int, float)) or sampling_freq_Hz &lt;= 0:\n        raise ValueError(\"Sampling frequency must be a positive float.\")\n\n    if not isinstance(plot_results, bool):\n        raise ValueError(\"Plot results must be a boolean (True or False).\")\n\n    # check if tracking_system is a string\n    if tracking_system is not None and not isinstance(tracking_system, str):\n        raise ValueError(\"tracking_system must be a string\")\n\n    # check if dt_data is a pandas Series with datetime values\n    if dt_data is not None and (\n        not isinstance(dt_data, pd.Series)\n        or not pd.api.types.is_datetime64_any_dtype(dt_data)\n    ):\n        raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n    # check if dt_data is provided and if it is a series with the same length as data\n    if dt_data is not None and len(dt_data) != len(accel_data):\n        raise ValueError(\"dt_data must be a series with the same length as data\")\n\n    # Convert acceleration data from \"m/s^2\" to \"g\"\n    accel_data /= 9.81\n\n    # Calculate the norm of acceleration\n    acceleration_norm = np.linalg.norm(accel_data, axis=1)\n\n    # Resample acceleration_norm to target sampling frequency\n    initial_sampling_frequency = sampling_freq_Hz\n    target_sampling_freq_Hz = 40\n    resampled_acceleration = preprocessing.resample_interpolate(\n        acceleration_norm, initial_sampling_frequency, target_sampling_freq_Hz\n    )\n\n    # Applying low-pass Savitzky-Golay filter to smoothen the resampled data\n    smoothed_acceleration = preprocessing.lowpass_filter(\n        resampled_acceleration,\n        method=\"savgol\",\n        window_length=21,\n        polynomial_order=7,\n    )\n\n    # Remove 40Hz drift from the filtered data\n    drift_removed_acceleration = preprocessing.highpass_filter(\n        signal=smoothed_acceleration,\n        sampling_frequency=target_sampling_freq_Hz,\n        method=\"iir\",\n    )\n\n    # Filter data using the fir low-pass filter\n    filtered_acceleration = preprocessing.lowpass_filter(\n        drift_removed_acceleration, method=\"fir\"\n    )\n\n    # Perform the continuous wavelet transform on the filtered acceleration data\n    wavelet_transform_result = preprocessing.apply_continuous_wavelet_transform(\n        filtered_acceleration,\n        scales=10,\n        desired_scale=10,\n        wavelet=\"gaus2\",\n        sampling_frequency=target_sampling_freq_Hz,\n    )\n\n    # Applying Savitzky-Golay filter to further smoothen the wavelet transformed data\n    smoothed_wavelet_result = preprocessing.lowpass_filter(\n        wavelet_transform_result, window_length=11, polynomial_order=5\n    )\n\n    # Perform continuous wavelet transform\n    further_smoothed_wavelet_result = (\n        preprocessing.apply_continuous_wavelet_transform(\n            smoothed_wavelet_result,\n            scales=10,\n            desired_scale=10,\n            wavelet=\"gaus2\",\n            sampling_frequency=target_sampling_freq_Hz,\n        )\n    )\n    further_smoothed_wavelet_result = further_smoothed_wavelet_result.T\n\n    # Smoothing the data using successive Gaussian filters\n    filtered_signal = preprocessing.apply_successive_gaussian_filters(\n        further_smoothed_wavelet_result\n    )\n\n    # Use pre-processsed signal for post-processing purposes\n    detected_activity_signal = filtered_signal\n\n    # Compute the envelope of the processed acceleration data\n    envelope, _ = preprocessing.calculate_envelope_activity(\n        detected_activity_signal,\n        int(round(target_sampling_freq_Hz)),\n        1,\n        int(round(target_sampling_freq_Hz)),\n    )\n\n    # Initialize a list for walking bouts\n    walking_bouts = [0]\n\n    # Process alarm data to identify walking bouts\n    if envelope.size &gt; 0:\n        index_ranges = preprocessing.find_consecutive_groups(envelope &gt; 0)\n        for j in range(len(index_ranges)):\n            if (\n                index_ranges[j, 1] - index_ranges[j, 0]\n                &lt;= 3 * target_sampling_freq_Hz\n            ):\n                envelope[index_ranges[j, 0] : index_ranges[j, 1] + 1] = 0\n            else:\n                walking_bouts.extend(\n                    detected_activity_signal[\n                        index_ranges[j, 0] : index_ranges[j, 1] + 1\n                    ]\n                )\n\n        # Convert walk_low_back list to a NumPy array\n        walking_bouts_array = np.array(walking_bouts)\n\n        # Find positive peaks in the walk_low_back_array\n        positive_peak_indices, _ = scipy.signal.find_peaks(walking_bouts_array)\n\n        # Get the corresponding y-axis data values for the positive peak\n        positive_peaks = walking_bouts_array[positive_peak_indices]\n\n        # Find negative peaks in the inverted walk_low_back array\n        negative_peak_indices, _ = scipy.signal.find_peaks(-walking_bouts_array)\n\n        # Get the corresponding y-axis data values for the positive peak\n        negative_peaks = -walking_bouts_array[negative_peak_indices]\n\n        # Combine positive and negative peaks\n        combined_peaks = [x for x in positive_peaks if x &gt; 0] + [\n            x for x in negative_peaks if x &gt; 0\n        ]\n\n        # Calculate the data adaptive threshold using the 5th percentile of the combined peaks\n        try:\n            threshold = np.percentile(combined_peaks, 5)\n\n        except IndexError:\n            # If combined_peaks is empty, set threshold to default value\n            threshold = 0.15\n            selected_signal = smoothed_wavelet_result\n\n        # Set selected_signal to detected_activity_signal\n        selected_signal = detected_activity_signal\n\n    # Detect mid-swing peaks\n    min_peaks, max_peaks = preprocessing.find_local_min_max(\n        selected_signal, threshold\n    )\n\n    # Find pulse trains in max_peaks and remove ones with steps less than 4\n    pulse_trains_max = preprocessing.identify_pulse_trains(max_peaks)\n\n    # Access the fields of the struct-like array\n    pulse_trains_max = [train for train in pulse_trains_max if train[\"steps\"] &gt;= 4]\n\n    # Find pulse trains in min_peaks and remove ones with steps less than 4\n    pulse_trains_min = preprocessing.identify_pulse_trains(min_peaks)\n\n    # Access the fields of the struct-like array\n    pulse_trains_min = [train for train in pulse_trains_min if train[\"steps\"] &gt;= 4]\n\n    # Convert t1 and t2 to sets and find their intersection\n    walking_periods = preprocessing.find_interval_intersection(\n        preprocessing.convert_pulse_train_to_array(pulse_trains_max),\n        preprocessing.convert_pulse_train_to_array(pulse_trains_min),\n    )\n\n    # Check if walking_periods is empty\n    if walking_periods is None:\n        walking_bouts = []\n\n    else:\n        # Call the organize_and_pack_results function with walking_periods and MaxPeaks\n        walking_bouts, _ = preprocessing.organize_and_pack_results(\n            walking_periods, max_peaks\n        )\n        if walking_bouts:\n            # Update the start value of the first element\n            walking_bouts[0][\"start\"] = max([1, walking_bouts[0][\"start\"]])\n\n            # Update the end value of the last element\n            walking_bouts[-1][\"end\"] = min(\n                [walking_bouts[-1][\"end\"], len(detected_activity_signal)]\n            )\n\n    # Calculate the length of walking bouts\n    walking_bouts_length = len(walking_bouts)\n\n    # Initialize an empty list for filtered walking bouts\n    filtered_walking_bouts = []\n\n    # Initialize a counter variable to count walking bouts\n    counter = 0\n\n    # Iterate through walking bouts to filter those with steps less than 5\n    for j in range(walking_bouts_length):\n        if walking_bouts[j][\"steps\"] &gt;= 5:\n            counter += 1\n            filtered_walking_bouts.append(\n                {\"start\": walking_bouts[j][\"start\"], \"end\": walking_bouts[j][\"end\"]}\n            )\n\n    # If no walking bouts are detected, print a message\n    if counter == 0:\n        print(\"No gait sequences detected due to insufficient steps in the data.\")\n        return self\n\n    # Initialize an array of zeros with the length of detected_activity_signal\n    walking_labels = np.zeros(len(detected_activity_signal))\n\n    # Calculate the length of the filtered_walking_bouts\n    filtered_walking_bouts_length = len(filtered_walking_bouts)\n\n    for j in range(filtered_walking_bouts_length):\n        walking_labels[\n            filtered_walking_bouts[j][\"start\"] : filtered_walking_bouts[j][\"end\"]\n            + 1\n        ] = 1\n\n    # Call the find_consecutive_groups function with the walking_labels variable\n    ind_noWk = []\n    ind_noWk = preprocessing.find_consecutive_groups(walking_labels == 0)\n\n    # Merge walking bouts if break less than 3 seconds\n    if ind_noWk.size &gt; 0:\n        for j in range(len(ind_noWk)):\n            if ind_noWk[j, 1] - ind_noWk[j, 0] &lt;= target_sampling_freq_Hz * 3:\n                walking_labels[ind_noWk[j, 0] : ind_noWk[j, 1] + 1] = 1\n\n    # Merge walking bouts if break less than 3 seconds\n    ind_Wk = []\n    walkLabel_1_indices = np.where(walking_labels == 1)[0]\n    GSD_Output = []\n\n    if walkLabel_1_indices.size &gt; 0:\n        ind_Wk = preprocessing.find_consecutive_groups(walking_labels == 1)\n        # Create an empty list to store 'walk' dictionaries\n        walk = []\n        if ind_Wk.size &gt; 0:\n            for j in range(len(ind_Wk)):\n                walk.append({\"start\": (ind_Wk[j, 0]), \"end\": ind_Wk[j, 1]})\n\n        n = len(walk)\n\n        for j in range(n):\n            GSD_Output.append(\n                {\n                    \"Start\": walk[j][\"start\"] / target_sampling_freq_Hz,\n                    \"End\": walk[j][\"end\"] / target_sampling_freq_Hz,\n                    \"fs\": sampling_freq_Hz,\n                }\n            )\n        print(f\"{n} gait sequence(s) detected.\")\n    else:\n        print(\"No gait sequence(s) detected.\")\n\n    # Create a DataFrame from the gait sequence data\n    gait_sequences_ = pd.DataFrame(GSD_Output)\n    gait_sequences_[\"onset\"] = gait_sequences_[\"Start\"]\n    gait_sequences_[\"duration\"] = gait_sequences_[\"End\"] - gait_sequences_[\"Start\"]\n    gait_sequences_[\"event_type\"] = \"gait sequence\"\n    gait_sequences_[\"tracking_system\"] = tracking_system\n\n    # Check if the indices in ind_Wk are within the range of dt_data's index\n    if ind_Wk.size &gt; 0 and dt_data is not None:\n        valid_indices = [index for index in ind_Wk[:, 0] if index &lt; len(dt_data)]\n        invalid_indices = len(ind_Wk[:, 0]) - len(valid_indices)\n\n        if invalid_indices &gt; 0:\n            print(f\"Warning: {invalid_indices} invalid index/indices found.\")\n\n        # Only use valid indices to access dt_data\n        valid_dt_data = dt_data.iloc[valid_indices]\n\n        # Create a DataFrame from the gait sequence data\n        gait_sequences_ = pd.DataFrame(GSD_Output)\n        gait_sequences_[\"onset\"] = gait_sequences_[\"Start\"]\n        gait_sequences_[\"duration\"] = (\n            gait_sequences_[\"End\"] - gait_sequences_[\"Start\"]\n        )\n        gait_sequences_[\"event_type\"] = \"gait sequence\"\n        gait_sequences_[\"tracking_system\"] = tracking_system\n\n        # If original datetime is available, update the 'onset' column\n        gait_sequences_[\"onset\"] = valid_dt_data.reset_index(drop=True)\n\n    # Create a DataFrame from the gait sequence data\n    gait_sequences_ = gait_sequences_[\n        [\"onset\", \"duration\", \"event_type\", \"tracking_system\"]\n    ]\n\n    # Return gait_sequences_ as an output\n    self.gait_sequences_ = gait_sequences_\n\n    # If Plot_results set to true\n    # currently no plotting for datetime values\n    if dt_data is not None and plot_results:\n        print(\"No plotting for datetime values.\")\n        plot_results = False\n        return self\n\n    # Plot results if set to true\n    if plot_results:\n        # Convert detected_activity_signal from g back to m/s^2 for consistency\n        detected_activity_signal *= 9.81\n\n        viz_utils.plot_gait(\n            target_sampling_freq_Hz, detected_activity_signal, gait_sequences_\n        )\n\n    return self\n</code></pre>"},{"location":"modules/icd/","title":"Initial Contact Detection","text":""},{"location":"modules/icd/#initial-contact-detection-paraschiv-ionescu","title":"Initial Contact Detection (Paraschiv-Ionescu)","text":"<p>This Paraschiv-Ionescu initial contact detection algorithm identifies initial contact in accelerometer data collected from a low back IMU sensor. The purpose of algorithm is to identify and characterize initial contacts within walking bouts.</p> <p>The algorithm takes accelerometer data as input, and the vertical acceleration component, and processes each specified gait sequence independently. The signal is first detrended and then low-pass filtered. The resulting signal is numerically integrated and differentiated using a Gaussian continuous wavelet transformation. The initial contact (IC) events are identified as the positive maximal peaks between successive zero-crossings.</p> <p>Finally, initial contacts information is provided as a DataFrame with columns <code>onset</code>, <code>event_type</code>, and <code>tracking_systems</code>.</p> <p>Methods:</p> Name Description <code>detect</code> <p>Detects initial contacts on the accelerometer signal.</p> <p>Examples:</p> <p>Find initial contacts based on the detected gait sequence</p> <pre><code>&gt;&gt;&gt; icd = ParaschivIonescuInitialContactDetection()\n&gt;&gt;&gt; icd = icd.detect(accel_data=acceleration_data, sampling_freq_Hz=100)\n&gt;&gt;&gt; print(icd.initial_contacts_)\n        onset   event_type       duration   tracking_systems\n    0   5       initial contact  0          SU\n    1   5.6     initial contact  0          SU\n</code></pre> References <p>[1] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer...</p> <p>[2] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using single trunk IMU: methodological challenges...</p> Source code in <code>kielmat/modules/icd/_paraschiv.py</code> <pre><code>class ParaschivIonescuInitialContactDetection:\n    \"\"\"\n    This Paraschiv-Ionescu initial contact detection algorithm identifies initial contact in accelerometer data\n    collected from a low back IMU sensor. The purpose of algorithm is to identify and characterize initial contacts\n    within walking bouts.\n\n    The algorithm takes accelerometer data as input, and the vertical acceleration component, and processes each\n    specified gait sequence independently. The signal is first detrended and then low-pass filtered. The resulting\n    signal is numerically integrated and differentiated using a Gaussian continuous wavelet transformation. The\n    initial contact (IC) events are identified as the positive maximal peaks between successive zero-crossings.\n\n    Finally, initial contacts information is provided as a DataFrame with columns `onset`, `event_type`, and\n    `tracking_systems`.\n\n    Methods:\n        detect(accel_data, gait_sequences, sampling_freq_Hz):\n            Detects initial contacts on the accelerometer signal.\n\n    Examples:\n        Find initial contacts based on the detected gait sequence\n\n        &gt;&gt;&gt; icd = ParaschivIonescuInitialContactDetection()\n        &gt;&gt;&gt; icd = icd.detect(accel_data=acceleration_data, sampling_freq_Hz=100)\n        &gt;&gt;&gt; print(icd.initial_contacts_)\n                onset   event_type       duration   tracking_systems\n            0   5       initial contact  0          SU\n            1   5.6     initial contact  0          SU\n\n    References:\n        [1] Paraschiv-Ionescu et al. (2019). Locomotion and cadence detection using a single trunk-fixed accelerometer...\n\n        [2] Paraschiv-Ionescu et al. (2020). Real-world speed estimation using single trunk IMU: methodological challenges...\n    \"\"\"\n\n    def __init__(\n        self,\n    ):\n        \"\"\"\n        Initializes the ParaschivIonescuInitialContactDetection instance.\n        \"\"\"\n        self.initial_contacts_ = None\n\n    def detect(\n        self,\n        accel_data: pd.DataFrame,\n        sampling_freq_Hz: float,\n        v_acc_col_name: str,\n        gait_sequences: Optional[pd.DataFrame] = None,\n        dt_data: Optional[pd.Series] = None,\n        tracking_system: Optional[str] = None,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Detects initial contacts based on the input accelerometer data.\n\n        Args:\n            accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n            sampling_freq_Hz (float): Sampling frequency of the accelerometer data.\n            v_acc_col_name (str): The column name that corresponds to the vertical acceleration.\n            gait_sequences (pd.DataFrame, optional): A dataframe of detected gait sequences. If not provided, the entire acceleration time series will be used for detecting initial contacts.\n            dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n            tracking_system (str, optional): Tracking system the data is from to be used for events df. Default is None.\n\n        Returns:\n            ParaschivIonescuInitialContactDetection: Returns an instance of the class.\n                The initial contacts information is stored in the 'initial_contacts_' attribute,\n                which is a pandas DataFrame in BIDS format with the following columns:\n                    - onset: Initial contacts.\n                    - event_type: Type of the event (default is 'Inital contact').\n                    - tracking_system: Tracking systems used the events are derived from.\n        \"\"\"\n        # Check if data is empty\n        if accel_data.empty:\n            self.initial_contacts_ = pd.DataFrame()\n            return self  # Return without performing further processing\n\n        # check if dt_data is a pandas Series with datetime values\n        if dt_data is not None and (\n            not isinstance(dt_data, pd.Series)\n            or not pd.api.types.is_datetime64_any_dtype(dt_data)\n        ):\n            raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n        # check if tracking_system is a string\n        if tracking_system is not None and not isinstance(tracking_system, str):\n            raise ValueError(\"tracking_system must be a string\")\n\n        # check if dt_data is provided and if it is a series with the same length as data\n        if dt_data is not None and len(dt_data) != len(accel_data):\n            raise ValueError(\"dt_data must be a series with the same length as data\")\n\n        # Convert acceleration data from \"m/s^2\" to \"g\"\n        accel_data /= 9.81\n\n        # Extract vertical accelerometer data using the specified index\n        acc_vertical = accel_data[v_acc_col_name]\n\n        # Initialize an empty list to store the processed output\n        processed_output = []\n\n        # Initialize an empty list to store all onsets\n        all_onsets = []\n\n        # Process each gait sequence\n        if gait_sequences is None:\n            gait_sequences = pd.DataFrame(\n                {\"onset\": [0], \"duration\": [len(accel_data) / sampling_freq_Hz]}\n            )\n        for _, gait_seq in gait_sequences.iterrows():\n            # Calculate start and stop indices for the current gait sequence\n            start_index = int(sampling_freq_Hz * gait_seq[\"onset\"])\n            stop_index = int(\n                sampling_freq_Hz * (gait_seq[\"onset\"] + gait_seq[\"duration\"])\n            )\n            accv_gait_seq = acc_vertical[start_index:stop_index].to_numpy()\n\n            try:\n                # Perform Signal Decomposition Algorithm for Initial Contacts (ICs)\n                initial_contacts_rel, _ = preprocessing.signal_decomposition_algorithm(\n                    accv_gait_seq, sampling_freq_Hz\n                )\n                initial_contacts = gait_seq[\"onset\"] + initial_contacts_rel\n\n                gait_seq[\"IC\"] = initial_contacts.tolist()\n\n                # Append onsets to the all_onsets list\n                all_onsets.extend(initial_contacts)\n\n            except Exception as e:\n                print(\n                    \"Signal decomposition algorithm did not run successfully. Returning an empty vector of initial contacts\"\n                )\n                print(f\"Error: {e}\")\n                initial_contacts = []\n                gait_seq[\"IC\"] = []\n\n            # Append the information to the processed_output list\n            processed_output.append(gait_seq)\n\n        # Check if processed_output is not empty\n        if not processed_output:\n            print(\"No initial contacts detected.\")\n            return pd.DataFrame()\n\n        # Create a DataFrame from the processed_output list\n        initial_contacts_ = pd.DataFrame(processed_output)\n\n        # Create a BIDS-compatible DataFrame with all onsets\n        self.initial_contacts_ = pd.DataFrame(\n            {\n                \"onset\": all_onsets,\n                \"event_type\": \"initial contact\",\n                \"duration\": 0,\n                \"tracking_systems\": tracking_system,\n            }\n        )\n\n        # If original datetime is available, update the 'onset' column\n        if dt_data is not None:\n            valid_indices = [\n                index\n                for index in self.initial_contacts_[\"onset\"]\n                if index &lt; len(dt_data)\n            ]\n            invalid_indices = len(self.initial_contacts_[\"onset\"]) - len(valid_indices)\n\n            if invalid_indices &gt; 0:\n                print(f\"Warning: {invalid_indices} invalid index/indices found.\")\n\n            # Only use valid indices to access dt_data\n            valid_dt_data = dt_data.iloc[valid_indices]\n\n            # Update the 'onset' column\n            self.initial_contacts_[\"onset\"] = valid_dt_data.reset_index(drop=True)\n\n        return self\n</code></pre>"},{"location":"modules/icd/#modules.icd._paraschiv.ParaschivIonescuInitialContactDetection.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the ParaschivIonescuInitialContactDetection instance.</p> Source code in <code>kielmat/modules/icd/_paraschiv.py</code> <pre><code>def __init__(\n    self,\n):\n    \"\"\"\n    Initializes the ParaschivIonescuInitialContactDetection instance.\n    \"\"\"\n    self.initial_contacts_ = None\n</code></pre>"},{"location":"modules/icd/#modules.icd._paraschiv.ParaschivIonescuInitialContactDetection.detect","title":"<code>detect(accel_data, sampling_freq_Hz, v_acc_col_name, gait_sequences=None, dt_data=None, tracking_system=None)</code>","text":"<p>Detects initial contacts based on the input accelerometer data.</p> <p>Parameters:</p> Name Type Description Default <code>accel_data</code> <code>DataFrame</code> <p>Input accelerometer data (N, 3) for x, y, and z axes.</p> required <code>sampling_freq_Hz</code> <code>float</code> <p>Sampling frequency of the accelerometer data.</p> required <code>v_acc_col_name</code> <code>str</code> <p>The column name that corresponds to the vertical acceleration.</p> required <code>gait_sequences</code> <code>DataFrame</code> <p>A dataframe of detected gait sequences. If not provided, the entire acceleration time series will be used for detecting initial contacts.</p> <code>None</code> <code>dt_data</code> <code>Series</code> <p>Original datetime in the input data. If original datetime is provided, the output onset will be based on that.</p> <code>None</code> <code>tracking_system</code> <code>str</code> <p>Tracking system the data is from to be used for events df. Default is None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>ParaschivIonescuInitialContactDetection</code> <code>DataFrame</code> <p>Returns an instance of the class. The initial contacts information is stored in the 'initial_contacts_' attribute, which is a pandas DataFrame in BIDS format with the following columns:     - onset: Initial contacts.     - event_type: Type of the event (default is 'Inital contact').     - tracking_system: Tracking systems used the events are derived from.</p> Source code in <code>kielmat/modules/icd/_paraschiv.py</code> <pre><code>def detect(\n    self,\n    accel_data: pd.DataFrame,\n    sampling_freq_Hz: float,\n    v_acc_col_name: str,\n    gait_sequences: Optional[pd.DataFrame] = None,\n    dt_data: Optional[pd.Series] = None,\n    tracking_system: Optional[str] = None,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects initial contacts based on the input accelerometer data.\n\n    Args:\n        accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n        sampling_freq_Hz (float): Sampling frequency of the accelerometer data.\n        v_acc_col_name (str): The column name that corresponds to the vertical acceleration.\n        gait_sequences (pd.DataFrame, optional): A dataframe of detected gait sequences. If not provided, the entire acceleration time series will be used for detecting initial contacts.\n        dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n        tracking_system (str, optional): Tracking system the data is from to be used for events df. Default is None.\n\n    Returns:\n        ParaschivIonescuInitialContactDetection: Returns an instance of the class.\n            The initial contacts information is stored in the 'initial_contacts_' attribute,\n            which is a pandas DataFrame in BIDS format with the following columns:\n                - onset: Initial contacts.\n                - event_type: Type of the event (default is 'Inital contact').\n                - tracking_system: Tracking systems used the events are derived from.\n    \"\"\"\n    # Check if data is empty\n    if accel_data.empty:\n        self.initial_contacts_ = pd.DataFrame()\n        return self  # Return without performing further processing\n\n    # check if dt_data is a pandas Series with datetime values\n    if dt_data is not None and (\n        not isinstance(dt_data, pd.Series)\n        or not pd.api.types.is_datetime64_any_dtype(dt_data)\n    ):\n        raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n    # check if tracking_system is a string\n    if tracking_system is not None and not isinstance(tracking_system, str):\n        raise ValueError(\"tracking_system must be a string\")\n\n    # check if dt_data is provided and if it is a series with the same length as data\n    if dt_data is not None and len(dt_data) != len(accel_data):\n        raise ValueError(\"dt_data must be a series with the same length as data\")\n\n    # Convert acceleration data from \"m/s^2\" to \"g\"\n    accel_data /= 9.81\n\n    # Extract vertical accelerometer data using the specified index\n    acc_vertical = accel_data[v_acc_col_name]\n\n    # Initialize an empty list to store the processed output\n    processed_output = []\n\n    # Initialize an empty list to store all onsets\n    all_onsets = []\n\n    # Process each gait sequence\n    if gait_sequences is None:\n        gait_sequences = pd.DataFrame(\n            {\"onset\": [0], \"duration\": [len(accel_data) / sampling_freq_Hz]}\n        )\n    for _, gait_seq in gait_sequences.iterrows():\n        # Calculate start and stop indices for the current gait sequence\n        start_index = int(sampling_freq_Hz * gait_seq[\"onset\"])\n        stop_index = int(\n            sampling_freq_Hz * (gait_seq[\"onset\"] + gait_seq[\"duration\"])\n        )\n        accv_gait_seq = acc_vertical[start_index:stop_index].to_numpy()\n\n        try:\n            # Perform Signal Decomposition Algorithm for Initial Contacts (ICs)\n            initial_contacts_rel, _ = preprocessing.signal_decomposition_algorithm(\n                accv_gait_seq, sampling_freq_Hz\n            )\n            initial_contacts = gait_seq[\"onset\"] + initial_contacts_rel\n\n            gait_seq[\"IC\"] = initial_contacts.tolist()\n\n            # Append onsets to the all_onsets list\n            all_onsets.extend(initial_contacts)\n\n        except Exception as e:\n            print(\n                \"Signal decomposition algorithm did not run successfully. Returning an empty vector of initial contacts\"\n            )\n            print(f\"Error: {e}\")\n            initial_contacts = []\n            gait_seq[\"IC\"] = []\n\n        # Append the information to the processed_output list\n        processed_output.append(gait_seq)\n\n    # Check if processed_output is not empty\n    if not processed_output:\n        print(\"No initial contacts detected.\")\n        return pd.DataFrame()\n\n    # Create a DataFrame from the processed_output list\n    initial_contacts_ = pd.DataFrame(processed_output)\n\n    # Create a BIDS-compatible DataFrame with all onsets\n    self.initial_contacts_ = pd.DataFrame(\n        {\n            \"onset\": all_onsets,\n            \"event_type\": \"initial contact\",\n            \"duration\": 0,\n            \"tracking_systems\": tracking_system,\n        }\n    )\n\n    # If original datetime is available, update the 'onset' column\n    if dt_data is not None:\n        valid_indices = [\n            index\n            for index in self.initial_contacts_[\"onset\"]\n            if index &lt; len(dt_data)\n        ]\n        invalid_indices = len(self.initial_contacts_[\"onset\"]) - len(valid_indices)\n\n        if invalid_indices &gt; 0:\n            print(f\"Warning: {invalid_indices} invalid index/indices found.\")\n\n        # Only use valid indices to access dt_data\n        valid_dt_data = dt_data.iloc[valid_indices]\n\n        # Update the 'onset' column\n        self.initial_contacts_[\"onset\"] = valid_dt_data.reset_index(drop=True)\n\n    return self\n</code></pre>"},{"location":"modules/pam/","title":"Physical Activity Monitoring","text":""},{"location":"modules/pam/#physical-activity-monitoring","title":"Physical Activity Monitoring","text":"<p>The algortihm monitors physical activity levels based on accelerometer data. It determines the intensity level of physical activities based on accelerometer signals using the following steps:</p> <ul> <li> <p>Load Data: Includes a time index and accelerometer data (N, 3) for x, y, and z axes. The     sampling frequency (sampling_freq_Hz) is in Hz, with a default value of 100. Thresholds     (thresholds_mg) are provided as a dictionary containing threshold values for physical     activity detection in mg unit. The epoch duration (epoch_duration_sec) is defined in     seconds, with a default of 5 seconds. The last input is plot, which, if set to     True, generates a plot showing the average Euclidean Norm Minus One (ENMO) per hour for     each date. The default is True.</p> </li> <li> <p>Preprocess Signal: Calculate the sample-level Euclidean norm (EN) of the acceleration     signal. Apply a fourth-order Butterworth low-pass filter with a cut-off frequency of 20Hz     to remove noise. Calculate the Euclidean Norm Minus One (ENMO) index and truncate negative     values to zero. Convert the indices by multiplying them by 1000 to convert units from g to     mg.</p> </li> <li> <p>Classify Intensity: Classify the intensity of physical activities based on the calculated     ENMO values using 5-second epochs. Thresholds for categorization are as follows: sedentary     activity &lt; 45 mg, light activity 45\u2013100 mg, moderate activity 100\u2013400 mg, vigorous activity     &gt; 400 mg.</p> </li> <li> <p>Classify Activities: Classify different levels of activities and calculate the time spent     on each activity level for each day. If <code>plot</code> is True, the function generates a     plot showing the averaged ENMO values for each day.</p> </li> </ul> <p>Attributes:</p> Name Type Description <code>physical_activities_</code> <code>DataFrame</code> <p>DataFrame containing physical activity information for each day.</p> <p>Methods:</p> Name Description <code>detect</code> <p>Detects gait sequences on the accelerometer signal.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pam = PhysicalActivityMonitoring()\n&gt;&gt;&gt; pam.detect(\n        data=acceleration_data,\n        acceleration_unit:\"m/s^2\",\n        sampling_freq_Hz=100,\n        thresholds_mg={\n            \"sedentary_threshold\": 45,\n            \"light_threshold\": 100,\n            \"moderate_threshold\": 400,\n        },\n        epoch_duration_sec=5,\n        plot=True)\n&gt;&gt;&gt; print(pam.physical_activities_)\n                sedentary_mean_mg  sedentary_time_min  light_mean_mg  light_time_min  moderate_mean_mg  moderate_time_min  vigorous_mean_mg  vigorous_time_min\n3/19/2018       23.48              733.08              60.78          72              146.2             21.58              730.34            0.58\n3/20/2018       27.16              753.83              57.06          102.25          137.26            7.92               737.9             0.42\n</code></pre> References <p>[1] Doherty, Aiden, et al. (2017). Large scale population assessment of physical activity using wrist-worn accelerometers...</p> <p>[2] Van Hees, Vincent T., et al. (2013). Separating movement and gravity components in an acceleration signal and implications...</p> Source code in <code>kielmat/modules/pam/_pam.py</code> <pre><code>class PhysicalActivityMonitoring:\n    \"\"\"\n    The algortihm monitors physical activity levels based on accelerometer data. It determines the\n    intensity level of physical activities based on accelerometer signals using the following steps:\n\n    - Load Data: Includes a time index and accelerometer data (N, 3) for x, y, and z axes. The\n        sampling frequency (sampling_freq_Hz) is in Hz, with a default value of 100. Thresholds\n        (thresholds_mg) are provided as a dictionary containing threshold values for physical\n        activity detection in mg unit. The epoch duration (epoch_duration_sec) is defined in\n        seconds, with a default of 5 seconds. The last input is plot, which, if set to\n        True, generates a plot showing the average Euclidean Norm Minus One (ENMO) per hour for\n        each date. The default is True.\n\n    - Preprocess Signal: Calculate the sample-level Euclidean norm (EN) of the acceleration\n        signal. Apply a fourth-order Butterworth low-pass filter with a cut-off frequency of 20Hz\n        to remove noise. Calculate the Euclidean Norm Minus One (ENMO) index and truncate negative\n        values to zero. Convert the indices by multiplying them by 1000 to convert units from g to\n        mg.\n\n    - Classify Intensity: Classify the intensity of physical activities based on the calculated\n        ENMO values using 5-second epochs. Thresholds for categorization are as follows: sedentary\n        activity &lt; 45 mg, light activity 45\u2013100 mg, moderate activity 100\u2013400 mg, vigorous activity\n        &gt; 400 mg.\n\n    - Classify Activities: Classify different levels of activities and calculate the time spent\n        on each activity level for each day. If `plot` is True, the function generates a\n        plot showing the averaged ENMO values for each day.\n\n    Attributes:\n        physical_activities_ (pd.DataFrame): DataFrame containing physical activity information for each day.\n\n    Methods:\n        detect(data, sampling_freq_Hz, thresholds_mg, epoch_duration_sec, plot):\n            Detects gait sequences on the accelerometer signal.\n\n    Examples:\n        &gt;&gt;&gt; pam = PhysicalActivityMonitoring()\n        &gt;&gt;&gt; pam.detect(\n                data=acceleration_data,\n                acceleration_unit:\"m/s^2\",\n                sampling_freq_Hz=100,\n                thresholds_mg={\n                    \"sedentary_threshold\": 45,\n                    \"light_threshold\": 100,\n                    \"moderate_threshold\": 400,\n                },\n                epoch_duration_sec=5,\n                plot=True)\n        &gt;&gt;&gt; print(pam.physical_activities_)\n                        sedentary_mean_mg  sedentary_time_min  light_mean_mg  light_time_min  moderate_mean_mg  moderate_time_min  vigorous_mean_mg  vigorous_time_min\n        3/19/2018       23.48              733.08              60.78          72              146.2             21.58              730.34            0.58\n        3/20/2018       27.16              753.83              57.06          102.25          137.26            7.92               737.9             0.42\n\n    References:\n        [1] Doherty, Aiden, et al. (2017). Large scale population assessment of physical activity using wrist-worn accelerometers...\n\n        [2] Van Hees, Vincent T., et al. (2013). Separating movement and gravity components in an acceleration signal and implications...\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the physical activity instance.\n        \"\"\"\n        self.physical_activities_ = None\n\n    def detect(\n        self,\n        data: pd.DataFrame,\n        acceleration_unit: str,\n        sampling_freq_Hz: float,\n        thresholds_mg: dict[str, float] = {\n            \"sedentary_threshold\": 45,\n            \"light_threshold\": 100,\n            \"moderate_threshold\": 400,\n        },\n        epoch_duration_sec: float = 5,\n        plot: bool = True,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Detects and classifies physical activity levels.\n\n        Args:\n            data (pd.DataFrame): Input data with time index and accelerometer data (N, 3) for x, y, and z axes.\n            acceleration_unit (str): Unit of input acceleration data.\n            sampling_freq_Hz (float): Sampling frequency of the accelerometer data (in Hertz).\n            thresholds_mg (dict): Dictionary containing threshold values for physical activity detection.\n            epoch_duration_sec (int): Duration of each epoch in seconds.\n            plot (bool): If True, generates a plot showing the average Euclidean Norm Minus One (ENMO). Default is True.\n\n        Returns:\n            pd.DataFrame: Contains date, sedentary_mean_mg, sedentary_time_min, light_mean_mg, light_time_min,\n                          moderate_mean_mg, moderate_time_min, vigorous_mean_mg, vigorous_time_min\n        \"\"\"\n        # Error handling for invalid input data\n\n        # Check if data is a DataFrame\n        if not isinstance(data, pd.DataFrame):\n            raise ValueError(\"Input data must be a DataFrame.\")\n\n        # Check if data has at least 3 columns\n        if data.shape[1] &lt; 3:\n            raise ValueError(\"Input data must have at least 3 columns.\")\n\n        # Create a time index if data does not have a timestamp column\n        if data.index.name != \"timestamp\" or not isinstance(\n            data.index, pd.DatetimeIndex\n        ):\n            # Create a timestamp index with the correct frequency if not already present\n            data.index = pd.date_range(\n                start=\"2023-01-01 00:00:00\",\n                periods=len(data),\n                freq=f\"{1/sampling_freq_Hz}s\",\n            )\n            data.index.name = \"timestamp\"\n\n        # check if index column in named timestamp\n        if data.index.name != \"timestamp\":\n            raise ValueError(\"Index column must be named timestamp.\")\n\n        if not isinstance(sampling_freq_Hz, (int, float)) or sampling_freq_Hz &lt;= 0:\n            raise ValueError(\"Sampling frequency must be a positive float.\")\n\n        if not isinstance(thresholds_mg, dict):\n            raise ValueError(\"Thresholds must be a dictionary.\")\n\n        if not isinstance(epoch_duration_sec, int) or epoch_duration_sec &lt;= 0:\n            raise ValueError(\"Epoch duration must be a positive integer.\")\n\n        if not isinstance(plot, bool):\n            raise ValueError(\"Plot results must be a boolean (True or False).\")\n\n        # Check unit of acceleration data if it is in g or m/s^2\n        if acceleration_unit == \"m/s^2\":\n            # Convert acceleration data from m/s^2 to g (if not already is in g)\n            data = data.copy()\n            data /= 9.81\n\n        # Calculate Euclidean Norm (EN)\n        data = data.copy()\n        data[\"en\"] = np.linalg.norm(data.values, axis=1)\n\n        # Apply 4th order low-pass Butterworth filter with the cutoff frequency of 20Hz\n        data[\"en\"] = preprocessing.lowpass_filter(\n            data[\"en\"].values,\n            method=\"butter\",\n            order=4,\n            cutoff_freq_hz=20,\n            sampling_rate_hz=sampling_freq_Hz,\n        )\n\n        # Calculate Euclidean Norm Minus One (ENMO) value\n        data[\"enmo\"] = data[\"en\"] - 1\n\n        # Set negative values of ENMO to zero\n        data[\"truncated_enmo\"] = np.maximum(data[\"enmo\"], 0)\n\n        # Convert ENMO from g to milli-g\n        data[\"enmo\"] = data[\"truncated_enmo\"] * 1000\n\n        # Create a final DataFrame with time index and processed ENMO values\n        processed_data = pd.DataFrame(data={\"enmo\": data[\"enmo\"]}, index=data.index)\n\n        # Classify activities based on thresholds using activity_classification\n        classified_processed_data = preprocessing.classify_physical_activity(\n            processed_data,\n            time_column_name=data.index.name,\n            sedentary_threshold=thresholds_mg.get(\"sedentary_threshold\"),\n            light_threshold=thresholds_mg.get(\"light_threshold\"),\n            moderate_threshold=thresholds_mg.get(\"moderate_threshold\"),\n            epoch_duration=epoch_duration_sec,\n        )\n\n        # Extract date from the datetime index\n        classified_processed_data[\"date\"] = classified_processed_data[\n            data.index.name\n        ].dt.date\n\n        # Calculate time spent in each activity level for each epoch\n        classified_processed_data[\"sedentary_time_min\"] = (\n            classified_processed_data[\"sedentary\"] * epoch_duration_sec\n        ) / 60\n        classified_processed_data[\"light_time_min\"] = (\n            classified_processed_data[\"light\"] * epoch_duration_sec\n        ) / 60\n        classified_processed_data[\"moderate_time_min\"] = (\n            classified_processed_data[\"moderate\"] * epoch_duration_sec\n        ) / 60\n        classified_processed_data[\"vigorous_time_min\"] = (\n            classified_processed_data[\"vigorous\"] * epoch_duration_sec\n        ) / 60\n\n        # Group by date and calculate mean and total time spent in each activity level\n        physical_activities_ = (\n            classified_processed_data.groupby(\"date\")\n            .agg(\n                sedentary_mean_enmo=(\n                    \"enmo\",\n                    lambda x: (\n                        np.nanmean(\n                            x[classified_processed_data.loc[x.index, \"sedentary\"] == 1]\n                        )\n                        if len(\n                            x[classified_processed_data.loc[x.index, \"sedentary\"] == 1]\n                        )\n                        &gt; 0\n                        else 0\n                    ),\n                ),\n                sedentary_time_min=(\"sedentary_time_min\", \"sum\"),\n                light_mean_enmo=(\n                    \"enmo\",\n                    lambda x: (\n                        np.nanmean(\n                            x[classified_processed_data.loc[x.index, \"light\"] == 1]\n                        )\n                        if len(x[classified_processed_data.loc[x.index, \"light\"] == 1])\n                        &gt; 0\n                        else 0\n                    ),\n                ),\n                light_time_min=(\"light_time_min\", \"sum\"),\n                moderate_mean_enmo=(\n                    \"enmo\",\n                    lambda x: (\n                        np.nanmean(\n                            x[classified_processed_data.loc[x.index, \"moderate\"] == 1]\n                        )\n                        if len(\n                            x[classified_processed_data.loc[x.index, \"moderate\"] == 1]\n                        )\n                        &gt; 0\n                        else 0\n                    ),\n                ),\n                moderate_time_min=(\"moderate_time_min\", \"sum\"),\n                vigorous_mean_enmo=(\n                    \"enmo\",\n                    lambda x: (\n                        np.nanmean(\n                            x[classified_processed_data.loc[x.index, \"vigorous\"] == 1]\n                        )\n                        if len(\n                            x[classified_processed_data.loc[x.index, \"vigorous\"] == 1]\n                        )\n                        &gt; 0\n                        else 0\n                    ),\n                ),\n                vigorous_time_min=(\"vigorous_time_min\", \"sum\"),\n            )\n            .reset_index()\n        )\n\n        # Return physical activities as an output\n        self.physical_activities_ = physical_activities_\n\n        # Group by date and hour to calculate the average ENMO for each hour\n        hourly_average_data = processed_data.groupby(\n            [processed_data.index.date, processed_data.index.hour]\n        )[\"enmo\"].mean()\n\n        # Reshape the data to have dates as rows, hours as columns, and average ENMO as values\n        hourly_average_data = hourly_average_data.unstack()\n\n        self.hourly_average_data = hourly_average_data\n\n        # Plot if set to true\n        if plot:\n\n            viz_utils.plot_pam(hourly_average_data)\n\n        return self\n</code></pre>"},{"location":"modules/pam/#modules.pam._pam.PhysicalActivityMonitoring.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the physical activity instance.</p> Source code in <code>kielmat/modules/pam/_pam.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the physical activity instance.\n    \"\"\"\n    self.physical_activities_ = None\n</code></pre>"},{"location":"modules/pam/#modules.pam._pam.PhysicalActivityMonitoring.detect","title":"<code>detect(data, acceleration_unit, sampling_freq_Hz, thresholds_mg={'sedentary_threshold': 45, 'light_threshold': 100, 'moderate_threshold': 400}, epoch_duration_sec=5, plot=True)</code>","text":"<p>Detects and classifies physical activity levels.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Input data with time index and accelerometer data (N, 3) for x, y, and z axes.</p> required <code>acceleration_unit</code> <code>str</code> <p>Unit of input acceleration data.</p> required <code>sampling_freq_Hz</code> <code>float</code> <p>Sampling frequency of the accelerometer data (in Hertz).</p> required <code>thresholds_mg</code> <code>dict</code> <p>Dictionary containing threshold values for physical activity detection.</p> <code>{'sedentary_threshold': 45, 'light_threshold': 100, 'moderate_threshold': 400}</code> <code>epoch_duration_sec</code> <code>int</code> <p>Duration of each epoch in seconds.</p> <code>5</code> <code>plot</code> <code>bool</code> <p>If True, generates a plot showing the average Euclidean Norm Minus One (ENMO). Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Contains date, sedentary_mean_mg, sedentary_time_min, light_mean_mg, light_time_min,           moderate_mean_mg, moderate_time_min, vigorous_mean_mg, vigorous_time_min</p> Source code in <code>kielmat/modules/pam/_pam.py</code> <pre><code>def detect(\n    self,\n    data: pd.DataFrame,\n    acceleration_unit: str,\n    sampling_freq_Hz: float,\n    thresholds_mg: dict[str, float] = {\n        \"sedentary_threshold\": 45,\n        \"light_threshold\": 100,\n        \"moderate_threshold\": 400,\n    },\n    epoch_duration_sec: float = 5,\n    plot: bool = True,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects and classifies physical activity levels.\n\n    Args:\n        data (pd.DataFrame): Input data with time index and accelerometer data (N, 3) for x, y, and z axes.\n        acceleration_unit (str): Unit of input acceleration data.\n        sampling_freq_Hz (float): Sampling frequency of the accelerometer data (in Hertz).\n        thresholds_mg (dict): Dictionary containing threshold values for physical activity detection.\n        epoch_duration_sec (int): Duration of each epoch in seconds.\n        plot (bool): If True, generates a plot showing the average Euclidean Norm Minus One (ENMO). Default is True.\n\n    Returns:\n        pd.DataFrame: Contains date, sedentary_mean_mg, sedentary_time_min, light_mean_mg, light_time_min,\n                      moderate_mean_mg, moderate_time_min, vigorous_mean_mg, vigorous_time_min\n    \"\"\"\n    # Error handling for invalid input data\n\n    # Check if data is a DataFrame\n    if not isinstance(data, pd.DataFrame):\n        raise ValueError(\"Input data must be a DataFrame.\")\n\n    # Check if data has at least 3 columns\n    if data.shape[1] &lt; 3:\n        raise ValueError(\"Input data must have at least 3 columns.\")\n\n    # Create a time index if data does not have a timestamp column\n    if data.index.name != \"timestamp\" or not isinstance(\n        data.index, pd.DatetimeIndex\n    ):\n        # Create a timestamp index with the correct frequency if not already present\n        data.index = pd.date_range(\n            start=\"2023-01-01 00:00:00\",\n            periods=len(data),\n            freq=f\"{1/sampling_freq_Hz}s\",\n        )\n        data.index.name = \"timestamp\"\n\n    # check if index column in named timestamp\n    if data.index.name != \"timestamp\":\n        raise ValueError(\"Index column must be named timestamp.\")\n\n    if not isinstance(sampling_freq_Hz, (int, float)) or sampling_freq_Hz &lt;= 0:\n        raise ValueError(\"Sampling frequency must be a positive float.\")\n\n    if not isinstance(thresholds_mg, dict):\n        raise ValueError(\"Thresholds must be a dictionary.\")\n\n    if not isinstance(epoch_duration_sec, int) or epoch_duration_sec &lt;= 0:\n        raise ValueError(\"Epoch duration must be a positive integer.\")\n\n    if not isinstance(plot, bool):\n        raise ValueError(\"Plot results must be a boolean (True or False).\")\n\n    # Check unit of acceleration data if it is in g or m/s^2\n    if acceleration_unit == \"m/s^2\":\n        # Convert acceleration data from m/s^2 to g (if not already is in g)\n        data = data.copy()\n        data /= 9.81\n\n    # Calculate Euclidean Norm (EN)\n    data = data.copy()\n    data[\"en\"] = np.linalg.norm(data.values, axis=1)\n\n    # Apply 4th order low-pass Butterworth filter with the cutoff frequency of 20Hz\n    data[\"en\"] = preprocessing.lowpass_filter(\n        data[\"en\"].values,\n        method=\"butter\",\n        order=4,\n        cutoff_freq_hz=20,\n        sampling_rate_hz=sampling_freq_Hz,\n    )\n\n    # Calculate Euclidean Norm Minus One (ENMO) value\n    data[\"enmo\"] = data[\"en\"] - 1\n\n    # Set negative values of ENMO to zero\n    data[\"truncated_enmo\"] = np.maximum(data[\"enmo\"], 0)\n\n    # Convert ENMO from g to milli-g\n    data[\"enmo\"] = data[\"truncated_enmo\"] * 1000\n\n    # Create a final DataFrame with time index and processed ENMO values\n    processed_data = pd.DataFrame(data={\"enmo\": data[\"enmo\"]}, index=data.index)\n\n    # Classify activities based on thresholds using activity_classification\n    classified_processed_data = preprocessing.classify_physical_activity(\n        processed_data,\n        time_column_name=data.index.name,\n        sedentary_threshold=thresholds_mg.get(\"sedentary_threshold\"),\n        light_threshold=thresholds_mg.get(\"light_threshold\"),\n        moderate_threshold=thresholds_mg.get(\"moderate_threshold\"),\n        epoch_duration=epoch_duration_sec,\n    )\n\n    # Extract date from the datetime index\n    classified_processed_data[\"date\"] = classified_processed_data[\n        data.index.name\n    ].dt.date\n\n    # Calculate time spent in each activity level for each epoch\n    classified_processed_data[\"sedentary_time_min\"] = (\n        classified_processed_data[\"sedentary\"] * epoch_duration_sec\n    ) / 60\n    classified_processed_data[\"light_time_min\"] = (\n        classified_processed_data[\"light\"] * epoch_duration_sec\n    ) / 60\n    classified_processed_data[\"moderate_time_min\"] = (\n        classified_processed_data[\"moderate\"] * epoch_duration_sec\n    ) / 60\n    classified_processed_data[\"vigorous_time_min\"] = (\n        classified_processed_data[\"vigorous\"] * epoch_duration_sec\n    ) / 60\n\n    # Group by date and calculate mean and total time spent in each activity level\n    physical_activities_ = (\n        classified_processed_data.groupby(\"date\")\n        .agg(\n            sedentary_mean_enmo=(\n                \"enmo\",\n                lambda x: (\n                    np.nanmean(\n                        x[classified_processed_data.loc[x.index, \"sedentary\"] == 1]\n                    )\n                    if len(\n                        x[classified_processed_data.loc[x.index, \"sedentary\"] == 1]\n                    )\n                    &gt; 0\n                    else 0\n                ),\n            ),\n            sedentary_time_min=(\"sedentary_time_min\", \"sum\"),\n            light_mean_enmo=(\n                \"enmo\",\n                lambda x: (\n                    np.nanmean(\n                        x[classified_processed_data.loc[x.index, \"light\"] == 1]\n                    )\n                    if len(x[classified_processed_data.loc[x.index, \"light\"] == 1])\n                    &gt; 0\n                    else 0\n                ),\n            ),\n            light_time_min=(\"light_time_min\", \"sum\"),\n            moderate_mean_enmo=(\n                \"enmo\",\n                lambda x: (\n                    np.nanmean(\n                        x[classified_processed_data.loc[x.index, \"moderate\"] == 1]\n                    )\n                    if len(\n                        x[classified_processed_data.loc[x.index, \"moderate\"] == 1]\n                    )\n                    &gt; 0\n                    else 0\n                ),\n            ),\n            moderate_time_min=(\"moderate_time_min\", \"sum\"),\n            vigorous_mean_enmo=(\n                \"enmo\",\n                lambda x: (\n                    np.nanmean(\n                        x[classified_processed_data.loc[x.index, \"vigorous\"] == 1]\n                    )\n                    if len(\n                        x[classified_processed_data.loc[x.index, \"vigorous\"] == 1]\n                    )\n                    &gt; 0\n                    else 0\n                ),\n            ),\n            vigorous_time_min=(\"vigorous_time_min\", \"sum\"),\n        )\n        .reset_index()\n    )\n\n    # Return physical activities as an output\n    self.physical_activities_ = physical_activities_\n\n    # Group by date and hour to calculate the average ENMO for each hour\n    hourly_average_data = processed_data.groupby(\n        [processed_data.index.date, processed_data.index.hour]\n    )[\"enmo\"].mean()\n\n    # Reshape the data to have dates as rows, hours as columns, and average ENMO as values\n    hourly_average_data = hourly_average_data.unstack()\n\n    self.hourly_average_data = hourly_average_data\n\n    # Plot if set to true\n    if plot:\n\n        viz_utils.plot_pam(hourly_average_data)\n\n    return self\n</code></pre>"},{"location":"modules/ptd/","title":"Postural Transition Detection","text":""},{"location":"modules/ptd/#postural-transition-detection-pham","title":"Postural Transition Detection (Pham)","text":"<p>This algorithm aims to detect postural transitions (e.g., sit to stand or stand to sit movements) using accelerometer and gyroscope data collected from a lower back inertial measurement unit (IMU) sensor based on [1].</p> <p>The algorithm is designed to be robust in detecting postural transitions using inertial sensor data and provides detailed information about these transitions. It starts by loading the accelerometer and gyro data, which includes three columns corresponding to the acceleration and gyro signals across the x, y, and z axes, along with the sampling frequency of the data. It first checks the validity of the input data. Then, it calculates the sampling period, selects accelerometer and gyro data. Then, it uses a Versatile Quaternion-based Filter (VQF) to estimate the orientation of the IMU [2]. This helps in correcting the orientation of accelerometer and gyroscope data. Tilt angle estimation is performed using gyro data in lateral or anteroposterior direction which represent movements or rotations in the mediolateral direction. The tilt angle is decomposed using wavelet transformation to identify stationary periods. Stationary periods are detected using accelerometer variance and gyro variance. Then, peaks in the wavelet-transformed tilt signal are detected as potential postural transition events.</p> <p>If there's enough stationary data, further processing is done to estimate the orientation using quaternions and to identify the beginning and end of postural transitions using gyro data. Otherwise, if there's insufficient stationary data, direction changes in gyro data are used to infer postural transitions. Finally, the detected postural transitions along with their characteristics (onset, duration, etc.) are stored in a pandas DataFrame (postural_transitions_ attribute).</p> <p>In addition, spatial-temporal parameters are calculated using detected postural transitions and their characteristics by the spatio_temporal_parameters method. As a return, the postural transition id along with its spatial-temporal parameters including type of postural transition (sit to stand or stand to sit), angle of postural transition, maximum flexion velocity, and maximum extension velocity are stored in a pandas DataFrame (parameters_ attribute).</p> <p>If requested (plot_results set to True), it generates plots of the accelerometer and gyroscope data along with the detected postural transitions.</p> <p>Methods:</p> Name Description <code>detect</code> <p>Detects  sit to stand and stand to sit using accelerometer and gyro signals.</p> <code>spatio_temporal_parameters</code> <p>Extracts spatio-temporal parameters of the detected turns.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pham = PhamPosturalTransitionDetection()\n&gt;&gt;&gt; pham.detect(\n        accel_data=accel_data,\n        gyro_data=gyro_data,\n        sampling_freq_Hz=200.0,\n        tracking_system=\"imu\",\n        tracked_point=\"LowerBack\",\n        plot_results=False\n        )\n&gt;&gt;&gt; print(pham.postural_transitions_)\n        onset      duration     event_type              tracking_systems    tracked_points\n    0   17.895     1.8          postural transition     imu                 LowerBack\n    1   54.655     1.9          postural transition     imu                 LowerBack\n</code></pre> <pre><code>&gt;&gt;&gt; pham.spatio_temporal_parameters()\n&gt;&gt;&gt; print(pham.parameters_)\n        type of postural transition    angle of postural transition     maximum flexion velocity    maximum extension velocity\n    0   sit to stand                   53.26                            79                          8\n    1   stand to sit                   47.12                            91                      120\n</code></pre> References <p>[1] Pham et al. (2018). Validation of a Lower Back \"Wearable\"-Based Sit-to-Stand and Stand-to-Sit Algorithm... https://doi.org/10.3389/fneur.2018.00652 [2] D. Laidig and T. Seel. \u201cVQF: Highly Accurate IMU Orientation Estimation with Bias Estimation ... https://doi.org/10.1016/j.inffus.2022.10.014</p> Source code in <code>kielmat/modules/ptd/_pham.py</code> <pre><code>class PhamPosturalTransitionDetection:\n    \"\"\"\n    This algorithm aims to detect postural transitions (e.g., sit to stand or stand to sit movements)\n    using accelerometer and gyroscope data collected from a lower back inertial measurement unit (IMU)\n    sensor based on [1].\n\n    The algorithm is designed to be robust in detecting postural transitions using inertial sensor data\n    and provides detailed information about these transitions. It starts by loading the accelerometer and\n    gyro data, which includes three columns corresponding to the acceleration and gyro signals across\n    the x, y, and z axes, along with the sampling frequency of the data. It first checks the validity of\n    the input data. Then, it calculates the sampling period, selects accelerometer and gyro data. Then, it uses\n    a Versatile Quaternion-based Filter (VQF) to estimate the orientation of the IMU [2]. This helps in correcting\n    the orientation of accelerometer and gyroscope data. Tilt angle estimation is performed using gyro data in\n    lateral or anteroposterior direction which represent movements or rotations in the mediolateral direction.\n    The tilt angle is decomposed using wavelet transformation to identify stationary periods. Stationary periods\n    are detected using accelerometer variance and gyro variance. Then, peaks in the wavelet-transformed\n    tilt signal are detected as potential postural transition events.\n\n    If there's enough stationary data, further processing is done to estimate the orientation using\n    quaternions and to identify the beginning and end of postural transitions using gyro data. Otherwise,\n    if there's insufficient stationary data, direction changes in gyro data are used to infer postural\n    transitions. Finally, the detected postural transitions along with their characteristics (onset, duration, etc.)\n    are stored in a pandas DataFrame (postural_transitions_ attribute).\n\n    In addition, spatial-temporal parameters are calculated using detected postural transitions and their\n    characteristics by the spatio_temporal_parameters method. As a return, the postural transition id along\n    with its spatial-temporal parameters including type of postural transition (sit to stand or stand to sit),\n    angle of postural transition, maximum flexion velocity, and maximum extension velocity are stored in a pandas\n    DataFrame (parameters_ attribute).\n\n    If requested (plot_results set to True), it generates plots of the accelerometer and gyroscope data\n    along with the detected postural transitions.\n\n    Methods:\n        detect(accel_data, gyro_data, sampling_freq_Hz, dt_data, tracking_system, tracked_point, plot_results):\n            Detects  sit to stand and stand to sit using accelerometer and gyro signals.\n\n        spatio_temporal_parameters():\n            Extracts spatio-temporal parameters of the detected turns.\n\n    Examples:\n        &gt;&gt;&gt; pham = PhamPosturalTransitionDetection()\n        &gt;&gt;&gt; pham.detect(\n                accel_data=accel_data,\n                gyro_data=gyro_data,\n                sampling_freq_Hz=200.0,\n                tracking_system=\"imu\",\n                tracked_point=\"LowerBack\",\n                plot_results=False\n                )\n        &gt;&gt;&gt; print(pham.postural_transitions_)\n                onset      duration     event_type              tracking_systems    tracked_points\n            0   17.895     1.8          postural transition     imu                 LowerBack\n            1   54.655     1.9          postural transition     imu                 LowerBack\n\n        &gt;&gt;&gt; pham.spatio_temporal_parameters()\n        &gt;&gt;&gt; print(pham.parameters_)\n                type of postural transition    angle of postural transition     maximum flexion velocity    maximum extension velocity\n            0   sit to stand                   53.26                            79                          8\n            1   stand to sit                   47.12                            91                      120\n\n    References:\n        [1] Pham et al. (2018). Validation of a Lower Back \"Wearable\"-Based Sit-to-Stand and Stand-to-Sit Algorithm... https://doi.org/10.3389/fneur.2018.00652\n        [2] D. Laidig and T. Seel. \u201cVQF: Highly Accurate IMU Orientation Estimation with Bias Estimation ... https://doi.org/10.1016/j.inffus.2022.10.014\n    \"\"\"\n\n    def __init__(\n        self,\n        cutoff_freq_hz: float = 5.0,\n        thr_accel_var: float = 0.05,\n        thr_gyro_var: float = 10e-2,\n        min_postural_transition_angle_deg: float = 15.0,\n    ):\n        \"\"\"\n        Initializes the PhamPosturalTransitionDetection instance.\n\n        Args:\n            cutoff_freq_hz (float, optional): Cutoff frequency for low-pass Butterworth filer. Default is 5.0.\n            thr_accel_var (float): Threshold value for identifying periods where the acceleartion variance is low. Default is 0.5.\n            thr_gyro_var (float): Threshold value for identifying periods where the gyro variance is low. Default is 2e-4.\n            min_postural_transition_angle_deg (float): Minimum angle which is considered as postural transition in degrees. Default is 15.0.\n        \"\"\"\n        self.cutoff_freq_hz = cutoff_freq_hz\n        self.thr_accel_var = thr_accel_var\n        self.thr_gyro_var = thr_gyro_var\n        self.min_postural_transition_angle_deg = min_postural_transition_angle_deg\n\n    def detect(\n        self,\n        accel_data: pd.DataFrame,\n        gyro_data: pd.DataFrame,\n        sampling_freq_Hz: float,\n        dt_data: Optional[pd.Series] = None,\n        tracking_system: Optional[str] = None,\n        tracked_point: Optional[str] = None,\n        plot_results: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Detects postural transitions based on the input accelerometer and gyro data.\n\n        Args:\n            accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n            gyro_data (pd.DataFrame): Input gyro data (N, 3) for x, y, and z axes.\n            sampling_freq_Hz (float): Sampling frequency of the input data.\n            dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n            tracking_system (str, optional): Tracking systems.\n            tracked_point (str, optional): Tracked points on the body.\n            plot_results (bool, optional): If True, generates a plot. Default is False.\n\n        Returns:\n            The postural transition information is stored in the 'postural_transitions_' attribute, which is a pandas DataFrame in BIDS format with the following columns:\n\n                - onset: Start time of the postural transition in second.\n                - duration: Duration of the postural transition in second.\n                - event_type: Type of the event which is postural transition.\n                - tracking_systems: Name of the tracking systems.\n                - tracked_points: Name of the tracked points on the body.\n        \"\"\"\n        # check if dt_data is a pandas Series with datetime values\n        if dt_data is not None:\n            # Ensure dt_data is a pandas Series\n            if not isinstance(dt_data, pd.Series):\n                raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n            # Ensure dt_data has datetime values\n            if not pd.api.types.is_datetime64_any_dtype(dt_data):\n                raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n            # Ensure dt_data has the same length as accel_data and gyro_data\n            if len(dt_data) != len(accel_data):\n                raise ValueError(\n                    \"dt_data must be a pandas Series with the same length as accel_data and gyro_data\"\n                )\n\n        # Check if data is a DataFrame\n        if not isinstance(accel_data, pd.DataFrame):\n            raise ValueError(\"Input data must be a pandas DataFrame\")\n\n        if not isinstance(gyro_data, pd.DataFrame):\n            raise ValueError(\"Input data must be a pandas DataFrame\")\n\n        # Error handling for invalid input data\n        if not isinstance(accel_data, pd.DataFrame) or accel_data.shape[1] != 3:\n            raise ValueError(\n                \"Input accelerometer data must be a DataFrame with 3 columns for x, y, and z axes.\"\n            )\n\n        if not isinstance(gyro_data, pd.DataFrame) or gyro_data.shape[1] != 3:\n            raise ValueError(\n                \"Input gyro data must be a DataFrame with 3 columns for x, y, and z axes.\"\n            )\n\n        # Check if sampling frequency is positive\n        if sampling_freq_Hz &lt;= 0:\n            raise ValueError(\"Sampling frequency must be positive\")\n\n        # Check if plot_results is a boolean\n        if not isinstance(plot_results, bool):\n            raise ValueError(\"plot_results must be a boolean value\")\n\n        # Calculate sampling period\n        sampling_period = 1 / sampling_freq_Hz\n\n        gyro_data = np.deg2rad(gyro_data)\n\n        # Ensure that acceleration and gyroscope arrays are C-contiguous for efficient processing\n        accel_data = np.ascontiguousarray(accel_data)\n        self.gyro_data = np.ascontiguousarray(gyro_data)\n\n        # Initialize the Versatile Quaternion-based Filter (VQF) with the calculated sampling period\n        vqf = VQF(sampling_period)\n\n        # Perform orientation estimation using VQF\n        # This step estimates the orientation of the IMU and returns quaternion-based orientation estimates\n        out_orientation_est = vqf.updateBatch(self.gyro_data, accel_data)\n\n        # Initialize arrays to store the updated acceleration and gyroscope data\n        accel_updated = np.zeros_like(accel_data)\n        gyro_updated = np.zeros_like(self.gyro_data)\n\n        # Apply quaternion-based orientation correction to the accelerometer data\n        # This step corrects the accelerometer data based on the estimated orientation\n        for t in range(accel_updated.shape[0]):\n            accel_updated[t, :] = vqf.quatRotate(\n                out_orientation_est[\"quat6D\"][t, :], accel_data[t, :]\n            )\n\n        # Apply quaternion-based orientation correction to the gyroscope data\n        # This step corrects the gyroscope data based on the estimated orientation\n        for t in range(gyro_updated.shape[0]):\n            gyro_updated[t, :] = vqf.quatRotate(\n                out_orientation_est[\"quat6D\"][t, :], self.gyro_data[t, :]\n            )\n\n        # Convert updated acceleration data back from \"m/s^2\" to \"g\" units\n        # This step reverses the initial conversion applied to the acceleration data\n        accel = accel_updated / 9.81\n\n        # Convert back gyro data from rad/s to deg/s after orientation estimation\n        self.gyro = np.rad2deg(gyro_updated)\n\n        # Compute the range of gyro signals for x and y components\n        range_x = np.ptp(self.gyro[:, 0])  # gyro x-axis\n        range_y = np.ptp(self.gyro[:, 1])  # gyro y-axis\n\n        # Compute the variance of gyro signals for x and y components\n        var_x = np.var(self.gyro[:, 0])  # gyro x-axis\n        var_y = np.var(self.gyro[:, 1])  # gyro y-axis\n\n        # Determine which component of gyro corresponds to the mediolateral direction\n        if range_x &gt; range_y or var_x &gt; var_y:\n            # X component has a larger range/variance, likely mediolateral\n            self.gyro_mediolateral = self.gyro[:, 0]  # Gyro x-axis is mediolateral\n        else:\n            # Y component has a larger range/variance, likely mediolateral\n            self.gyro_mediolateral = self.gyro[:, 1]  # Gyro y-axis is mediolateral\n\n        # Calculate timestamps to use in next calculation\n        time = np.arange(1, len(accel[:, 0]) + 1) * sampling_period\n\n        # Estimate tilt angle in deg\n        tilt_angle_deg = preprocessing.tilt_angle_estimation(\n            data=self.gyro_mediolateral, sampling_frequency_hz=sampling_freq_Hz\n        )\n\n        # Convert tilt angle to rad\n        tilt_angle_rad = np.deg2rad(tilt_angle_deg)\n\n        # Calculate sine of the tilt angle in radians\n        tilt_sin = np.sin(tilt_angle_rad)\n\n        # Apply wavelet decomposition with level of 3\n        tilt_dwt_3 = preprocessing.wavelet_decomposition(\n            data=tilt_sin, level=3, wavetype=\"coif5\"\n        )\n\n        # Apply wavelet decomposition with level of 10\n        tilt_dwt_10 = preprocessing.wavelet_decomposition(\n            data=tilt_sin, level=10, wavetype=\"coif5\"\n        )\n\n        # Calculate difference\n        tilt_dwt = tilt_dwt_3 - tilt_dwt_10\n\n        # Find peaks in denoised tilt signal\n        self.local_peaks, _ = scipy.signal.find_peaks(\n            tilt_dwt, height=0.2, prominence=0.2\n        )\n\n        # Calculate the norm of acceleration\n        accel_norm = np.sqrt(accel[:, 0] ** 2 + accel[:, 1] ** 2 + accel[:, 2] ** 2)\n\n        # Calculate absolute value of the acceleration signal\n        accel_norm = np.abs(accel_norm)\n\n        # Detect stationary parts of the signal based on the deifned threshold\n        stationary_1 = accel_norm &lt; self.thr_accel_var\n        stationary_1 = (stationary_1).astype(int)\n\n        # Compute the variance of the moving window acceleration\n        accel_var = preprocessing.moving_var(data=accel_norm, window=sampling_freq_Hz)\n\n        # Calculate stationary_2 from acceleration variance\n        stationary_2 = (accel_var &lt;= self.thr_gyro_var).astype(int)\n\n        # Calculate stationary of gyro variance\n        gyro_norm = np.sqrt(\n            self.gyro[:, 0] ** 2 + self.gyro[:, 1] ** 2 + self.gyro[:, 2] ** 2\n        )\n\n        # Compute the variance of the moving window of gyro\n        gyro_var = preprocessing.moving_var(data=gyro_norm, window=sampling_freq_Hz)\n\n        # Calculate stationary of gyro variance\n        stationary_3 = (gyro_var &lt;= self.thr_gyro_var).astype(int)\n\n        # Perform stationarity checks\n        stationary = stationary_1 &amp; stationary_2 &amp; stationary_3\n\n        # Remove consecutive True values in the stationary array\n        for i in range(len(stationary) - 1):\n            if stationary[i] == 1:\n                if stationary[i + 1] == 0:\n                    stationary[i] = 0\n\n        # Set initial period and check if enough stationary data is available\n        # Stationary periods are defined as the episodes when the lower back of the participant was almost not moving and not rotating.\n        # The thresholds are determined based on the training data set.\n        init_period = 0.1\n\n        if (\n            np.sum(stationary[: int(sampling_freq_Hz * init_period)]) &gt;= 200\n        ):  # If the process is stationary in the first 2s\n            # If there is enough stationary data, perform sensor fusion using accelerometer and gyro data\n            (\n                postural_transition_onset,\n                postural_transition_type,\n                self.postural_transition_angle,\n                duration,\n                self.flexion_max_vel,\n                self.extension_max_vel,\n            ) = preprocessing.process_postural_transitions_stationary_periods(\n                time,\n                accel,\n                self.gyro,\n                stationary,\n                tilt_angle_deg,\n                sampling_period,\n                sampling_freq_Hz,\n                init_period,\n                self.local_peaks,\n            )\n\n            # Create a DataFrame with postural transition information\n            postural_transitions_ = pd.DataFrame(\n                {\n                    \"onset\": postural_transition_onset,\n                    \"duration\": duration,\n                    \"event_type\": postural_transition_type,\n                    \"tracking_systems\": tracking_system,\n                    \"tracked_points\": tracked_point,\n                }\n            )\n\n        else:\n            # Handle cases where there is not enough stationary data\n            # Find indices where the product of consecutive changes sign, indicating a change in direction\n            iZeroCr = np.where(\n                (self.gyro_mediolateral[:-1] * self.gyro_mediolateral[1:]) &lt; 0\n            )[0]\n\n            # Calculate the difference between consecutive values\n            gyro_y_diff = np.diff(self.gyro_mediolateral, axis=0)\n\n            # Initialize arrays to store left and right indices for each local peak\n            # Initialize left side indices with ones\n            self.left_side = np.ones_like(self.local_peaks)\n\n            # Initialize right side indices with length of gyro data\n            self.right_side = len(self.gyro_mediolateral) * np.ones_like(\n                self.local_peaks\n            )\n\n            # Loop through each local peak\n            for i in range(len(self.local_peaks)):\n                # Get the index of the current local peak\n                postural_transitions = self.local_peaks[i]\n\n                # Calculate distances to all zero-crossing points relative to the peak\n                dist2peak = iZeroCr - postural_transitions\n\n                # Extract distances to zero-crossing points on the left side of the peak\n                dist2peak_left_side = dist2peak[dist2peak &lt; 0]\n\n                # Extract distances to zero-crossing points on the right side of the peak\n                dist2peak_right_side = dist2peak[dist2peak &gt; 0]\n\n                # Iterate over distances to zero-crossing points on the left side of the peak (in reverse order)\n                for j in range(len(dist2peak_left_side) - 1, -1, -1):\n                    # Check if slope is down and the left side not too close to the peak (more than 200ms)\n                    if gyro_y_diff[\n                        postural_transitions + dist2peak_left_side[j]\n                    ] &lt; 0 and -dist2peak_left_side[j] &gt; (0.2 * sampling_freq_Hz):\n                        if j &gt; 0:\n                            # If the left side peak is far enough or small enough\n                            if (\n                                dist2peak_left_side[j] - dist2peak_left_side[j - 1]\n                            ) &gt;= (0.2 * sampling_freq_Hz) or (\n                                tilt_angle_deg[\n                                    postural_transitions + dist2peak_left_side[j - 1]\n                                ]\n                                - tilt_angle_deg[\n                                    postural_transitions + dist2peak_left_side[j]\n                                ]\n                            ) &gt; 1:\n                                # Store the index of the left side\n                                self.left_side[i] = (\n                                    postural_transitions + dist2peak_left_side[j]\n                                )\n                                break\n                            else:\n                                self.left_side[i] = (\n                                    postural_transitions + dist2peak_left_side[j]\n                                )\n                                break\n                for j in range(len(dist2peak_right_side)):\n                    if gyro_y_diff[\n                        postural_transitions + dist2peak_right_side[j]\n                    ] &lt; 0 and dist2peak_right_side[j] &gt; (0.2 * sampling_freq_Hz):\n                        self.right_side[i] = (\n                            postural_transitions + dist2peak_right_side[j]\n                        )\n                        break\n\n                # Calculate postural transition angle\n                self.postural_transition_angle = np.abs(\n                    tilt_angle_deg[self.local_peaks] - tilt_angle_deg[self.left_side]\n                )\n                if self.left_side[0] == 1:\n                    self.postural_transition_angle[0] = abs(\n                        tilt_angle_deg[self.local_peaks[0]]\n                        - tilt_angle_deg[self.right_side[0]]\n                    )\n\n                # Calculate duration of each postural transition\n                duration = (self.right_side - self.left_side) / sampling_freq_Hz\n\n                # Convert peak times to integers\n                postural_transition_onset = time[self.local_peaks]\n\n        # Remove too small postural transitions\n        i = self.postural_transition_angle &gt;= self.min_postural_transition_angle_deg\n        postural_transition_onset = self.left_side[i] / sampling_freq_Hz\n        duration = duration[i]\n\n        # Check if dt_data is provided for datetime conversion\n        if dt_data is not None:\n            # Convert onset times to datetime format\n            starting_datetime = dt_data.iloc[\n                0\n            ]  # Assuming dt_data is aligned with the signal data\n            postural_transition_onset = [\n                starting_datetime + pd.Timedelta(seconds=t)\n                for t in postural_transition_onset\n            ]\n\n        # Create a DataFrame with postural transition information\n        postural_transitions_ = pd.DataFrame(\n            {\n                \"onset\": postural_transition_onset,\n                \"duration\": duration,\n                \"event_type\": \"postural transition\",\n                \"tracking_systems\": tracking_system,\n                \"tracked_points\": tracked_point,\n            }\n        )\n\n        # Assign the DataFrame to the 'postural_transitions_' attribute\n        self.postural_transitions_ = postural_transitions_\n\n        # If Plot_results set to true\n        if plot_results:\n            viz_utils.plot_postural_transitions(\n                accel,\n                self.gyro,\n                postural_transitions_,\n                sampling_freq_Hz,\n            )\n\n        # Return an instance of the class\n        return self\n\n    def spatio_temporal_parameters(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Extracts spatio-temporal parameters of the detected postural transitions.\n\n        Returns:\n            The spatio-temporal parameter information is stored in the 'spatio_temporal_parameters' attribute, which is a pandas DataFrame as:\n\n                - type_of_postural_transition: Type of postural transition which is either \"sit to stand\" or \"stand to sit\".\n                - angel_of_postural_transition: Angle of the postural transition in degrees.\n                - maximum_flexion_velocity: Maximum flexion velocity in deg/s.\n                - maximum_extension_velocity: Maximum extension velocity in deg/s.\n        \"\"\"\n        if self.postural_transitions_ is None:\n            raise ValueError(\n                \"No postural transition detected. Please run the detect method first.\"\n            )\n\n        # Initialize list for postural transition types\n        postural_transition_type = []\n\n        # Distinguish between different types of postural transitions\n        for i in range(len(self.local_peaks)):\n            gyro_temp = self.gyro_mediolateral[self.left_side[i] : self.right_side[i]]\n            min_peak = np.min(gyro_temp)\n            max_peak = np.max(gyro_temp)\n            if (abs(max_peak) - abs(min_peak)) &gt; 0.5:\n                postural_transition_type.append(\"sit to stand\")\n            else:\n                postural_transition_type.append(\"stand to sit\")\n\n        # Postural transition type and angle determination\n        i = self.postural_transition_angle &gt;= self.min_postural_transition_angle_deg\n        postural_transition_type = [\n            postural_transition_type[idx]\n            for idx, val in enumerate(postural_transition_type)\n            if i[idx]\n        ]\n        self.postural_transition_angle = self.postural_transition_angle[i]\n\n        # Calculate maximum flexion velocity and maximum extension velocity\n        flexion_max_vel = np.zeros_like(self.local_peaks)\n        extension_max_vel = np.zeros_like(self.local_peaks)\n\n        for id in range(len(self.local_peaks)):\n            flexion_max_vel[id] = max(\n                abs(self.gyro_mediolateral[self.left_side[id] : self.local_peaks[id]])\n            )\n            extension_max_vel[id] = max(\n                abs(self.gyro_mediolateral[self.local_peaks[id] : self.right_side[id]])\n            )\n\n        # Filter the velocities based on valid indices\n        flexion_max_vel = [\n            flexion_max_vel[idx] for idx, val in enumerate(flexion_max_vel) if i[idx]\n        ]\n\n        # Calculate maximum extension velocity\n        extension_max_vel = [\n            extension_max_vel[idx]\n            for idx, val in enumerate(extension_max_vel)\n            if i[idx]\n        ]\n\n        # Create a DataFrame with the calculated spatio-temporal parameters\n        self.parameters_ = pd.DataFrame(\n            {\n                \"type_of_postural_transition\": postural_transition_type,\n                \"angle_of_postural_transition\": self.postural_transition_angle,\n                \"maximum_flexion_velocity\": flexion_max_vel,\n                \"maximum_extension_velocity\": extension_max_vel,\n            }\n        )\n\n        # Set the index name to 'postural transition id'\n        self.parameters_.index.name = \"postural transition id\"\n</code></pre>"},{"location":"modules/ptd/#modules.ptd._pham.PhamPosturalTransitionDetection.__init__","title":"<code>__init__(cutoff_freq_hz=5.0, thr_accel_var=0.05, thr_gyro_var=0.1, min_postural_transition_angle_deg=15.0)</code>","text":"<p>Initializes the PhamPosturalTransitionDetection instance.</p> <p>Parameters:</p> Name Type Description Default <code>cutoff_freq_hz</code> <code>float</code> <p>Cutoff frequency for low-pass Butterworth filer. Default is 5.0.</p> <code>5.0</code> <code>thr_accel_var</code> <code>float</code> <p>Threshold value for identifying periods where the acceleartion variance is low. Default is 0.5.</p> <code>0.05</code> <code>thr_gyro_var</code> <code>float</code> <p>Threshold value for identifying periods where the gyro variance is low. Default is 2e-4.</p> <code>0.1</code> <code>min_postural_transition_angle_deg</code> <code>float</code> <p>Minimum angle which is considered as postural transition in degrees. Default is 15.0.</p> <code>15.0</code> Source code in <code>kielmat/modules/ptd/_pham.py</code> <pre><code>def __init__(\n    self,\n    cutoff_freq_hz: float = 5.0,\n    thr_accel_var: float = 0.05,\n    thr_gyro_var: float = 10e-2,\n    min_postural_transition_angle_deg: float = 15.0,\n):\n    \"\"\"\n    Initializes the PhamPosturalTransitionDetection instance.\n\n    Args:\n        cutoff_freq_hz (float, optional): Cutoff frequency for low-pass Butterworth filer. Default is 5.0.\n        thr_accel_var (float): Threshold value for identifying periods where the acceleartion variance is low. Default is 0.5.\n        thr_gyro_var (float): Threshold value for identifying periods where the gyro variance is low. Default is 2e-4.\n        min_postural_transition_angle_deg (float): Minimum angle which is considered as postural transition in degrees. Default is 15.0.\n    \"\"\"\n    self.cutoff_freq_hz = cutoff_freq_hz\n    self.thr_accel_var = thr_accel_var\n    self.thr_gyro_var = thr_gyro_var\n    self.min_postural_transition_angle_deg = min_postural_transition_angle_deg\n</code></pre>"},{"location":"modules/ptd/#modules.ptd._pham.PhamPosturalTransitionDetection.detect","title":"<code>detect(accel_data, gyro_data, sampling_freq_Hz, dt_data=None, tracking_system=None, tracked_point=None, plot_results=False)</code>","text":"<p>Detects postural transitions based on the input accelerometer and gyro data.</p> <p>Parameters:</p> Name Type Description Default <code>accel_data</code> <code>DataFrame</code> <p>Input accelerometer data (N, 3) for x, y, and z axes.</p> required <code>gyro_data</code> <code>DataFrame</code> <p>Input gyro data (N, 3) for x, y, and z axes.</p> required <code>sampling_freq_Hz</code> <code>float</code> <p>Sampling frequency of the input data.</p> required <code>dt_data</code> <code>Series</code> <p>Original datetime in the input data. If original datetime is provided, the output onset will be based on that.</p> <code>None</code> <code>tracking_system</code> <code>str</code> <p>Tracking systems.</p> <code>None</code> <code>tracked_point</code> <code>str</code> <p>Tracked points on the body.</p> <code>None</code> <code>plot_results</code> <code>bool</code> <p>If True, generates a plot. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The postural transition information is stored in the 'postural_transitions_' attribute, which is a pandas DataFrame in BIDS format with the following columns:</p> <ul> <li>onset: Start time of the postural transition in second.</li> <li>duration: Duration of the postural transition in second.</li> <li>event_type: Type of the event which is postural transition.</li> <li>tracking_systems: Name of the tracking systems.</li> <li>tracked_points: Name of the tracked points on the body.</li> </ul> Source code in <code>kielmat/modules/ptd/_pham.py</code> <pre><code>def detect(\n    self,\n    accel_data: pd.DataFrame,\n    gyro_data: pd.DataFrame,\n    sampling_freq_Hz: float,\n    dt_data: Optional[pd.Series] = None,\n    tracking_system: Optional[str] = None,\n    tracked_point: Optional[str] = None,\n    plot_results: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects postural transitions based on the input accelerometer and gyro data.\n\n    Args:\n        accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n        gyro_data (pd.DataFrame): Input gyro data (N, 3) for x, y, and z axes.\n        sampling_freq_Hz (float): Sampling frequency of the input data.\n        dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n        tracking_system (str, optional): Tracking systems.\n        tracked_point (str, optional): Tracked points on the body.\n        plot_results (bool, optional): If True, generates a plot. Default is False.\n\n    Returns:\n        The postural transition information is stored in the 'postural_transitions_' attribute, which is a pandas DataFrame in BIDS format with the following columns:\n\n            - onset: Start time of the postural transition in second.\n            - duration: Duration of the postural transition in second.\n            - event_type: Type of the event which is postural transition.\n            - tracking_systems: Name of the tracking systems.\n            - tracked_points: Name of the tracked points on the body.\n    \"\"\"\n    # check if dt_data is a pandas Series with datetime values\n    if dt_data is not None:\n        # Ensure dt_data is a pandas Series\n        if not isinstance(dt_data, pd.Series):\n            raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n        # Ensure dt_data has datetime values\n        if not pd.api.types.is_datetime64_any_dtype(dt_data):\n            raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n        # Ensure dt_data has the same length as accel_data and gyro_data\n        if len(dt_data) != len(accel_data):\n            raise ValueError(\n                \"dt_data must be a pandas Series with the same length as accel_data and gyro_data\"\n            )\n\n    # Check if data is a DataFrame\n    if not isinstance(accel_data, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame\")\n\n    if not isinstance(gyro_data, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame\")\n\n    # Error handling for invalid input data\n    if not isinstance(accel_data, pd.DataFrame) or accel_data.shape[1] != 3:\n        raise ValueError(\n            \"Input accelerometer data must be a DataFrame with 3 columns for x, y, and z axes.\"\n        )\n\n    if not isinstance(gyro_data, pd.DataFrame) or gyro_data.shape[1] != 3:\n        raise ValueError(\n            \"Input gyro data must be a DataFrame with 3 columns for x, y, and z axes.\"\n        )\n\n    # Check if sampling frequency is positive\n    if sampling_freq_Hz &lt;= 0:\n        raise ValueError(\"Sampling frequency must be positive\")\n\n    # Check if plot_results is a boolean\n    if not isinstance(plot_results, bool):\n        raise ValueError(\"plot_results must be a boolean value\")\n\n    # Calculate sampling period\n    sampling_period = 1 / sampling_freq_Hz\n\n    gyro_data = np.deg2rad(gyro_data)\n\n    # Ensure that acceleration and gyroscope arrays are C-contiguous for efficient processing\n    accel_data = np.ascontiguousarray(accel_data)\n    self.gyro_data = np.ascontiguousarray(gyro_data)\n\n    # Initialize the Versatile Quaternion-based Filter (VQF) with the calculated sampling period\n    vqf = VQF(sampling_period)\n\n    # Perform orientation estimation using VQF\n    # This step estimates the orientation of the IMU and returns quaternion-based orientation estimates\n    out_orientation_est = vqf.updateBatch(self.gyro_data, accel_data)\n\n    # Initialize arrays to store the updated acceleration and gyroscope data\n    accel_updated = np.zeros_like(accel_data)\n    gyro_updated = np.zeros_like(self.gyro_data)\n\n    # Apply quaternion-based orientation correction to the accelerometer data\n    # This step corrects the accelerometer data based on the estimated orientation\n    for t in range(accel_updated.shape[0]):\n        accel_updated[t, :] = vqf.quatRotate(\n            out_orientation_est[\"quat6D\"][t, :], accel_data[t, :]\n        )\n\n    # Apply quaternion-based orientation correction to the gyroscope data\n    # This step corrects the gyroscope data based on the estimated orientation\n    for t in range(gyro_updated.shape[0]):\n        gyro_updated[t, :] = vqf.quatRotate(\n            out_orientation_est[\"quat6D\"][t, :], self.gyro_data[t, :]\n        )\n\n    # Convert updated acceleration data back from \"m/s^2\" to \"g\" units\n    # This step reverses the initial conversion applied to the acceleration data\n    accel = accel_updated / 9.81\n\n    # Convert back gyro data from rad/s to deg/s after orientation estimation\n    self.gyro = np.rad2deg(gyro_updated)\n\n    # Compute the range of gyro signals for x and y components\n    range_x = np.ptp(self.gyro[:, 0])  # gyro x-axis\n    range_y = np.ptp(self.gyro[:, 1])  # gyro y-axis\n\n    # Compute the variance of gyro signals for x and y components\n    var_x = np.var(self.gyro[:, 0])  # gyro x-axis\n    var_y = np.var(self.gyro[:, 1])  # gyro y-axis\n\n    # Determine which component of gyro corresponds to the mediolateral direction\n    if range_x &gt; range_y or var_x &gt; var_y:\n        # X component has a larger range/variance, likely mediolateral\n        self.gyro_mediolateral = self.gyro[:, 0]  # Gyro x-axis is mediolateral\n    else:\n        # Y component has a larger range/variance, likely mediolateral\n        self.gyro_mediolateral = self.gyro[:, 1]  # Gyro y-axis is mediolateral\n\n    # Calculate timestamps to use in next calculation\n    time = np.arange(1, len(accel[:, 0]) + 1) * sampling_period\n\n    # Estimate tilt angle in deg\n    tilt_angle_deg = preprocessing.tilt_angle_estimation(\n        data=self.gyro_mediolateral, sampling_frequency_hz=sampling_freq_Hz\n    )\n\n    # Convert tilt angle to rad\n    tilt_angle_rad = np.deg2rad(tilt_angle_deg)\n\n    # Calculate sine of the tilt angle in radians\n    tilt_sin = np.sin(tilt_angle_rad)\n\n    # Apply wavelet decomposition with level of 3\n    tilt_dwt_3 = preprocessing.wavelet_decomposition(\n        data=tilt_sin, level=3, wavetype=\"coif5\"\n    )\n\n    # Apply wavelet decomposition with level of 10\n    tilt_dwt_10 = preprocessing.wavelet_decomposition(\n        data=tilt_sin, level=10, wavetype=\"coif5\"\n    )\n\n    # Calculate difference\n    tilt_dwt = tilt_dwt_3 - tilt_dwt_10\n\n    # Find peaks in denoised tilt signal\n    self.local_peaks, _ = scipy.signal.find_peaks(\n        tilt_dwt, height=0.2, prominence=0.2\n    )\n\n    # Calculate the norm of acceleration\n    accel_norm = np.sqrt(accel[:, 0] ** 2 + accel[:, 1] ** 2 + accel[:, 2] ** 2)\n\n    # Calculate absolute value of the acceleration signal\n    accel_norm = np.abs(accel_norm)\n\n    # Detect stationary parts of the signal based on the deifned threshold\n    stationary_1 = accel_norm &lt; self.thr_accel_var\n    stationary_1 = (stationary_1).astype(int)\n\n    # Compute the variance of the moving window acceleration\n    accel_var = preprocessing.moving_var(data=accel_norm, window=sampling_freq_Hz)\n\n    # Calculate stationary_2 from acceleration variance\n    stationary_2 = (accel_var &lt;= self.thr_gyro_var).astype(int)\n\n    # Calculate stationary of gyro variance\n    gyro_norm = np.sqrt(\n        self.gyro[:, 0] ** 2 + self.gyro[:, 1] ** 2 + self.gyro[:, 2] ** 2\n    )\n\n    # Compute the variance of the moving window of gyro\n    gyro_var = preprocessing.moving_var(data=gyro_norm, window=sampling_freq_Hz)\n\n    # Calculate stationary of gyro variance\n    stationary_3 = (gyro_var &lt;= self.thr_gyro_var).astype(int)\n\n    # Perform stationarity checks\n    stationary = stationary_1 &amp; stationary_2 &amp; stationary_3\n\n    # Remove consecutive True values in the stationary array\n    for i in range(len(stationary) - 1):\n        if stationary[i] == 1:\n            if stationary[i + 1] == 0:\n                stationary[i] = 0\n\n    # Set initial period and check if enough stationary data is available\n    # Stationary periods are defined as the episodes when the lower back of the participant was almost not moving and not rotating.\n    # The thresholds are determined based on the training data set.\n    init_period = 0.1\n\n    if (\n        np.sum(stationary[: int(sampling_freq_Hz * init_period)]) &gt;= 200\n    ):  # If the process is stationary in the first 2s\n        # If there is enough stationary data, perform sensor fusion using accelerometer and gyro data\n        (\n            postural_transition_onset,\n            postural_transition_type,\n            self.postural_transition_angle,\n            duration,\n            self.flexion_max_vel,\n            self.extension_max_vel,\n        ) = preprocessing.process_postural_transitions_stationary_periods(\n            time,\n            accel,\n            self.gyro,\n            stationary,\n            tilt_angle_deg,\n            sampling_period,\n            sampling_freq_Hz,\n            init_period,\n            self.local_peaks,\n        )\n\n        # Create a DataFrame with postural transition information\n        postural_transitions_ = pd.DataFrame(\n            {\n                \"onset\": postural_transition_onset,\n                \"duration\": duration,\n                \"event_type\": postural_transition_type,\n                \"tracking_systems\": tracking_system,\n                \"tracked_points\": tracked_point,\n            }\n        )\n\n    else:\n        # Handle cases where there is not enough stationary data\n        # Find indices where the product of consecutive changes sign, indicating a change in direction\n        iZeroCr = np.where(\n            (self.gyro_mediolateral[:-1] * self.gyro_mediolateral[1:]) &lt; 0\n        )[0]\n\n        # Calculate the difference between consecutive values\n        gyro_y_diff = np.diff(self.gyro_mediolateral, axis=0)\n\n        # Initialize arrays to store left and right indices for each local peak\n        # Initialize left side indices with ones\n        self.left_side = np.ones_like(self.local_peaks)\n\n        # Initialize right side indices with length of gyro data\n        self.right_side = len(self.gyro_mediolateral) * np.ones_like(\n            self.local_peaks\n        )\n\n        # Loop through each local peak\n        for i in range(len(self.local_peaks)):\n            # Get the index of the current local peak\n            postural_transitions = self.local_peaks[i]\n\n            # Calculate distances to all zero-crossing points relative to the peak\n            dist2peak = iZeroCr - postural_transitions\n\n            # Extract distances to zero-crossing points on the left side of the peak\n            dist2peak_left_side = dist2peak[dist2peak &lt; 0]\n\n            # Extract distances to zero-crossing points on the right side of the peak\n            dist2peak_right_side = dist2peak[dist2peak &gt; 0]\n\n            # Iterate over distances to zero-crossing points on the left side of the peak (in reverse order)\n            for j in range(len(dist2peak_left_side) - 1, -1, -1):\n                # Check if slope is down and the left side not too close to the peak (more than 200ms)\n                if gyro_y_diff[\n                    postural_transitions + dist2peak_left_side[j]\n                ] &lt; 0 and -dist2peak_left_side[j] &gt; (0.2 * sampling_freq_Hz):\n                    if j &gt; 0:\n                        # If the left side peak is far enough or small enough\n                        if (\n                            dist2peak_left_side[j] - dist2peak_left_side[j - 1]\n                        ) &gt;= (0.2 * sampling_freq_Hz) or (\n                            tilt_angle_deg[\n                                postural_transitions + dist2peak_left_side[j - 1]\n                            ]\n                            - tilt_angle_deg[\n                                postural_transitions + dist2peak_left_side[j]\n                            ]\n                        ) &gt; 1:\n                            # Store the index of the left side\n                            self.left_side[i] = (\n                                postural_transitions + dist2peak_left_side[j]\n                            )\n                            break\n                        else:\n                            self.left_side[i] = (\n                                postural_transitions + dist2peak_left_side[j]\n                            )\n                            break\n            for j in range(len(dist2peak_right_side)):\n                if gyro_y_diff[\n                    postural_transitions + dist2peak_right_side[j]\n                ] &lt; 0 and dist2peak_right_side[j] &gt; (0.2 * sampling_freq_Hz):\n                    self.right_side[i] = (\n                        postural_transitions + dist2peak_right_side[j]\n                    )\n                    break\n\n            # Calculate postural transition angle\n            self.postural_transition_angle = np.abs(\n                tilt_angle_deg[self.local_peaks] - tilt_angle_deg[self.left_side]\n            )\n            if self.left_side[0] == 1:\n                self.postural_transition_angle[0] = abs(\n                    tilt_angle_deg[self.local_peaks[0]]\n                    - tilt_angle_deg[self.right_side[0]]\n                )\n\n            # Calculate duration of each postural transition\n            duration = (self.right_side - self.left_side) / sampling_freq_Hz\n\n            # Convert peak times to integers\n            postural_transition_onset = time[self.local_peaks]\n\n    # Remove too small postural transitions\n    i = self.postural_transition_angle &gt;= self.min_postural_transition_angle_deg\n    postural_transition_onset = self.left_side[i] / sampling_freq_Hz\n    duration = duration[i]\n\n    # Check if dt_data is provided for datetime conversion\n    if dt_data is not None:\n        # Convert onset times to datetime format\n        starting_datetime = dt_data.iloc[\n            0\n        ]  # Assuming dt_data is aligned with the signal data\n        postural_transition_onset = [\n            starting_datetime + pd.Timedelta(seconds=t)\n            for t in postural_transition_onset\n        ]\n\n    # Create a DataFrame with postural transition information\n    postural_transitions_ = pd.DataFrame(\n        {\n            \"onset\": postural_transition_onset,\n            \"duration\": duration,\n            \"event_type\": \"postural transition\",\n            \"tracking_systems\": tracking_system,\n            \"tracked_points\": tracked_point,\n        }\n    )\n\n    # Assign the DataFrame to the 'postural_transitions_' attribute\n    self.postural_transitions_ = postural_transitions_\n\n    # If Plot_results set to true\n    if plot_results:\n        viz_utils.plot_postural_transitions(\n            accel,\n            self.gyro,\n            postural_transitions_,\n            sampling_freq_Hz,\n        )\n\n    # Return an instance of the class\n    return self\n</code></pre>"},{"location":"modules/ptd/#modules.ptd._pham.PhamPosturalTransitionDetection.spatio_temporal_parameters","title":"<code>spatio_temporal_parameters()</code>","text":"<p>Extracts spatio-temporal parameters of the detected postural transitions.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The spatio-temporal parameter information is stored in the 'spatio_temporal_parameters' attribute, which is a pandas DataFrame as:</p> <ul> <li>type_of_postural_transition: Type of postural transition which is either \"sit to stand\" or \"stand to sit\".</li> <li>angel_of_postural_transition: Angle of the postural transition in degrees.</li> <li>maximum_flexion_velocity: Maximum flexion velocity in deg/s.</li> <li>maximum_extension_velocity: Maximum extension velocity in deg/s.</li> </ul> Source code in <code>kielmat/modules/ptd/_pham.py</code> <pre><code>def spatio_temporal_parameters(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Extracts spatio-temporal parameters of the detected postural transitions.\n\n    Returns:\n        The spatio-temporal parameter information is stored in the 'spatio_temporal_parameters' attribute, which is a pandas DataFrame as:\n\n            - type_of_postural_transition: Type of postural transition which is either \"sit to stand\" or \"stand to sit\".\n            - angel_of_postural_transition: Angle of the postural transition in degrees.\n            - maximum_flexion_velocity: Maximum flexion velocity in deg/s.\n            - maximum_extension_velocity: Maximum extension velocity in deg/s.\n    \"\"\"\n    if self.postural_transitions_ is None:\n        raise ValueError(\n            \"No postural transition detected. Please run the detect method first.\"\n        )\n\n    # Initialize list for postural transition types\n    postural_transition_type = []\n\n    # Distinguish between different types of postural transitions\n    for i in range(len(self.local_peaks)):\n        gyro_temp = self.gyro_mediolateral[self.left_side[i] : self.right_side[i]]\n        min_peak = np.min(gyro_temp)\n        max_peak = np.max(gyro_temp)\n        if (abs(max_peak) - abs(min_peak)) &gt; 0.5:\n            postural_transition_type.append(\"sit to stand\")\n        else:\n            postural_transition_type.append(\"stand to sit\")\n\n    # Postural transition type and angle determination\n    i = self.postural_transition_angle &gt;= self.min_postural_transition_angle_deg\n    postural_transition_type = [\n        postural_transition_type[idx]\n        for idx, val in enumerate(postural_transition_type)\n        if i[idx]\n    ]\n    self.postural_transition_angle = self.postural_transition_angle[i]\n\n    # Calculate maximum flexion velocity and maximum extension velocity\n    flexion_max_vel = np.zeros_like(self.local_peaks)\n    extension_max_vel = np.zeros_like(self.local_peaks)\n\n    for id in range(len(self.local_peaks)):\n        flexion_max_vel[id] = max(\n            abs(self.gyro_mediolateral[self.left_side[id] : self.local_peaks[id]])\n        )\n        extension_max_vel[id] = max(\n            abs(self.gyro_mediolateral[self.local_peaks[id] : self.right_side[id]])\n        )\n\n    # Filter the velocities based on valid indices\n    flexion_max_vel = [\n        flexion_max_vel[idx] for idx, val in enumerate(flexion_max_vel) if i[idx]\n    ]\n\n    # Calculate maximum extension velocity\n    extension_max_vel = [\n        extension_max_vel[idx]\n        for idx, val in enumerate(extension_max_vel)\n        if i[idx]\n    ]\n\n    # Create a DataFrame with the calculated spatio-temporal parameters\n    self.parameters_ = pd.DataFrame(\n        {\n            \"type_of_postural_transition\": postural_transition_type,\n            \"angle_of_postural_transition\": self.postural_transition_angle,\n            \"maximum_flexion_velocity\": flexion_max_vel,\n            \"maximum_extension_velocity\": extension_max_vel,\n        }\n    )\n\n    # Set the index name to 'postural transition id'\n    self.parameters_.index.name = \"postural transition id\"\n</code></pre>"},{"location":"modules/td/","title":"Turn Detection","text":""},{"location":"modules/td/#turn-detection-pham","title":"Turn Detection (Pham)","text":"<p>This algorithm aims to detect turns using accelerometer and gyroscope data collected from a lower back inertial measurement unit (IMU) sensor.</p> <p>The core of the algorithm lies in the detect method, where turns are identified using accelerometer and gyroscope data. The method first processes the gyro data, converting it to rad/s if needed and computing the variance to identify periods of low variance, which may indicate bias. It then calculates the gyro bias and subtracts it from the original gyro signal to remove any biases. Next, the yaw angle is computed by integrating the vertical component of the gyro data, and zero-crossings indices are found to detect turns. Then, turns are identified based on significant changes in the yaw angle.</p> <p>The algorithm also accounts for hesitations, which are brief pauses or fluctuations in the signal that may occur within a turn. Hesitations are marked based on specific conditions related to the magnitude and continuity of the yaw angle changes.</p> <p>Then, the detected turns are characterized by their onset and duration. Turns with angles equal to or greater than 90 degrees and durations between 0.5 and 10 seconds are selected for further analysis. Finally, the detected turns along with their characteristics (onset, duration, etc.) are stored in a pandas DataFrame (turns_ attribute).</p> <p>In addition, spatial-temporal parameters are calculated using detected turns and their characteristics by the spatio_temporal_parameters method. As a return, the turn id along with its spatial-temporal parameters including direction (left or right), angle of turn and peak angular velocity are stored in a pandas DataFrame (parameters_ attribute).</p> <p>Optionally, if plot_results is set to True, the algorithm generates a plot visualizing the accelerometer and gyroscope data alongside the detected turns. This visualization aids in the qualitative assessment of the algorithm's performance and provides insights into the dynamics of the detected turns.</p> <p>Methods:</p> Name Description <code>detect</code> <p>Detects turns using accelerometer and gyro signals.</p> <p>Returns:     PhamTurnDetection: an instance of the class with the detected turns     stored in the 'turns_' attribute.</p> <code>spatio_temporal_parameters</code> <p>Extracts spatio-temporal parameters of the detected turns.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; pham = PhamTurnDetection()\n&gt;&gt;&gt; pham.detect(\n        accel_data=accel_data,\n        gyro_data=gyro_data,\n        gyro_vertical=\"pelvis_GYRO_x\",\n        sampling_freq_Hz=200.0,\n        tracking_system=\"imu\",\n        tracked_point=\"LowerBack\",\n        plot_results=False\n        )\n&gt;&gt;&gt; print(pham.turns_)\n        onset   duration   event_type   tracking_systems    tracked_points\n    0   4.04    3.26       turn         imu                 LowerBack\n    1   9.44    3.35       turn         imu                 LowerBack\n</code></pre> <pre><code>&gt;&gt;&gt; pham.spatio_temporal_parameters()\n&gt;&gt;&gt; print(pham.parameters_)\n        direction_of_turn   angle_of_turn   peak_angular_velocity\n    0   left               -197.55          159.45\n    1   right               199.69          144.67\n</code></pre> References <p>[1] Pham et al. (2017). Algorithm for Turning Detection and Analysis Validated under Home-Like Conditions... https://doi.org/10.3389/fneur.2017.00135</p> Source code in <code>kielmat/modules/td/_pham.py</code> <pre><code>class PhamTurnDetection:\n    \"\"\"\n    This algorithm aims to detect turns using accelerometer and gyroscope data collected from a lower back\n    inertial measurement unit (IMU) sensor.\n\n    The core of the algorithm lies in the detect method, where turns are identified using accelerometer and\n    gyroscope data. The method first processes the gyro data, converting it to rad/s if needed and computing\n    the variance to identify periods of low variance, which may indicate bias. It then calculates the gyro bias\n    and subtracts it from the original gyro signal to remove any biases. Next, the yaw angle is computed by\n    integrating the vertical component of the gyro data, and zero-crossings indices are found to detect turns.\n    Then, turns are identified based on significant changes in the yaw angle.\n\n    The algorithm also accounts for hesitations, which are brief pauses or fluctuations in the signal that may\n    occur within a turn. Hesitations are marked based on specific conditions related to the magnitude and\n    continuity of the yaw angle changes.\n\n    Then, the detected turns are characterized by their onset and duration. Turns with angles equal to or greater\n    than 90 degrees and durations between 0.5 and 10 seconds are selected for further analysis. Finally, the detected\n    turns along with their characteristics (onset, duration, etc.) are stored in a pandas DataFrame\n    (turns_ attribute).\n\n    In addition, spatial-temporal parameters are calculated using detected turns and their characteristics by\n    the spatio_temporal_parameters method. As a return, the turn id along with its spatial-temporal parameters\n    including direction (left or right), angle of turn and peak angular velocity are stored in a pandas DataFrame\n    (parameters_ attribute).\n\n    Optionally, if plot_results is set to True, the algorithm generates a plot visualizing the accelerometer\n    and gyroscope data alongside the detected turns. This visualization aids in the qualitative assessment of\n    the algorithm's performance and provides insights into the dynamics of the detected turns.\n\n    Methods:\n        detect(accel_data, gyro_data, gyro_vertical, sampling_freq_Hz, dt_data, tracking_system, tracked_point, plot_results):\n            Detects turns using accelerometer and gyro signals.\n\n            Returns:\n                PhamTurnDetection: an instance of the class with the detected turns\n                stored in the 'turns_' attribute.\n\n        spatio_temporal_parameters():\n            Extracts spatio-temporal parameters of the detected turns.\n\n    Examples:\n        &gt;&gt;&gt; pham = PhamTurnDetection()\n        &gt;&gt;&gt; pham.detect(\n                accel_data=accel_data,\n                gyro_data=gyro_data,\n                gyro_vertical=\"pelvis_GYRO_x\",\n                sampling_freq_Hz=200.0,\n                tracking_system=\"imu\",\n                tracked_point=\"LowerBack\",\n                plot_results=False\n                )\n        &gt;&gt;&gt; print(pham.turns_)\n                onset   duration   event_type   tracking_systems    tracked_points\n            0   4.04    3.26       turn         imu                 LowerBack\n            1   9.44    3.35       turn         imu                 LowerBack\n\n        &gt;&gt;&gt; pham.spatio_temporal_parameters()\n        &gt;&gt;&gt; print(pham.parameters_)\n                direction_of_turn   angle_of_turn   peak_angular_velocity\n            0   left               -197.55          159.45\n            1   right               199.69          144.67\n\n    References:\n        [1] Pham et al. (2017). Algorithm for Turning Detection and Analysis Validated under Home-Like Conditions... https://doi.org/10.3389/fneur.2017.00135\n    \"\"\"\n\n    def __init__(\n        self,\n        thr_gyro_var: float = 2e-4,\n        min_turn_duration_s: float = 0.5,\n        max_turn_duration_s: float = 10,\n        min_turn_angle_deg: float = 90,\n    ):\n        \"\"\"\n        Initializes the PhamTurnDetection instance.\n\n        Args:\n            thr_gyro_var (float): Threshold value for identifying periods where the variance is low. Default is 2e-4.\n            min_turn_duration_s (float): Minimum duration of a turn in seconds. Default is 0.5.\n            max_turn_duration_s (float): Maximum duration of a turn in seconds. Default is 10.\n            min_turn_angle_deg (float): Minimum angle of a turn in degrees. Default is 90.\n        \"\"\"\n        self.thr_gyro_var = thr_gyro_var\n        self.min_turn_duration_s = min_turn_duration_s\n        self.max_turn_duration_s = max_turn_duration_s\n        self.min_turn_angle_deg = min_turn_angle_deg\n\n    def detect(\n        self,\n        accel_data: pd.DataFrame,\n        gyro_data: pd.DataFrame,\n        gyro_vertical: str,\n        sampling_freq_Hz: float,\n        dt_data: Optional[pd.Series] = None,\n        tracking_system: Optional[str] = None,\n        tracked_point: Optional[str] = None,\n        plot_results: bool = False,\n    ) -&gt; pd.DataFrame:\n        \"\"\"\n        Detects truns based on the input accelerometer and gyro data.\n\n        Args:\n            accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n            gyro_data (pd.DataFrame): Input gyro data (N, 3) for x, y, and z axes.\n            gyro_vertical (str): The column name that corresponds to the vertical component gyro.\n            sampling_freq_Hz (float): Sampling frequency of the input data in Hz.\n            dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n            tracking_system (str, optional): Tracking systems.\n            tracked_point (str, optional): Tracked points on the body.\n            plot_results (bool, optional): If True, generates a plot. Default is False.\n\n        Returns:\n            The turns information is stored in the 'turns_' attribute, which is a pandas DataFrame in BIDS format with the following information:\n\n                - onset: Start time of the turn in second.\n                - duration: Duration of the turn in second.\n                - event_type: Type of the event (turn).\n                - tracking_systems: Name of the tracking systems.\n                - tracked_points: Name of the tracked points on the body.\n        \"\"\"\n        # check if dt_data is a pandas Series with datetime values\n        if dt_data is not None:\n            # Ensure dt_data is a pandas Series\n            if not isinstance(dt_data, pd.Series):\n                raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n            # Ensure dt_data has datetime values\n            if not pd.api.types.is_datetime64_any_dtype(dt_data):\n                raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n            # Ensure dt_data has the same length as input data\n            if len(dt_data) != len(accel_data):\n                raise ValueError(\n                    \"dt_data must be a series with the same length as data\"\n                )\n\n        # Check if data is a DataFrame\n        if not isinstance(accel_data, pd.DataFrame):\n            raise ValueError(\"Acceleration data must be a pandas DataFrame\")\n\n        if not isinstance(gyro_data, pd.DataFrame):\n            raise ValueError(\"Gyro data must be a pandas DataFrame\")\n\n        # Error handling for invalid input data\n        if not isinstance(accel_data, pd.DataFrame) or accel_data.shape[1] != 3:\n            raise ValueError(\n                \"Accelerometer data must be a DataFrame with 3 columns for x, y, and z axes.\"\n            )\n\n        if not isinstance(gyro_data, pd.DataFrame) or gyro_data.shape[1] != 3:\n            raise ValueError(\n                \"Gyro data must be a DataFrame with 3 columns for x, y, and z axes.\"\n            )\n\n        # Check if sampling frequency is positive\n        if sampling_freq_Hz &lt;= 0:\n            raise ValueError(\"Sampling frequency must be positive\")\n\n        # Check if plot_results is a boolean\n        if not isinstance(plot_results, bool):\n            raise ValueError(\"plot_results must be a boolean value\")\n\n        # Select acceleration data and convert it to numpy array format\n        accel = accel_data.to_numpy()\n\n        # Select gyro data and convert it to numpy array format\n        gyro = gyro_data.to_numpy()\n        self.gyro = gyro\n\n        # Convert acceleration data from \"m/s^2\" to \"g\"\n        accel /= 9.81\n\n        # Convert gyro data from deg/s to rad/s\n        gyro = np.deg2rad(gyro)\n\n        # Compute the variance of the moving window of gyro signal\n        gyro_vars = []\n\n        for i in range(3):\n            gyro_var = preprocessing.moving_var(gyro[:, i], sampling_freq_Hz)\n            gyro_vars.append(gyro_var)\n        gyro_vars = np.array(gyro_vars)\n        gyro_vars = np.mean(gyro_vars, axis=0)\n\n        # Find bias period\n        bias_periods = np.where(gyro_vars &lt; self.thr_gyro_var)[0]\n\n        # Remove the last sampling_freq_Hz samples from bias_periods to avoid edge effects\n        bias_periods = bias_periods[bias_periods &lt; (len(gyro_vars) - sampling_freq_Hz)]\n\n        # Compute gyro bias (mean of gyro signal during bias periods)\n        self.gyro_bias = np.mean(gyro[bias_periods, :], axis=0)\n\n        # Subtract gyro bias from the original gyro signal\n        gyro_unbiased = gyro - self.gyro_bias\n\n        # Get the index of the vertical component of gyro from data\n        gyro_vertical_index = [\n            i for i, col in enumerate(gyro_data) if gyro_vertical in col\n        ][0]\n\n        # Integrate x component of the gyro signal to get yaw angle (also convert gyro unit to deg/s)\n        self.yaw = (\n            scipy.integrate.cumulative_trapezoid(\n                np.rad2deg(gyro_unbiased[:, gyro_vertical_index]), initial=0\n            )\n            / sampling_freq_Hz\n        )\n\n        # Find zero-crossings indices\n        self.index_zero_crossings = np.where(\n            np.diff(np.sign(gyro[:, gyro_vertical_index]))\n        )[0]\n\n        # Calculate turns from yaw angle\n        self.turns_all = (\n            self.yaw[self.index_zero_crossings[1:]]\n            - self.yaw[self.index_zero_crossings[:-1]]\n        )\n\n        # Marks hesitations in the signal\n        # Initialize an array to mark hesitations\n        hesitation_markers = np.zeros(len(self.turns_all))\n\n        # Loop through each index in the turns_all array\n        for i in range(len(self.turns_all)):\n            # Check if the absolute value of the turn angle at index i is greater than or equal to 10\n            if abs(self.turns_all[i]) &gt;= 10:\n                # Loop to search for potential hesitations\n                for j in range(i + 1, len(self.turns_all)):\n                    # Check if the difference between current index and i exceeds 4, or if the time between zero crossings exceeds half a second\n                    if (j - i) &gt; 4 or (\n                        self.index_zero_crossings[j] - self.index_zero_crossings[i + 1]\n                        &gt; (sampling_freq_Hz / 2)\n                    ):\n                        # Break the loop if the conditions for hesitation are not met\n                        break\n                    else:\n                        # Check conditions for hesitation:\n                        # - Absolute values of both turns are greater than or equal to 10\n                        # - The relative change in yaw angle is less than 20% of the minimum turn angle\n                        # - The signs of both turns are the same\n                        if (\n                            abs(self.turns_all[i]) &gt;= 10\n                            and abs(self.turns_all[j]) &gt;= 10\n                            and abs(\n                                self.yaw[self.index_zero_crossings[i + 1]]\n                                - self.yaw[self.index_zero_crossings[j]]\n                            )\n                            / min(abs(self.turns_all[i]), abs(self.turns_all[j]))\n                            &lt; 0.2\n                            and np.sign(self.turns_all[i]) == np.sign(self.turns_all[j])\n                        ):\n                            # Mark the range between i and j (inclusive) as a hesitation\n                            hesitation_markers[i : j + 1] = 1\n                            # Break the inner loop as the hesitation condition is met\n                            break\n\n        # Initialize variables to store data related to turns without hesitation\n        sum_temp = 0  # Temporary sum for accumulating turn angles\n        turns_no_hesitation = []  # List to store turn angles without hesitation\n        flags_start_no_hesitation = (\n            []\n        )  # List to store start indices of turns without hesitation\n        flags_end_no_hesitation = (\n            []\n        )  # List to store end indices of turns without hesitation\n        durations_no_hesitation = (\n            []\n        )  # List to store durations of turns without hesitation\n        z = 1  # Index for keeping track of the current turn\n\n        # Iterate through each index in the hesitation_markers array\n        for i in range(len(hesitation_markers)):\n            # Check if there is a hesitation marker at the current index\n            if hesitation_markers[i] == 1:\n                # Check if sum_temp is zero, indicating the start of a new turn\n                if sum_temp == 0:\n                    f1 = self.index_zero_crossings[\n                        i\n                    ]  # Store the start index of the turn\n\n                # Check if the absolute value of the turn angle is greater than or equal to 10\n                if abs(self.turns_all[i]) &gt;= 10:\n                    try:\n                        # Check if the next index also has a hesitation marker\n                        if hesitation_markers[i + 1] != 0:\n                            # Iterate through subsequent indices to find the end of the turn\n                            for j in range(i + 1, len(hesitation_markers)):\n                                # Check if the absolute value of the turn angle is greater than or equal to 10\n                                if abs(self.turns_all[j]) &gt;= 10:\n                                    # Check if the signs of the turn angles are the same\n                                    if np.sign(self.turns_all[j]) == np.sign(\n                                        self.turns_all[i]\n                                    ):\n                                        sum_temp += self.turns_all[\n                                            i\n                                        ]  # Accumulate the turn angle\n                                    else:\n                                        f2 = hesitation_markers[\n                                            i + 1\n                                        ]  # Store the end index of the turn\n                                        sum_temp += self.turns_all[\n                                            i\n                                        ]  # Accumulate the turn angle\n                                        turns_no_hesitation.append(\n                                            sum_temp\n                                        )  # Store the turn angle without hesitation\n                                        flags_start_no_hesitation.append(\n                                            f1\n                                        )  # Store the start index of the turn\n                                        flags_end_no_hesitation.append(\n                                            f2\n                                        )  # Store the end index of the turn\n                                        durations_no_hesitation.append(\n                                            (f2 - f1) / sampling_freq_Hz\n                                        )  # Calculate and store the duration of the turn\n                                        z += 1  # Increment the turn index\n                                        sum_temp = 0  # Reset the temporary sum\n                                        del (\n                                            f1,\n                                            f2,\n                                        )  # Delete stored indices to avoid conflicts\n                                    break  # Exit the loop once the turn is processed\n                        else:\n                            f2 = self.index_zero_crossings[\n                                i + 1\n                            ]  # Store the end index of the turn\n                            sum_temp += self.turns_all[i]  # Accumulate the turn angle\n                            turns_no_hesitation.append(\n                                sum_temp\n                            )  # Store the turn angle without hesitation\n                            flags_start_no_hesitation.append(\n                                f1\n                            )  # Store the start index of the turn\n                            flags_end_no_hesitation.append(\n                                f2\n                            )  # Store the end index of the turn\n                            durations_no_hesitation.append(\n                                (f2 - f1) / sampling_freq_Hz\n                            )  # Calculate and store the duration of the turn\n                            z += 1  # Increment the turn index\n                            del f1, f2  # Delete stored indices to avoid conflicts\n                            sum_temp = 0  # Reset the temporary sum\n                    except:\n                        f2 = self.index_zero_crossings[\n                            i + 1\n                        ]  # Store the end index of the turn\n                        sum_temp += self.turns_all[i]  # Accumulate the turn angle\n                        turns_no_hesitation.append(\n                            sum_temp\n                        )  # Store the turn angle without hesitation\n                        flags_start_no_hesitation.append(\n                            f1\n                        )  # Store the start index of the turn\n                        flags_end_no_hesitation.append(\n                            f2\n                        )  # Store the end index of the turn\n                        durations_no_hesitation.append(\n                            (f2 - f1) / sampling_freq_Hz\n                        )  # Calculate and store the duration of the turn\n                        z += 1\n                        del f1, f2\n                        sum_temp = 0\n                else:\n                    sum_temp += self.turns_all[\n                        i\n                    ]  # Accumulate the turn angle if it's smaller than 10 degrees\n            else:  # If there's no hesitation marker at the current index\n                turns_no_hesitation.append(self.turns_all[i])\n                flags_start_no_hesitation.append(self.index_zero_crossings[i])\n                flags_end_no_hesitation.append(self.index_zero_crossings[i + 1])\n                durations_no_hesitation.append(\n                    (self.index_zero_crossings[i + 1] - self.index_zero_crossings[i])\n                    / sampling_freq_Hz\n                )  # Calculate and store the duration of the turn\n                z += 1  # Increment the turn index\n\n        # Initialize lists to store information about turns &gt;= 90 degrees\n        turns_90 = []\n        flags_start_90 = []\n        flags_end_90 = []\n\n        # Iterate through each turn without hesitation\n        for k in range(len(turns_no_hesitation)):\n            # Check if the turn angle is greater than or equal to 90 degrees\n            # and if the duration of the turn is between 0.5 and 10 seconds\n            if (\n                abs(turns_no_hesitation[k]) &gt;= self.min_turn_angle_deg\n                and durations_no_hesitation[k] &gt;= self.min_turn_duration_s\n                and durations_no_hesitation[k] &lt; self.max_turn_duration_s\n            ):\n                # If conditions are met, store information about the turn\n                turns_90.append(turns_no_hesitation[k])\n                flags_start_90.append(flags_start_no_hesitation[k])\n                flags_end_90.append(flags_end_no_hesitation[k])\n\n        # Initialize lists to store additional information about &gt;= 90 degree turns\n        duration_90 = []\n\n        # Assign detected truns attribute\n        self.turns_90 = turns_90\n        self.flags_start_90 = flags_start_90\n        self.flags_end_90 = flags_end_90\n\n        # Assign sampling frequency to the attribute\n        self.sampling_freq_Hz = sampling_freq_Hz\n\n        # Compute duration of the turn in seconds\n        for k in range(len(flags_start_90)):\n            # Compute duration of the turn in seconds\n            duration_nsamples = self.flags_end_90[k] - self.flags_start_90[k]\n            duration_90.append(duration_nsamples / sampling_freq_Hz)\n\n        # Create a DataFrame with postural transition information\n        self.turns_ = pd.DataFrame(\n            {\n                \"onset\": np.array(flags_start_90) / sampling_freq_Hz,\n                \"duration\": duration_90,\n                \"event_type\": \"turn\",\n                \"tracking_systems\": tracking_system,\n                \"tracked_points\": tracked_point,\n            }\n        )\n\n        # If original datetime is available, update the 'onset' and 'duration'\n        if dt_data is not None:\n            # Update the 'onset' based on the original datetime information\n            self.turns_[\"onset\"] = dt_data.iloc[flags_start_90].reset_index(drop=True)\n\n            # Update the 'duration' based on the difference between end and start indices\n            self.turns_[\"duration\"] = dt_data.iloc[flags_end_90].reset_index(\n                drop=True\n            ) - dt_data.iloc[flags_start_90].reset_index(drop=True)\n\n        # If Plot_results set to true\n        if plot_results:\n            viz_utils.plot_turns(accel, gyro, self.turns_, sampling_freq_Hz)\n\n        # Return an instance of the class\n        return self\n\n    def spatio_temporal_parameters(self) -&gt; pd.DataFrame:\n        \"\"\"\n        Extracts spatio-temporal parameters of the detected turns.\n\n        Returns:\n            The spatio-temporal parameter information is stored in the 'spatio_temporal_parameters' attribute, which is a pandas DataFrame as:\n\n                - direction_of_turn: Direction of turn which is either \"left\" or \"right\".\n                - angle_of_turn: Angle of the turn in degrees.\n                - peak_angular_velocity: Peak angular velocity during turn in deg/s.\n        \"\"\"\n        if self.turns_ is None:\n            raise ValueError(\"No turns detected. Please run the detect method first.\")\n\n        # Calculate additional information for each &gt;= 90 degree turn\n        peak_angular_velocities = []\n        diff_yaw = np.diff(self.yaw)\n\n        for k in range(len(self.flags_start_90)):\n            # Calculate peak angular velocity during the turn\n            diff_vector = abs(\n                diff_yaw[(self.flags_start_90[k] - 1) : (self.flags_end_90[k] - 1)]\n            )\n            peak_angular_velocities.append(np.max(diff_vector) * self.sampling_freq_Hz)\n\n        # Determine direction of the turn (left or right)\n        direction_of_turns = []\n\n        for turn_angle in self.turns_90:\n            if turn_angle &lt; 0:\n                direction_of_turns.append(\"left\")\n            else:\n                direction_of_turns.append(\"right\")\n\n        # Create a DataFrame with the calculated spatio-temporal parameters\n        self.parameters_ = pd.DataFrame(\n            {\n                \"direction_of_turn\": direction_of_turns,\n                \"angle_of_turn\": self.turns_90,\n                \"peak_angular_velocity\": peak_angular_velocities,\n            }\n        )\n\n        # Set the index name to 'turn id'\n        self.parameters_.index.name = \"turn id\"\n</code></pre>"},{"location":"modules/td/#modules.td._pham.PhamTurnDetection.__init__","title":"<code>__init__(thr_gyro_var=0.0002, min_turn_duration_s=0.5, max_turn_duration_s=10, min_turn_angle_deg=90)</code>","text":"<p>Initializes the PhamTurnDetection instance.</p> <p>Parameters:</p> Name Type Description Default <code>thr_gyro_var</code> <code>float</code> <p>Threshold value for identifying periods where the variance is low. Default is 2e-4.</p> <code>0.0002</code> <code>min_turn_duration_s</code> <code>float</code> <p>Minimum duration of a turn in seconds. Default is 0.5.</p> <code>0.5</code> <code>max_turn_duration_s</code> <code>float</code> <p>Maximum duration of a turn in seconds. Default is 10.</p> <code>10</code> <code>min_turn_angle_deg</code> <code>float</code> <p>Minimum angle of a turn in degrees. Default is 90.</p> <code>90</code> Source code in <code>kielmat/modules/td/_pham.py</code> <pre><code>def __init__(\n    self,\n    thr_gyro_var: float = 2e-4,\n    min_turn_duration_s: float = 0.5,\n    max_turn_duration_s: float = 10,\n    min_turn_angle_deg: float = 90,\n):\n    \"\"\"\n    Initializes the PhamTurnDetection instance.\n\n    Args:\n        thr_gyro_var (float): Threshold value for identifying periods where the variance is low. Default is 2e-4.\n        min_turn_duration_s (float): Minimum duration of a turn in seconds. Default is 0.5.\n        max_turn_duration_s (float): Maximum duration of a turn in seconds. Default is 10.\n        min_turn_angle_deg (float): Minimum angle of a turn in degrees. Default is 90.\n    \"\"\"\n    self.thr_gyro_var = thr_gyro_var\n    self.min_turn_duration_s = min_turn_duration_s\n    self.max_turn_duration_s = max_turn_duration_s\n    self.min_turn_angle_deg = min_turn_angle_deg\n</code></pre>"},{"location":"modules/td/#modules.td._pham.PhamTurnDetection.detect","title":"<code>detect(accel_data, gyro_data, gyro_vertical, sampling_freq_Hz, dt_data=None, tracking_system=None, tracked_point=None, plot_results=False)</code>","text":"<p>Detects truns based on the input accelerometer and gyro data.</p> <p>Parameters:</p> Name Type Description Default <code>accel_data</code> <code>DataFrame</code> <p>Input accelerometer data (N, 3) for x, y, and z axes.</p> required <code>gyro_data</code> <code>DataFrame</code> <p>Input gyro data (N, 3) for x, y, and z axes.</p> required <code>gyro_vertical</code> <code>str</code> <p>The column name that corresponds to the vertical component gyro.</p> required <code>sampling_freq_Hz</code> <code>float</code> <p>Sampling frequency of the input data in Hz.</p> required <code>dt_data</code> <code>Series</code> <p>Original datetime in the input data. If original datetime is provided, the output onset will be based on that.</p> <code>None</code> <code>tracking_system</code> <code>str</code> <p>Tracking systems.</p> <code>None</code> <code>tracked_point</code> <code>str</code> <p>Tracked points on the body.</p> <code>None</code> <code>plot_results</code> <code>bool</code> <p>If True, generates a plot. Default is False.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The turns information is stored in the 'turns_' attribute, which is a pandas DataFrame in BIDS format with the following information:</p> <ul> <li>onset: Start time of the turn in second.</li> <li>duration: Duration of the turn in second.</li> <li>event_type: Type of the event (turn).</li> <li>tracking_systems: Name of the tracking systems.</li> <li>tracked_points: Name of the tracked points on the body.</li> </ul> Source code in <code>kielmat/modules/td/_pham.py</code> <pre><code>def detect(\n    self,\n    accel_data: pd.DataFrame,\n    gyro_data: pd.DataFrame,\n    gyro_vertical: str,\n    sampling_freq_Hz: float,\n    dt_data: Optional[pd.Series] = None,\n    tracking_system: Optional[str] = None,\n    tracked_point: Optional[str] = None,\n    plot_results: bool = False,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Detects truns based on the input accelerometer and gyro data.\n\n    Args:\n        accel_data (pd.DataFrame): Input accelerometer data (N, 3) for x, y, and z axes.\n        gyro_data (pd.DataFrame): Input gyro data (N, 3) for x, y, and z axes.\n        gyro_vertical (str): The column name that corresponds to the vertical component gyro.\n        sampling_freq_Hz (float): Sampling frequency of the input data in Hz.\n        dt_data (pd.Series, optional): Original datetime in the input data. If original datetime is provided, the output onset will be based on that.\n        tracking_system (str, optional): Tracking systems.\n        tracked_point (str, optional): Tracked points on the body.\n        plot_results (bool, optional): If True, generates a plot. Default is False.\n\n    Returns:\n        The turns information is stored in the 'turns_' attribute, which is a pandas DataFrame in BIDS format with the following information:\n\n            - onset: Start time of the turn in second.\n            - duration: Duration of the turn in second.\n            - event_type: Type of the event (turn).\n            - tracking_systems: Name of the tracking systems.\n            - tracked_points: Name of the tracked points on the body.\n    \"\"\"\n    # check if dt_data is a pandas Series with datetime values\n    if dt_data is not None:\n        # Ensure dt_data is a pandas Series\n        if not isinstance(dt_data, pd.Series):\n            raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n        # Ensure dt_data has datetime values\n        if not pd.api.types.is_datetime64_any_dtype(dt_data):\n            raise ValueError(\"dt_data must be a pandas Series with datetime values\")\n\n        # Ensure dt_data has the same length as input data\n        if len(dt_data) != len(accel_data):\n            raise ValueError(\n                \"dt_data must be a series with the same length as data\"\n            )\n\n    # Check if data is a DataFrame\n    if not isinstance(accel_data, pd.DataFrame):\n        raise ValueError(\"Acceleration data must be a pandas DataFrame\")\n\n    if not isinstance(gyro_data, pd.DataFrame):\n        raise ValueError(\"Gyro data must be a pandas DataFrame\")\n\n    # Error handling for invalid input data\n    if not isinstance(accel_data, pd.DataFrame) or accel_data.shape[1] != 3:\n        raise ValueError(\n            \"Accelerometer data must be a DataFrame with 3 columns for x, y, and z axes.\"\n        )\n\n    if not isinstance(gyro_data, pd.DataFrame) or gyro_data.shape[1] != 3:\n        raise ValueError(\n            \"Gyro data must be a DataFrame with 3 columns for x, y, and z axes.\"\n        )\n\n    # Check if sampling frequency is positive\n    if sampling_freq_Hz &lt;= 0:\n        raise ValueError(\"Sampling frequency must be positive\")\n\n    # Check if plot_results is a boolean\n    if not isinstance(plot_results, bool):\n        raise ValueError(\"plot_results must be a boolean value\")\n\n    # Select acceleration data and convert it to numpy array format\n    accel = accel_data.to_numpy()\n\n    # Select gyro data and convert it to numpy array format\n    gyro = gyro_data.to_numpy()\n    self.gyro = gyro\n\n    # Convert acceleration data from \"m/s^2\" to \"g\"\n    accel /= 9.81\n\n    # Convert gyro data from deg/s to rad/s\n    gyro = np.deg2rad(gyro)\n\n    # Compute the variance of the moving window of gyro signal\n    gyro_vars = []\n\n    for i in range(3):\n        gyro_var = preprocessing.moving_var(gyro[:, i], sampling_freq_Hz)\n        gyro_vars.append(gyro_var)\n    gyro_vars = np.array(gyro_vars)\n    gyro_vars = np.mean(gyro_vars, axis=0)\n\n    # Find bias period\n    bias_periods = np.where(gyro_vars &lt; self.thr_gyro_var)[0]\n\n    # Remove the last sampling_freq_Hz samples from bias_periods to avoid edge effects\n    bias_periods = bias_periods[bias_periods &lt; (len(gyro_vars) - sampling_freq_Hz)]\n\n    # Compute gyro bias (mean of gyro signal during bias periods)\n    self.gyro_bias = np.mean(gyro[bias_periods, :], axis=0)\n\n    # Subtract gyro bias from the original gyro signal\n    gyro_unbiased = gyro - self.gyro_bias\n\n    # Get the index of the vertical component of gyro from data\n    gyro_vertical_index = [\n        i for i, col in enumerate(gyro_data) if gyro_vertical in col\n    ][0]\n\n    # Integrate x component of the gyro signal to get yaw angle (also convert gyro unit to deg/s)\n    self.yaw = (\n        scipy.integrate.cumulative_trapezoid(\n            np.rad2deg(gyro_unbiased[:, gyro_vertical_index]), initial=0\n        )\n        / sampling_freq_Hz\n    )\n\n    # Find zero-crossings indices\n    self.index_zero_crossings = np.where(\n        np.diff(np.sign(gyro[:, gyro_vertical_index]))\n    )[0]\n\n    # Calculate turns from yaw angle\n    self.turns_all = (\n        self.yaw[self.index_zero_crossings[1:]]\n        - self.yaw[self.index_zero_crossings[:-1]]\n    )\n\n    # Marks hesitations in the signal\n    # Initialize an array to mark hesitations\n    hesitation_markers = np.zeros(len(self.turns_all))\n\n    # Loop through each index in the turns_all array\n    for i in range(len(self.turns_all)):\n        # Check if the absolute value of the turn angle at index i is greater than or equal to 10\n        if abs(self.turns_all[i]) &gt;= 10:\n            # Loop to search for potential hesitations\n            for j in range(i + 1, len(self.turns_all)):\n                # Check if the difference between current index and i exceeds 4, or if the time between zero crossings exceeds half a second\n                if (j - i) &gt; 4 or (\n                    self.index_zero_crossings[j] - self.index_zero_crossings[i + 1]\n                    &gt; (sampling_freq_Hz / 2)\n                ):\n                    # Break the loop if the conditions for hesitation are not met\n                    break\n                else:\n                    # Check conditions for hesitation:\n                    # - Absolute values of both turns are greater than or equal to 10\n                    # - The relative change in yaw angle is less than 20% of the minimum turn angle\n                    # - The signs of both turns are the same\n                    if (\n                        abs(self.turns_all[i]) &gt;= 10\n                        and abs(self.turns_all[j]) &gt;= 10\n                        and abs(\n                            self.yaw[self.index_zero_crossings[i + 1]]\n                            - self.yaw[self.index_zero_crossings[j]]\n                        )\n                        / min(abs(self.turns_all[i]), abs(self.turns_all[j]))\n                        &lt; 0.2\n                        and np.sign(self.turns_all[i]) == np.sign(self.turns_all[j])\n                    ):\n                        # Mark the range between i and j (inclusive) as a hesitation\n                        hesitation_markers[i : j + 1] = 1\n                        # Break the inner loop as the hesitation condition is met\n                        break\n\n    # Initialize variables to store data related to turns without hesitation\n    sum_temp = 0  # Temporary sum for accumulating turn angles\n    turns_no_hesitation = []  # List to store turn angles without hesitation\n    flags_start_no_hesitation = (\n        []\n    )  # List to store start indices of turns without hesitation\n    flags_end_no_hesitation = (\n        []\n    )  # List to store end indices of turns without hesitation\n    durations_no_hesitation = (\n        []\n    )  # List to store durations of turns without hesitation\n    z = 1  # Index for keeping track of the current turn\n\n    # Iterate through each index in the hesitation_markers array\n    for i in range(len(hesitation_markers)):\n        # Check if there is a hesitation marker at the current index\n        if hesitation_markers[i] == 1:\n            # Check if sum_temp is zero, indicating the start of a new turn\n            if sum_temp == 0:\n                f1 = self.index_zero_crossings[\n                    i\n                ]  # Store the start index of the turn\n\n            # Check if the absolute value of the turn angle is greater than or equal to 10\n            if abs(self.turns_all[i]) &gt;= 10:\n                try:\n                    # Check if the next index also has a hesitation marker\n                    if hesitation_markers[i + 1] != 0:\n                        # Iterate through subsequent indices to find the end of the turn\n                        for j in range(i + 1, len(hesitation_markers)):\n                            # Check if the absolute value of the turn angle is greater than or equal to 10\n                            if abs(self.turns_all[j]) &gt;= 10:\n                                # Check if the signs of the turn angles are the same\n                                if np.sign(self.turns_all[j]) == np.sign(\n                                    self.turns_all[i]\n                                ):\n                                    sum_temp += self.turns_all[\n                                        i\n                                    ]  # Accumulate the turn angle\n                                else:\n                                    f2 = hesitation_markers[\n                                        i + 1\n                                    ]  # Store the end index of the turn\n                                    sum_temp += self.turns_all[\n                                        i\n                                    ]  # Accumulate the turn angle\n                                    turns_no_hesitation.append(\n                                        sum_temp\n                                    )  # Store the turn angle without hesitation\n                                    flags_start_no_hesitation.append(\n                                        f1\n                                    )  # Store the start index of the turn\n                                    flags_end_no_hesitation.append(\n                                        f2\n                                    )  # Store the end index of the turn\n                                    durations_no_hesitation.append(\n                                        (f2 - f1) / sampling_freq_Hz\n                                    )  # Calculate and store the duration of the turn\n                                    z += 1  # Increment the turn index\n                                    sum_temp = 0  # Reset the temporary sum\n                                    del (\n                                        f1,\n                                        f2,\n                                    )  # Delete stored indices to avoid conflicts\n                                break  # Exit the loop once the turn is processed\n                    else:\n                        f2 = self.index_zero_crossings[\n                            i + 1\n                        ]  # Store the end index of the turn\n                        sum_temp += self.turns_all[i]  # Accumulate the turn angle\n                        turns_no_hesitation.append(\n                            sum_temp\n                        )  # Store the turn angle without hesitation\n                        flags_start_no_hesitation.append(\n                            f1\n                        )  # Store the start index of the turn\n                        flags_end_no_hesitation.append(\n                            f2\n                        )  # Store the end index of the turn\n                        durations_no_hesitation.append(\n                            (f2 - f1) / sampling_freq_Hz\n                        )  # Calculate and store the duration of the turn\n                        z += 1  # Increment the turn index\n                        del f1, f2  # Delete stored indices to avoid conflicts\n                        sum_temp = 0  # Reset the temporary sum\n                except:\n                    f2 = self.index_zero_crossings[\n                        i + 1\n                    ]  # Store the end index of the turn\n                    sum_temp += self.turns_all[i]  # Accumulate the turn angle\n                    turns_no_hesitation.append(\n                        sum_temp\n                    )  # Store the turn angle without hesitation\n                    flags_start_no_hesitation.append(\n                        f1\n                    )  # Store the start index of the turn\n                    flags_end_no_hesitation.append(\n                        f2\n                    )  # Store the end index of the turn\n                    durations_no_hesitation.append(\n                        (f2 - f1) / sampling_freq_Hz\n                    )  # Calculate and store the duration of the turn\n                    z += 1\n                    del f1, f2\n                    sum_temp = 0\n            else:\n                sum_temp += self.turns_all[\n                    i\n                ]  # Accumulate the turn angle if it's smaller than 10 degrees\n        else:  # If there's no hesitation marker at the current index\n            turns_no_hesitation.append(self.turns_all[i])\n            flags_start_no_hesitation.append(self.index_zero_crossings[i])\n            flags_end_no_hesitation.append(self.index_zero_crossings[i + 1])\n            durations_no_hesitation.append(\n                (self.index_zero_crossings[i + 1] - self.index_zero_crossings[i])\n                / sampling_freq_Hz\n            )  # Calculate and store the duration of the turn\n            z += 1  # Increment the turn index\n\n    # Initialize lists to store information about turns &gt;= 90 degrees\n    turns_90 = []\n    flags_start_90 = []\n    flags_end_90 = []\n\n    # Iterate through each turn without hesitation\n    for k in range(len(turns_no_hesitation)):\n        # Check if the turn angle is greater than or equal to 90 degrees\n        # and if the duration of the turn is between 0.5 and 10 seconds\n        if (\n            abs(turns_no_hesitation[k]) &gt;= self.min_turn_angle_deg\n            and durations_no_hesitation[k] &gt;= self.min_turn_duration_s\n            and durations_no_hesitation[k] &lt; self.max_turn_duration_s\n        ):\n            # If conditions are met, store information about the turn\n            turns_90.append(turns_no_hesitation[k])\n            flags_start_90.append(flags_start_no_hesitation[k])\n            flags_end_90.append(flags_end_no_hesitation[k])\n\n    # Initialize lists to store additional information about &gt;= 90 degree turns\n    duration_90 = []\n\n    # Assign detected truns attribute\n    self.turns_90 = turns_90\n    self.flags_start_90 = flags_start_90\n    self.flags_end_90 = flags_end_90\n\n    # Assign sampling frequency to the attribute\n    self.sampling_freq_Hz = sampling_freq_Hz\n\n    # Compute duration of the turn in seconds\n    for k in range(len(flags_start_90)):\n        # Compute duration of the turn in seconds\n        duration_nsamples = self.flags_end_90[k] - self.flags_start_90[k]\n        duration_90.append(duration_nsamples / sampling_freq_Hz)\n\n    # Create a DataFrame with postural transition information\n    self.turns_ = pd.DataFrame(\n        {\n            \"onset\": np.array(flags_start_90) / sampling_freq_Hz,\n            \"duration\": duration_90,\n            \"event_type\": \"turn\",\n            \"tracking_systems\": tracking_system,\n            \"tracked_points\": tracked_point,\n        }\n    )\n\n    # If original datetime is available, update the 'onset' and 'duration'\n    if dt_data is not None:\n        # Update the 'onset' based on the original datetime information\n        self.turns_[\"onset\"] = dt_data.iloc[flags_start_90].reset_index(drop=True)\n\n        # Update the 'duration' based on the difference between end and start indices\n        self.turns_[\"duration\"] = dt_data.iloc[flags_end_90].reset_index(\n            drop=True\n        ) - dt_data.iloc[flags_start_90].reset_index(drop=True)\n\n    # If Plot_results set to true\n    if plot_results:\n        viz_utils.plot_turns(accel, gyro, self.turns_, sampling_freq_Hz)\n\n    # Return an instance of the class\n    return self\n</code></pre>"},{"location":"modules/td/#modules.td._pham.PhamTurnDetection.spatio_temporal_parameters","title":"<code>spatio_temporal_parameters()</code>","text":"<p>Extracts spatio-temporal parameters of the detected turns.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The spatio-temporal parameter information is stored in the 'spatio_temporal_parameters' attribute, which is a pandas DataFrame as:</p> <ul> <li>direction_of_turn: Direction of turn which is either \"left\" or \"right\".</li> <li>angle_of_turn: Angle of the turn in degrees.</li> <li>peak_angular_velocity: Peak angular velocity during turn in deg/s.</li> </ul> Source code in <code>kielmat/modules/td/_pham.py</code> <pre><code>def spatio_temporal_parameters(self) -&gt; pd.DataFrame:\n    \"\"\"\n    Extracts spatio-temporal parameters of the detected turns.\n\n    Returns:\n        The spatio-temporal parameter information is stored in the 'spatio_temporal_parameters' attribute, which is a pandas DataFrame as:\n\n            - direction_of_turn: Direction of turn which is either \"left\" or \"right\".\n            - angle_of_turn: Angle of the turn in degrees.\n            - peak_angular_velocity: Peak angular velocity during turn in deg/s.\n    \"\"\"\n    if self.turns_ is None:\n        raise ValueError(\"No turns detected. Please run the detect method first.\")\n\n    # Calculate additional information for each &gt;= 90 degree turn\n    peak_angular_velocities = []\n    diff_yaw = np.diff(self.yaw)\n\n    for k in range(len(self.flags_start_90)):\n        # Calculate peak angular velocity during the turn\n        diff_vector = abs(\n            diff_yaw[(self.flags_start_90[k] - 1) : (self.flags_end_90[k] - 1)]\n        )\n        peak_angular_velocities.append(np.max(diff_vector) * self.sampling_freq_Hz)\n\n    # Determine direction of the turn (left or right)\n    direction_of_turns = []\n\n    for turn_angle in self.turns_90:\n        if turn_angle &lt; 0:\n            direction_of_turns.append(\"left\")\n        else:\n            direction_of_turns.append(\"right\")\n\n    # Create a DataFrame with the calculated spatio-temporal parameters\n    self.parameters_ = pd.DataFrame(\n        {\n            \"direction_of_turn\": direction_of_turns,\n            \"angle_of_turn\": self.turns_90,\n            \"peak_angular_velocity\": peak_angular_velocities,\n        }\n    )\n\n    # Set the index name to 'turn id'\n    self.parameters_.index.name = \"turn id\"\n</code></pre>"},{"location":"utils/","title":"Overview","text":"<p>This part of the project documentation focuses on the available utilities that assist in various preprocessing, importing, and data handling tasks within the KielMAT toolbox. The following utilities provide functionality to import data from various formats, perform preprocessing, and estimate orientations for movement analysis.</p>"},{"location":"utils/#data-preprocessing","title":"Data Preprocessing","text":"<p>The Data Preprocessing provide a set of utilities designed to prepare motion data for analysis. These functions are essential for cleaning, filtering, and transforming raw sensor data into a suitable format for subsequent analysis.</p>"},{"location":"utils/#data-import","title":"Data Import","text":"<p>The Data Import within KielMAT are designed to handle data from various sources and formats. This makes it easy to load and integrate different datasets into the toolbox. Below are examples of the import functions available for different sensor data sources:</p> <ul> <li> <p>Axivity Data Import   The <code>import_axivity</code> function imports Axivity data from specified files. It reads Axivity data files, performs lowpass filtering, and calibrates for gravity, ensuring that the data is ready for analysis. The function outputs the data along with the associated channel information in a format compatible with the KielMAT <code>KielMATRecording</code> class. This function allows easy integration of Axivity data, including accelerometer information for a specific tracked point.</p> </li> <li> <p>APDM Mobility Lab Data Import   The <code>import_mobilityLab</code> function imports data from the APDM Mobility Lab system, which is commonly used for gait analysis. It reads data from sensor files (in HDF5 format) and extracts accelerometer, gyroscope, and magnetometer readings for specific tracked points such as lumbar. The function outputs the data along with channel information, which is formatted according to the required specifications, including sensor name, component type, units, and sampling frequency. It handles multiple tracked points and can process data from various sensor types in one operation.</p> </li> </ul> <p>These import functions facilitate the integration of complex sensor data into KielMAT for analysis and ensure that data from different systems can be processed consistently and efficiently.</p>"},{"location":"utils/#orientation-estimation","title":"Orientation estimation","text":"<p>The Orientation estimation utilities help estimate the orientation of the tracked points in space, crucial for movement analysis involving angular data. These functions apply algorithms that use accelerometer and gyroscope data to estimate the orientation of the sensors, providing insights into body posture and movement. The utility ensures that orientation data is available for further analysis, including gait and posture assessment.</p>"},{"location":"utils/importers/","title":"Import functions","text":""},{"location":"utils/importers/#utils.importers.import_axivity","title":"<code>import_axivity(file_path, tracked_point)</code>","text":"<p>Imports and processes data from an Axivity device file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the Axivity data file.</p> required <code>tracked_point</code> <code>str</code> <p>Label for the tracked body point (e.g., 'wrist').</p> required <p>Returns:</p> Type Description <code>tuple[DataFrame, DataFrame]</code> <p>tuple[pd.DataFrame, pd.DataFrame]: A tuple containing: - data (pd.DataFrame): Processed accelerometer data with time information. - channels (pd.DataFrame): Channel information DataFrame with metadata such as   component, type, units, and sampling frequency.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If no tracked point is provided.</p> Source code in <code>kielmat/utils/importers.py</code> <pre><code>def import_axivity(\n    file_path: str, tracked_point: str\n) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Imports and processes data from an Axivity device file.\n\n    Args:\n        file_path (str): Path to the Axivity data file.\n        tracked_point (str): Label for the tracked body point (e.g., 'wrist').\n\n    Returns:\n        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing:\n            - data (pd.DataFrame): Processed accelerometer data with time information.\n            - channels (pd.DataFrame): Channel information DataFrame with metadata such as\n              component, type, units, and sampling frequency.\n\n    Raises:\n        ValueError: If no tracked point is provided.\n    \"\"\"\n    # return an error if no tracked point is provided\n    if not tracked_point:\n        raise ValueError(\"Please provide a tracked point.\")\n\n    # Convert file_path to a Path object if it is a string\n    if isinstance(file_path, str):\n        file_path = Path(file_path)\n\n    # Read the Axivity data file and perform lowpass filtering and gravity calibration\n    data, info = actipy.read_device(\n        str(file_path),\n        lowpass_hz=20,\n        calibrate_gravity=True,\n    )\n\n    # Reset the index of the data DataFrame\n    data.reset_index(inplace=True)\n\n    # Construct the channel information\n    # Find all the columns that are named x, y or z in the data DataFrame\n    accel_col_names = [col for col in data.columns if col[-1] in [\"x\", \"y\", \"z\"]]\n    n_channels = len(accel_col_names)\n\n    # Create the column names for the KielMATRecording object\n    col_names = [f\"{tracked_point}_{s}_{x}\" for s in [\"ACCEL\"] for x in [\"x\", \"y\", \"z\"]]\n\n    # Create the channel dictionary following the BIDS naming conventions\n    channels_dict = {\n        \"name\": col_names,\n        \"component\": [\"x\", \"y\", \"z\"] * (n_channels // 3),\n        \"type\": [\"ACCEL\"] * (n_channels),\n        \"tracked_point\": [tracked_point] * n_channels,\n        \"units\": [\"m/s^2\"] * n_channels,\n        \"sampling_frequency\": [info[\"ResampleRate\"]] * n_channels,\n    }\n\n    # Convert channels dictionary to a DataFrame\n    channels = pd.DataFrame(channels_dict)\n\n    return data, channels\n</code></pre>"},{"location":"utils/importers/#utils.importers.import_mobilityLab","title":"<code>import_mobilityLab(file_name, tracked_points)</code>","text":"<p>Imports and processes data from an APDM Mobility Lab system file.</p> <p>Parameters:</p> Name Type Description Default <code>file_name</code> <code>str | Path</code> <p>Path to the Mobility Lab HDF5 file.</p> required <code>tracked_points</code> <code>str | list[str]</code> <p>Name or list of names for tracked body points to import.</p> required <p>Returns:</p> Type Description <code>tuple[DataFrame, DataFrame]</code> <p>tuple[pd.DataFrame, pd.DataFrame]: A tuple containing: - data (pd.DataFrame): DataFrame with combined accelerometer, gyroscope,   and magnetometer data for each tracked point. - channels (pd.DataFrame): DataFrame containing metadata, including sensor name,   component, type, units, and sampling frequency.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If any specified tracked point does not exist in the file's monitor labels.</p> Source code in <code>kielmat/utils/importers.py</code> <pre><code>def import_mobilityLab(\n    file_name: str | Path,\n    tracked_points: str | list[str],\n) -&gt; tuple[pd.DataFrame, pd.DataFrame]:\n    \"\"\"\n    Imports and processes data from an APDM Mobility Lab system file.\n\n    Args:\n        file_name (str | Path): Path to the Mobility Lab HDF5 file.\n        tracked_points (str | list[str]): Name or list of names for tracked body points to import.\n\n    Returns:\n        tuple[pd.DataFrame, pd.DataFrame]: A tuple containing:\n            - data (pd.DataFrame): DataFrame with combined accelerometer, gyroscope,\n              and magnetometer data for each tracked point.\n            - channels (pd.DataFrame): DataFrame containing metadata, including sensor name,\n              component, type, units, and sampling frequency.\n\n    Raises:\n        ValueError: If any specified tracked point does not exist in the file's monitor labels.\n    \"\"\"\n    # Convert file_name to a Path object if it is a string\n    if isinstance(file_name, str):\n        file_name = Path(file_name)\n\n    # Convert tracked_points into a list if the it is provided as a string\n    if isinstance(tracked_points, str):\n        tracked_points = [tracked_points]\n\n    with h5py.File(file_name, \"r\") as hfile:\n        # Get monitor labels and case IDs\n        monitor_labels = hfile.attrs[\"MonitorLabelList\"]\n        monitor_labels = [s.decode(\"UTF-8\").strip() for s in monitor_labels]\n        case_ids = hfile.attrs[\"CaseIdList\"]\n        case_ids = [s.decode(\"UTF-8\")[:9] for s in case_ids]\n\n        # Track invalid tracked points\n        invalid_tracked_points = [\n            tp for tp in tracked_points if tp not in monitor_labels\n        ]\n\n        if invalid_tracked_points:\n            raise ValueError(\n                f\"The following tracked points do not exist in monitor labels: {invalid_tracked_points}\"\n            )\n\n        # Initialize dictionaries to store channels and data frames\n        channels_dict = {\n            \"name\": [],\n            \"component\": [],\n            \"type\": [],\n            \"tracked_point\": [],\n            \"units\": [],\n            \"sampling_frequency\": [],\n        }\n\n        # Create dictionary to store data\n        data_dict = {}\n\n        # Iterate over each sensor\n        for idx_sensor, (monitor_label, case_id) in enumerate(\n            zip(monitor_labels, case_ids)\n        ):\n            if monitor_label not in tracked_points:\n                continue  # to next sensor name\n            sample_rate = hfile[case_id].attrs[\"SampleRate\"]\n\n            # Get raw data\n            rawAcc = hfile[case_id][\"Calibrated\"][\"Accelerometers\"][:]\n            rawGyro = hfile[case_id][\"Calibrated\"][\"Gyroscopes\"][:]\n            rawMagn = hfile[case_id][\"Calibrated\"][\"Magnetometers\"][:]\n\n            # Populate data_dict\n            data_dict[f\"{monitor_label}\"] = pd.DataFrame(\n                {\n                    f\"{monitor_label}_ACCEL_x\": rawAcc[:, 0],\n                    f\"{monitor_label}_ACCEL_y\": rawAcc[:, 1],\n                    f\"{monitor_label}_ACCEL_z\": rawAcc[:, 2],\n                    f\"{monitor_label}_GYRO_x\": rawGyro[:, 0],\n                    f\"{monitor_label}_GYRO_y\": rawGyro[:, 1],\n                    f\"{monitor_label}_GYRO_z\": rawGyro[:, 2],\n                    f\"{monitor_label}_MAGN_x\": rawMagn[:, 0],\n                    f\"{monitor_label}_MAGN_y\": rawMagn[:, 1],\n                    f\"{monitor_label}_MAGN_z\": rawMagn[:, 2],\n                }\n            )\n\n            # Extend lists in channels_dict\n            channels_dict[\"name\"].extend(\n                [\n                    f\"{monitor_label}_ACCEL_x\",\n                    f\"{monitor_label}_ACCEL_y\",\n                    f\"{monitor_label}_ACCEL_z\",\n                    f\"{monitor_label}_GYRO_x\",\n                    f\"{monitor_label}_GYRO_y\",\n                    f\"{monitor_label}_GYRO_z\",\n                    f\"{monitor_label}_MAGN_x\",\n                    f\"{monitor_label}_MAGN_y\",\n                    f\"{monitor_label}_MAGN_z\",\n                ]\n            )\n\n            channels_dict[\"component\"].extend([\"x\", \"y\", \"z\"] * 3)\n            channels_dict[\"type\"].extend(\n                [\n                    \"ACCEL\",\n                    \"ACCEL\",\n                    \"ACCEL\",\n                    \"GYRO\",\n                    \"GYRO\",\n                    \"GYRO\",\n                    \"MAGN\",\n                    \"MAGN\",\n                    \"MAGN\",\n                ]\n            )\n            channels_dict[\"tracked_point\"].extend([monitor_label] * 9)\n            channels_dict[\"units\"].extend(\n                [\"m/s^2\", \"m/s^2\", \"m/s^2\", \"rad/s\", \"rad/s\", \"rad/s\", \"\u00b5T\", \"\u00b5T\", \"\u00b5T\"]\n            )\n            channels_dict[\"sampling_frequency\"].extend([sample_rate] * 9)\n\n    # Concatenate data frames from data_dict\n    data = pd.concat(list(data_dict.values()), axis=1)\n\n    # Create DataFrame from channels_dict\n    channels = pd.DataFrame(channels_dict)\n\n    return data, channels\n</code></pre>"},{"location":"utils/orientation_estimation/","title":"Orientation estimation","text":""},{"location":"utils/orientation_estimation/#utils.quaternion.axang2rotm","title":"<code>axang2rotm(axang)</code>","text":"<p>Convert axis-angle representation to rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>axang</code> <code>ndarray</code> <p>Input array of axis-angle representations with shape (..., 4), where the first three elements are the axis of rotation and the last element is the angle of rotation in radians.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Rotation matrix corresponding to the input axis-angle representations.</p> <p>The function computes the rotation matrix using Rodrigues' rotation formula.</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def axang2rotm(axang: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Convert axis-angle representation to rotation matrix.\n\n    Args:\n        axang (np.ndarray): Input array of axis-angle representations with shape (..., 4),\n            where the first three elements are the axis of rotation\n            and the last element is the angle of rotation in radians.\n\n    Returns:\n        np.ndarray: Rotation matrix corresponding to the input axis-angle representations.\n\n    The function computes the rotation matrix using Rodrigues' rotation formula.\n    \"\"\"\n\n    # Cast array to float\n    axang = np.asarray(axang, float)\n    assert axang.shape[-1] == 4\n\n    # Extract axis and angle\n    axis = axang[..., :3]\n    angle = axang[..., 3]\n\n    # Normalize axis\n    axis /= np.linalg.norm(axis, axis=-1, keepdims=True)\n\n    # Compute rotation matrix using Rodrigues' rotation formula\n    cos_theta = np.cos(angle)\n    sin_theta = np.sin(angle)\n    cross_prod_matrix = np.zeros((*axis.shape[:-1], 3, 3), dtype=float)\n    cross_prod_matrix[..., 0, 1] = -axis[..., 2]\n    cross_prod_matrix[..., 0, 2] = axis[..., 1]\n    cross_prod_matrix[..., 1, 0] = axis[..., 2]\n    cross_prod_matrix[..., 1, 2] = -axis[..., 0]\n    cross_prod_matrix[..., 2, 0] = -axis[..., 1]\n    cross_prod_matrix[..., 2, 1] = axis[..., 0]\n    rotation_matrix = (\n        np.eye(3, dtype=float) * cos_theta[..., None]\n        + sin_theta[..., None] * cross_prod_matrix\n        + (1 - cos_theta[..., None]) * np.einsum(\"...i,...j-&gt;...ij\", axis, axis)\n    )\n\n    return rotation_matrix\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quat2axang","title":"<code>quat2axang(q)</code>","text":"<p>Convert a quaternion to axis-angle representation.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>ndarray</code> <p>Input quaternion array of shape (..., 4).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Axis-angle representation array of shape (..., 4), where the first three elements are the axis of rotation and the last element is the angle of rotation in radians.</p> <p>The function normalizes the input quaternion, calculates the angle of rotation, and computes the axis of rotation in the axis-angle representation.</p> <p>Note: The input quaternion array is expected to have the last dimension of size 4.</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quat2axang(q: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Convert a quaternion to axis-angle representation.\n\n    Args:\n        q (np.ndarray): Input quaternion array of shape (..., 4).\n\n    Returns:\n        np.ndarray: Axis-angle representation array of shape (..., 4),\n            where the first three elements are the axis of rotation\n            and the last element is the angle of rotation in radians.\n\n    The function normalizes the input quaternion, calculates the angle of rotation,\n    and computes the axis of rotation in the axis-angle representation.\n\n    Note: The input quaternion array is expected to have the last dimension of size 4.\n    \"\"\"\n\n    # Cast array to float\n    q = np.asarray(q, float)\n    assert q.shape[-1] == 4\n\n    # Normalize the quaternion\n    q = quatnormalize(q)\n\n    # Calculate the angle of rotation\n    axang = np.zeros_like(q)\n    axang[..., 3] = 2.0 * np.arccos(q[..., 0])\n    axang[..., :3] = np.where(\n        np.sin(axang[..., 3] / 2.0) &gt; _EPS,\n        q[..., 1:] / np.sin(axang[..., 3] / 2.0),\n        np.array([0.0, 0.0, 1.0]),\n    )\n    return axang\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quat2rotm","title":"<code>quat2rotm(q, scalar_first=True, channels_last=True)</code>","text":"<p>Convert quaternion(s) to rotation matrix.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>ndarray</code> <p>Input quaternion(s) as a NumPy array. The last dimension must have size 4.</p> required <code>scalar_first</code> <code>bool</code> <p>If True, the quaternion is assumed to be in scalar-first order (default is True).</p> <code>True</code> <code>channels_last</code> <code>bool</code> <p>If True, the last dimension represents the quaternion channels (default is True). If False, the quaternion channels are assumed to be in the first dimension.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Rotation matrix corresponding to the input quaternion(s).</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the last dimension of the input array <code>q</code> does not have size 4.</p> Notes <p>The conversion is based on the formula: R = | 1 - 2q2^2 - 2q3^2    2(q1q2 - q3q0)    2(q1q3 + q2q0) |     | 2(q1q2 + q3q0)    1 - 2q1^2 - 2q3^2    2(q2q3 - q1q0) |     | 2(q1q3 - q2q0)    2(q1q0 + q2q3)    1 - 2q1^2 - 2q2^2 |</p> References <p>Wikipedia: https://en.wikipedia.org/wiki/Rotation_matrix#Quaternion</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; quaternion = np.array([1.0, 0.0, 0.0, 0.0])\n&gt;&gt;&gt; rotation_matrix = quat2rotm(quaternion)\n</code></pre> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quat2rotm(\n    q: np.ndarray, scalar_first: bool = True, channels_last: bool = True\n) -&gt; np.ndarray:\n    \"\"\"\n    Convert quaternion(s) to rotation matrix.\n\n    Args:\n        q (np.ndarray): Input quaternion(s) as a NumPy array. The last dimension must have size 4.\n        scalar_first (bool, optional): If True, the quaternion is assumed to be in scalar-first order (default is True).\n        channels_last (bool, optional): If True, the last dimension represents the quaternion channels (default is True).\n            If False, the quaternion channels are assumed to be in the first dimension.\n\n    Returns:\n        np.ndarray: Rotation matrix corresponding to the input quaternion(s).\n\n    Raises:\n        AssertionError: If the last dimension of the input array `q` does not have size 4.\n\n    Notes:\n        &gt;&gt;&gt; The conversion is based on the formula:\n        &gt;&gt;&gt; R = | 1 - 2*q2^2 - 2*q3^2    2*(q1*q2 - q3*q0)    2*(q1*q3 + q2*q0) |\n            | 2*(q1*q2 + q3*q0)    1 - 2*q1^2 - 2*q3^2    2*(q2*q3 - q1*q0) |\n            | 2*(q1*q3 - q2*q0)    2*(q1*q0 + q2*q3)    1 - 2*q1^2 - 2*q2^2 |\n\n    References:\n        Wikipedia: https://en.wikipedia.org/wiki/Rotation_matrix#Quaternion\n\n    Examples:\n        &gt;&gt;&gt; quaternion = np.array([1.0, 0.0, 0.0, 0.0])\n        &gt;&gt;&gt; rotation_matrix = quat2rotm(quaternion)\n    \"\"\"\n\n    # Cast array to float\n    q = np.asarray(q, float)\n    assert q.shape[-1] == 4\n\n    # Derive rotation matrix from quaternion\n    R = np.zeros(q.shape[:-1] + (3, 3), float)\n    R[..., 0, 0] = 1 - 2 * q[..., 2] ** 2 - 2 * q[..., 3] ** 2\n    R[..., 0, 1] = 2 * (q[..., 1] * q[..., 2] - q[..., 3] * q[..., 0])\n    R[..., 0, 2] = 2 * (q[..., 1] * q[..., 3] + q[..., 2] * q[..., 0])\n    R[..., 1, 0] = 2 * (q[..., 1] * q[..., 2] + q[..., 3] * q[..., 0])\n    R[..., 1, 1] = 1 - 2 * q[..., 1] ** 2 - 2 * q[..., 3] ** 2\n    R[..., 1, 2] = 2 * (q[..., 2] * q[..., 3] - q[..., 1] * q[..., 0])\n    R[..., 2, 0] = 2 * (q[..., 1] * q[..., 3] - q[..., 2] * q[..., 0])\n    R[..., 2, 1] = 2 * (q[..., 1] * q[..., 0] + q[..., 2] * q[..., 3])\n    R[..., 2, 2] = 1 - 2 * q[..., 1] ** 2 - 2 * q[..., 2] ** 2\n    return R\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quatconj","title":"<code>quatconj(q, scalar_first=True, channels_last=True)</code>","text":"<p>Compute the quaternion conjugate.</p> <p>This function calculates the conjugate of a quaternion, which is obtained by negating the imaginary (vector) parts while keeping the real (scalar) part unchanged.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>ndarray</code> <p>Input array of quaternions with shape (..., 4).</p> required <code>scalar_first</code> <code>bool</code> <p>If True, assumes the scalar part is the first element. If False, assumes the scalar part is the last element. Default is True.</p> <code>True</code> <code>channels_last</code> <code>bool</code> <p>If True, assumes the channels are the last dimension. If False, assumes the channels are the second-to-last dimension. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Quaternion conjugate with the same shape as the input array.</p> Notes <ul> <li>The input array is cast to float before the computation.</li> <li>If channels_last is False, the input array is transposed to switch channels and time axis.</li> <li>If scalar_first is False, the scalar part is moved to the last element.</li> </ul> Quaternion Conjugate Formula <p>q_conj = [w, -x, -y, -z]</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quatconj(\n    q: np.ndarray, scalar_first: bool = True, channels_last: bool = True\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the quaternion conjugate.\n\n    This function calculates the conjugate of a quaternion, which is obtained by negating\n    the imaginary (vector) parts while keeping the real (scalar) part unchanged.\n\n    Args:\n        q (np.ndarray): Input array of quaternions with shape (..., 4).\n        scalar_first (bool, optional): If True, assumes the scalar part is the first element.\n            If False, assumes the scalar part is the last element. Default is True.\n        channels_last (bool, optional): If True, assumes the channels are the last dimension.\n            If False, assumes the channels are the second-to-last dimension. Default is True.\n\n    Returns:\n        np.ndarray: Quaternion conjugate with the same shape as the input array.\n\n    Notes:\n        - The input array is cast to float before the computation.\n        - If channels_last is False, the input array is transposed to switch channels and time axis.\n        - If scalar_first is False, the scalar part is moved to the last element.\n\n    Quaternion Conjugate Formula:\n        &gt;&gt;&gt; q_conj = [w, -x, -y, -z]\n    \"\"\"\n\n    # Cast array to float\n    q = np.asarray(q, float)\n\n    if not channels_last:\n        # Take the tranpose, i.e. switch channels and time axis\n        q = q.T\n\n    if not scalar_first:\n        # Put the scalar first\n        q_tmp = q.copy()\n        q[..., 0] = q_tmp[..., -1]\n        q[..., 1:] = q_tmp[..., :-1]\n        del q_tmp\n\n    # Negate the vector part of the quaternion\n    q_out = q.copy()\n    q_out[..., 1:] *= -1\n\n    if not scalar_first:\n        # Put scalar part back in last channel\n        q_tmp = q_out.copy()\n        q_out[..., -1] = q_tmp[..., 0]\n        q_out[..., :-1] = q_tmp[..., 1:]\n        del q_tmp\n\n    if not channels_last:\n        # Switch channels and time axis back\n        q_out = q_out.T\n    return q_out\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quatinv","title":"<code>quatinv(q, scalar_first=True, channels_last=True)</code>","text":"<p>Compute the inverse of quaternions.</p> <p>This function calculates the inverse of quaternions by first computing the conjugate and then normalizing the conjugate.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>ndarray</code> <p>Input array of quaternions with shape (..., 4).</p> required <code>scalar_first</code> <code>bool</code> <p>If True, assumes the scalar part is the first element. If False, assumes the scalar part is the last element. Default is True.</p> <code>True</code> <code>channels_last</code> <code>bool</code> <p>If True, assumes the channels are the last dimension. If False, assumes the channels are the second-to-last dimension. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Inverse of quaternions with the same shape as the input array.</p> Notes <ul> <li>The input array is cast to float before the computation.</li> <li>If channels_last is False, the input array is transposed to switch channels and time axis.</li> </ul> Quaternion Inverse Calculation <p>The inverse of a quaternion q is obtained by first calculating its conjugate and then normalizing it: q_inv = normalize(conjugate(q))</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quatinv(\n    q: np.ndarray, scalar_first: bool = True, channels_last: bool = True\n) -&gt; np.ndarray:\n    \"\"\"\n    Compute the inverse of quaternions.\n\n    This function calculates the inverse of quaternions by first computing the conjugate\n    and then normalizing the conjugate.\n\n    Args:\n        q (np.ndarray): Input array of quaternions with shape (..., 4).\n        scalar_first (bool, optional): If True, assumes the scalar part is the first element.\n            If False, assumes the scalar part is the last element. Default is True.\n        channels_last (bool, optional): If True, assumes the channels are the last dimension.\n            If False, assumes the channels are the second-to-last dimension. Default is True.\n\n    Returns:\n        np.ndarray: Inverse of quaternions with the same shape as the input array.\n\n    Notes:\n        - The input array is cast to float before the computation.\n        - If channels_last is False, the input array is transposed to switch channels and time axis.\n\n    Quaternion Inverse Calculation:\n        &gt;&gt;&gt; The inverse of a quaternion q is obtained by first calculating its conjugate and then normalizing it:\n        &gt;&gt;&gt; q_inv = normalize(conjugate(q))\n    \"\"\"\n\n    # Cast array to float\n    q = np.asarray(q, float)\n\n    # Compute the quaternion conjugate\n    qconj = quatconj(q, scalar_first=scalar_first, channels_last=channels_last)\n\n    # Normalize the quaternion conjugate\n    qout = quatnormalize(qconj)\n    return qout\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quatmultiply","title":"<code>quatmultiply(q1, q2=None, scalar_first=True, channels_last=True)</code>","text":"<p>Multiply two sets of quaternions.</p> <p>This function performs quaternion multiplication on two sets of quaternions. Quaternions are 4-dimensional vectors of the form [w, x, y, z], where 'w' is the scalar (real) part, and 'x', 'y', and 'z' are the vector (imaginary) parts.</p> <p>Parameters:</p> Name Type Description Default <code>q1</code> <code>ndarray</code> <p>Input array of quaternions with shape (..., 4).</p> required <code>q2</code> <code>ndarray</code> <p>Input array of quaternions with shape (..., 4). If None, q2 is set to q1, making it a self-multiplication. Default is None.</p> <code>None</code> <code>scalar_first</code> <code>bool</code> <p>If True, assumes the scalar part is the first element. If False, assumes the scalar part is the last element. Default is True.</p> <code>True</code> <code>channels_last</code> <code>bool</code> <p>If True, assumes the channels are the last dimension. If False, assumes the channels are the second-to-last dimension. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Result of quaternion multiplication with the same shape as the input arrays.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the last dimension of q1 and q2 is not 4.</p> Notes <ul> <li>If q2 is None, this function performs self-multiplication (q1 * q1).</li> <li>The input arrays are cast to float before the computation.</li> <li>If channels_last is False, the input arrays are transposed to switch channels and time axis.</li> </ul> Quaternion Conjugate Formula <p>q3 = [w1w2 - x1x2 - y1y2 - z1z2,     w1x2 + x1w2 + y1z2 - z1y2,     w1y2 - x1z2 + y1w2 + z1x2,     w1z2 + x1y2 - y1x2 + z1w2]</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quatmultiply(\n    q1: np.ndarray,\n    q2: Optional[np.ndarray] = None,\n    scalar_first: bool = True,\n    channels_last: bool = True,\n) -&gt; np.ndarray:\n    \"\"\"\n    Multiply two sets of quaternions.\n\n    This function performs quaternion multiplication on two sets of quaternions.\n    Quaternions are 4-dimensional vectors of the form [w, x, y, z], where 'w' is the\n    scalar (real) part, and 'x', 'y', and 'z' are the vector (imaginary) parts.\n\n    Args:\n        q1 (np.ndarray): Input array of quaternions with shape (..., 4).\n        q2 (np.ndarray, optional): Input array of quaternions with shape (..., 4).\n            If None, q2 is set to q1, making it a self-multiplication. Default is None.\n        scalar_first (bool, optional): If True, assumes the scalar part is the first element.\n            If False, assumes the scalar part is the last element. Default is True.\n        channels_last (bool, optional): If True, assumes the channels are the last dimension.\n            If False, assumes the channels are the second-to-last dimension. Default is True.\n\n    Returns:\n        np.ndarray: Result of quaternion multiplication with the same shape as the input arrays.\n\n    Raises:\n        AssertionError: If the last dimension of q1 and q2 is not 4.\n\n    Notes:\n        - If q2 is None, this function performs self-multiplication (q1 * q1).\n        - The input arrays are cast to float before the computation.\n        - If channels_last is False, the input arrays are transposed to switch channels and time axis.\n\n    Quaternion Conjugate Formula:\n        &gt;&gt;&gt; q3 = [w1w2 - x1x2 - y1y2 - z1z2,\n            w1x2 + x1w2 + y1z2 - z1y2,\n            w1y2 - x1z2 + y1w2 + z1x2,\n            w1z2 + x1y2 - y1x2 + z1w2]\n    \"\"\"\n\n    # Parse input quaternions\n    q2 = q1.copy() if q2 is None else q2\n\n    # Cast arrays to float\n    q1 = np.asarray(q1, float)\n    q2 = np.asarray(q2, float)\n\n    if not channels_last:\n        # Take the tranpose, i.e. switch channels and time axis\n        q1 = q1.T\n        q2 = q2.T\n\n    if not scalar_first:\n        # Put the scalar first\n        q1_tmp = q1.copy()\n        q1[..., 0] = q1_tmp[..., -1]\n        q1[..., 1:] = q1_tmp[..., :-1]\n        del q1_tmp\n\n        q2_tmp = q2.copy()\n        q2[..., 0] = q2_tmp[..., -1]\n        q2[..., 1:] = q2_tmp[..., :-1]\n        del q2_tmp\n\n    # Align shapes\n    if q1.shape != q2.shape:\n        q1, q2 = np.broadcast_arrays(q1, q2)\n    assert q1.shape[-1] == 4\n\n    # Multiply the quaternions\n    q3 = np.zeros(q1.shape, float)\n    q3[..., 0] = (\n        q1[..., 0] * q2[..., 0]\n        - q1[..., 1] * q2[..., 1]\n        - q1[..., 2] * q2[..., 2]\n        - q1[..., 3] * q2[..., 3]\n    )\n    q3[..., 1] = (\n        q1[..., 0] * q2[..., 1]\n        + q1[..., 1] * q2[..., 0]\n        + q1[..., 2] * q2[..., 3]\n        - q1[..., 3] * q2[..., 2]\n    )\n    q3[..., 2] = (\n        q1[..., 0] * q2[..., 2]\n        - q1[..., 1] * q2[..., 3]\n        + q1[..., 2] * q2[..., 0]\n        + q1[..., 3] * q2[..., 1]\n    )\n    q3[..., 3] = (\n        q1[..., 0] * q2[..., 3]\n        + q1[..., 1] * q2[..., 2]\n        - q1[..., 2] * q2[..., 1]\n        + q1[..., 3] * q2[..., 0]\n    )\n\n    if not scalar_first:\n        # Put scalar part back in last channel\n        q3_tmp = q3.copy()\n        q3[..., -1] = q3_tmp[..., 0]\n        q3[..., :-1] = q3_tmp[..., 1:]\n        del q3_tmp\n\n    if not channels_last:\n        # Switch channels and time axis back\n        q3 = q3.T\n    return q3\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quatnorm","title":"<code>quatnorm(q, channels_last=True)</code>","text":"<p>Calculate the norm (magnitude) of quaternions.</p> <p>This function computes the norm (magnitude) of quaternions along the specified axis, which represents the length of the quaternion vector.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>ndarray</code> <p>Input array of quaternions with shape (..., 4).</p> required <code>channels_last</code> <code>bool</code> <p>If True, assumes the channels are the last dimension. If False, assumes the channels are the first dimension. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Norm of quaternions along the specified axis with the same shape as the input array.</p> Notes <ul> <li>The input array is cast to float before the computation.</li> <li>If channels_last is False, the input array is transposed to switch channels and time axis.</li> </ul> Quaternion Norm Calculation <p>The norm of a quaternion q is calculated as follows: norm(q) = sqrt(w^2 + x^2 + y^2 + z^2)</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quatnorm(q: np.ndarray, channels_last: bool = True) -&gt; np.ndarray:\n    \"\"\"\n    Calculate the norm (magnitude) of quaternions.\n\n    This function computes the norm (magnitude) of quaternions along the specified axis,\n    which represents the length of the quaternion vector.\n\n    Args:\n        q (np.ndarray): Input array of quaternions with shape (..., 4).\n        channels_last (bool, optional): If True, assumes the channels are the last dimension.\n            If False, assumes the channels are the first dimension. Default is True.\n\n    Returns:\n        np.ndarray: Norm of quaternions along the specified axis with the same shape as the input array.\n\n    Notes:\n        - The input array is cast to float before the computation.\n        - If channels_last is False, the input array is transposed to switch channels and time axis.\n\n    Quaternion Norm Calculation:\n        &gt;&gt;&gt; The norm of a quaternion q is calculated as follows:\n        &gt;&gt;&gt; norm(q) = sqrt(w^2 + x^2 + y^2 + z^2)\n    \"\"\"\n\n    # Cast array to float\n    q = np.asarray(q, float)\n\n    # Calculate the quaternion norm\n    norm = (\n        np.linalg.norm(q, axis=-1, keepdims=True)\n        if channels_last\n        else np.linalg.norm(q, axis=0, keepdims=True)\n    )\n    return norm\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.quatnormalize","title":"<code>quatnormalize(q, channels_last=True)</code>","text":"<p>Normalize quaternions.</p> <p>This function normalizes quaternions by dividing each quaternion by its magnitude (norm). The result is a unit quaternion with the same orientation as the original quaternion.</p> <p>Parameters:</p> Name Type Description Default <code>q</code> <code>ndarray</code> <p>Input array of quaternions with shape (..., 4).</p> required <code>channels_last</code> <code>bool</code> <p>If True, assumes the channels are the last dimension. If False, assumes the channels are the second-to-last dimension. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Normalized quaternions with the same shape as the input array.</p> Notes <ul> <li>The input array is cast to float before the computation.</li> <li>If channels_last is False, the input array is transposed to switch channels and time axis.</li> </ul> Quaternion Normalization <p>The normalization of a quaternion q is performed by dividing each element of q by its norm: q_normalized = q / norm(q)</p> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def quatnormalize(q: np.ndarray, channels_last: bool = True) -&gt; np.ndarray:\n    \"\"\"\n    Normalize quaternions.\n\n    This function normalizes quaternions by dividing each quaternion by its magnitude (norm).\n    The result is a unit quaternion with the same orientation as the original quaternion.\n\n    Args:\n        q (np.ndarray): Input array of quaternions with shape (..., 4).\n        channels_last (bool, optional): If True, assumes the channels are the last dimension.\n            If False, assumes the channels are the second-to-last dimension. Default is True.\n\n    Returns:\n        np.ndarray: Normalized quaternions with the same shape as the input array.\n\n    Notes:\n        - The input array is cast to float before the computation.\n        - If channels_last is False, the input array is transposed to switch channels and time axis.\n\n    Quaternion Normalization:\n        &gt;&gt;&gt; The normalization of a quaternion q is performed by dividing each element of q by its norm:\n        &gt;&gt;&gt; q_normalized = q / norm(q)\n    \"\"\"\n\n    # Cast array to float\n    q = np.asarray(q, float)\n\n    # Calculate the norm\n    norm = quatnorm(q, channels_last=channels_last)\n\n    # Divide each quaternion by its norm\n    q_out = q / norm\n    return q_out\n</code></pre>"},{"location":"utils/orientation_estimation/#utils.quaternion.rotm2quat","title":"<code>rotm2quat(R, method='auto')</code>","text":"<p>Convert a 3x3 rotation matrix to a quaternion.</p> <p>Source: - https://github.com/dlaidig/qmt/blob/0fa8d32eb461e14d78e9ddbd569664ea59bcea19/qmt/functions/quaternion.py#L1004</p> <p>Parameters:</p> Name Type Description Default <code>R</code> <code>ndarray</code> <p>A rotation matrix with shape (3, 3).</p> required <code>method</code> <code>int | str</code> <p>The method to use for conversion. Can be \"auto\" (default), \"copysign\", or a number (0, 1, 2, or 3).</p> <code>'auto'</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The quaternion corresponding to the rotation matrix.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the shape of R is not (3, 3).</p> Notes <ul> <li>If q2 is None, this function performs self-multiplication (q1 * q1).</li> <li>The input arrays are cast to float before the computation.</li> <li>If channels_last is False, the input arrays are transposed to switch channels and time axis.</li> </ul> Source code in <code>kielmat/utils/quaternion.py</code> <pre><code>def rotm2quat(R: np.ndarray, method: int | str = \"auto\") -&gt; np.ndarray:\n    \"\"\"\n    Convert a 3x3 rotation matrix to a quaternion.\n\n    Source:\n    - https://github.com/dlaidig/qmt/blob/0fa8d32eb461e14d78e9ddbd569664ea59bcea19/qmt/functions/quaternion.py#L1004\n\n    Args:\n        R (np.ndarray): A rotation matrix with shape (3, 3).\n        method (int | str, optional): The method to use for conversion.\n            Can be \"auto\" (default), \"copysign\", or a number (0, 1, 2, or 3).\n\n    Returns:\n        np.ndarray: The quaternion corresponding to the rotation matrix.\n\n    Raises:\n        AssertionError: If the shape of R is not (3, 3).\n\n    Notes:\n        - If q2 is None, this function performs self-multiplication (q1 * q1).\n        - The input arrays are cast to float before the computation.\n        - If channels_last is False, the input arrays are transposed to switch channels and time axis.\n    \"\"\"\n\n    # Cast array to float\n    R = np.asarray(R, float)\n    assert R.ndim &gt;= 2 and R.shape[-2:] == (3, 3)\n\n    w_sq = (1 + R[..., 0, 0] + R[..., 1, 1] + R[..., 2, 2]) / 4\n    x_sq = (1 + R[..., 0, 0] - R[..., 1, 1] - R[..., 2, 2]) / 4\n    y_sq = (1 - R[..., 0, 0] + R[..., 1, 1] - R[..., 2, 2]) / 4\n    z_sq = (1 - R[..., 0, 0] - R[..., 1, 1] + R[..., 2, 2]) / 4\n\n    q = np.zeros(R.shape[:-2] + (4,), float)\n    if method == \"auto\":  # use the largest value to avoid numerical problems\n        methods = np.argmax(np.array([w_sq, x_sq, y_sq, z_sq]), axis=0)\n    elif method == \"copysign\":\n        q[..., 0] = np.sqrt(w_sq)\n        q[..., 1] = np.copysign(np.sqrt(x_sq), R[..., 2, 1] - R[..., 1, 2])\n        q[..., 2] = np.copysign(np.sqrt(y_sq), R[..., 0, 2] - R[..., 2, 0])\n        q[..., 3] = np.copysign(np.sqrt(z_sq), R[..., 1, 0] - R[..., 0, 1])\n    elif method not in (0, 1, 2, 3):\n        raise RuntimeError('invalid method, must be \"copysign\", \"auto\", 0, 1, 2 or 3')\n\n    if method == 0 or method == \"auto\":\n        ind = methods == 0 if method == \"auto\" else slice(None)\n        q[ind, 0] = np.sqrt(w_sq[ind])\n        q[ind, 1] = (R[ind, 2, 1] - R[ind, 1, 2]) / (4 * q[ind, 0])\n        q[ind, 2] = (R[ind, 0, 2] - R[ind, 2, 0]) / (4 * q[ind, 0])\n        q[ind, 3] = (R[ind, 1, 0] - R[ind, 0, 1]) / (4 * q[ind, 0])\n    if method == 1 or method == \"auto\":\n        ind = methods == 1 if method == \"auto\" else slice(None)\n        q[ind, 1] = np.sqrt(x_sq[ind])\n        q[ind, 0] = (R[ind, 2, 1] - R[ind, 1, 2]) / (4 * q[ind, 1])\n        q[ind, 2] = (R[ind, 1, 0] + R[ind, 0, 1]) / (4 * q[ind, 1])\n        q[ind, 3] = (R[ind, 0, 2] + R[ind, 2, 0]) / (4 * q[ind, 1])\n    if method == 2 or method == \"auto\":\n        ind = methods == 2 if method == \"auto\" else slice(None)\n        q[ind, 2] = np.sqrt(y_sq[ind])\n        q[ind, 0] = (R[ind, 0, 2] - R[ind, 2, 0]) / (4 * q[ind, 2])\n        q[ind, 1] = (R[ind, 1, 0] + R[ind, 0, 1]) / (4 * q[ind, 2])\n        q[ind, 3] = (R[ind, 2, 1] + R[ind, 1, 2]) / (4 * q[ind, 2])\n    if method == 3 or method == \"auto\":\n        ind = methods == 3 if method == \"auto\" else slice(None)\n        q[ind, 3] = np.sqrt(z_sq[ind])\n        q[ind, 0] = (R[ind, 1, 0] - R[ind, 0, 1]) / (4 * q[ind, 3])\n        q[ind, 1] = (R[ind, 0, 2] + R[ind, 2, 0]) / (4 * q[ind, 3])\n        q[ind, 2] = (R[ind, 2, 1] + R[ind, 1, 2]) / (4 * q[ind, 3])\n    return q\n</code></pre>"},{"location":"utils/preprocessing/","title":"Preprocessing functions","text":"<p>This part from the utilities documentation focuses on comon preprocessing steps.</p>"},{"location":"utils/preprocessing/#utils.preprocessing.apply_continuous_wavelet_transform","title":"<code>apply_continuous_wavelet_transform(data, scales=10, desired_scale=10, wavelet='gaus2', sampling_frequency=40)</code>","text":"<p>Apply continuous wavelet transform to the input signal.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input signal.</p> required <code>scales</code> <code>int</code> <p>Number of scales for the wavelet transform. Default is 10.</p> <code>10</code> <code>desired_scale</code> <code>int</code> <p>Desired scale to use in calculations. Default is 10.</p> <code>10</code> <code>wavelet</code> <code>str</code> <p>Type of wavelet to use. Default is 'gaus2'.</p> <code>'gaus2'</code> <code>sampling_frequency</code> <code>float</code> <p>Sampling frequency of the signal. Default is 40.</p> <code>40</code> <p>Returns:</p> Name Type Description <code>smoothed_data</code> <code>ndarray</code> <p>Smoothed data after applying multiple Gaussian filters.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def apply_continuous_wavelet_transform(\n    data, scales=10, desired_scale=10, wavelet=\"gaus2\", sampling_frequency=40\n):\n    \"\"\"\n    Apply continuous wavelet transform to the input signal.\n\n    Args:\n        data (numpy.ndarray): Input signal.\n        scales (int, optional): Number of scales for the wavelet transform. Default is 10.\n        desired_scale (int, optional): Desired scale to use in calculations. Default is 10.\n        wavelet (str, optional): Type of wavelet to use. Default is 'gaus2'.\n        sampling_frequency (float, optional): Sampling frequency of the signal. Default is 40.\n\n    Returns:\n        smoothed_data (numpy.ndarray): Smoothed data after applying multiple Gaussian filters.\n    \"\"\"\n    # Error handling for invalid input data\n    try:\n        if not isinstance(data, np.ndarray):\n            raise ValueError(\"Input data must be a numpy.ndarray\")\n        if not isinstance(scales, int) or scales &lt;= 0:\n            raise ValueError(\"Scales must be a positive integer\")\n        if not isinstance(sampling_frequency, (int, float)) or sampling_frequency &lt;= 0:\n            raise ValueError(\"Sampling frequency must be a positive number\")\n\n        sampling_period = 1 / sampling_frequency\n        coefficients, _ = pywt.cwt(\n            data, np.arange(1, scales + 1), wavelet, sampling_period\n        )\n        wavelet_transform_result = coefficients[desired_scale - 1, :]\n\n        return wavelet_transform_result\n    except Exception as e:\n        # Handle the exception by printing an error message and returning None.\n        print(f\"Error in apply_continuous_wavelet_transform: {e}\")\n\n        return None\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.apply_successive_gaussian_filters","title":"<code>apply_successive_gaussian_filters(data)</code>","text":"<p>Apply successive Gaussian filters to the input data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input data.</p> required <p>Returns:</p> Name Type Description <code>data</code> <code>ndarray</code> <p>Filtered data.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def apply_successive_gaussian_filters(data):\n    \"\"\"\n    Apply successive Gaussian filters to the input data.\n\n    Args:\n        data (numpy.ndarray): Input data.\n\n    Returns:\n        data (numpy.ndarray): Filtered data.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(data, np.ndarray):\n        raise ValueError(\"Input data must be a NumPy array.\")\n\n    if data.size &lt; 1:\n        raise ValueError(\"Input data must not be empty.\")\n\n    sigma_params = [2, 2, 3, 2]\n    kernel_size_params = [10, 10, 15, 10]\n    mode_params = [\"reflect\", \"reflect\", \"nearest\", \"reflect\"]\n\n    filtered_signal = data\n\n    for sigma, kernel_size, mode in zip(sigma_params, kernel_size_params, mode_params):\n\n        gaussian_radius = (kernel_size - 1) / 2\n        filtered_signal = scipy.ndimage.gaussian_filter1d(\n            filtered_signal, sigma=sigma, mode=mode, radius=round(gaussian_radius)\n        )\n\n    return filtered_signal\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.calculate_envelope_activity","title":"<code>calculate_envelope_activity(input_signal, smooth_window=20, threshold_style=1, duration=20)</code>","text":"<p>Calculate envelope-based activity detection using the Hilbert transform.</p> <p>This function analyzes an input signal <code>input_signal</code> to detect periods of activity based on the signal's envelope. It calculates the analytical signal using the Hilbert transform, smoothes the envelope, and applies an adaptive threshold to identify active regions.</p> <p>Parameters:</p> Name Type Description Default <code>input_signal</code> <code>array_like</code> <p>The input signal.</p> required <code>smooth_window</code> <code>int</code> <p>Window length for smoothing the envelope (default is 20).</p> <code>20</code> <code>threshold_style</code> <code>int</code> <p>Threshold selection style: 0 for manual, 1 for automatic (default is 1).</p> <code>1</code> <code>duration</code> <code>int</code> <p>Minimum duration of activity to be detected (default is 20).</p> <code>20</code> <p>Returns:</p> Name Type Description <code>alarm</code> <code>ndarray</code> <p>Vector indicating active parts of the signal.</p> <code>env</code> <code>ndarray</code> <p>Smoothed envelope of the signal.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def calculate_envelope_activity(\n    input_signal, smooth_window=20, threshold_style=1, duration=20\n):\n    \"\"\"\n    Calculate envelope-based activity detection using the Hilbert transform.\n\n    This function analyzes an input signal `input_signal` to detect periods of activity based on the signal's envelope.\n    It calculates the analytical signal using the Hilbert transform, smoothes the envelope, and applies an\n    adaptive threshold to identify active regions.\n\n    Parameters:\n        input_signal (array_like): The input signal.\n        smooth_window (int): Window length for smoothing the envelope (default is 20).\n        threshold_style (int): Threshold selection style: 0 for manual, 1 for automatic (default is 1).\n        duration (int): Minimum duration of activity to be detected (default is 20).\n\n    Returns:\n        alarm (ndarray): Vector indicating active parts of the signal.\n        env (ndarray): Smoothed envelope of the signal.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(input_signal, np.ndarray):\n        raise ValueError(\"Input signal should be a NumPy array.\")\n\n    if not isinstance(smooth_window, (int)) or smooth_window &lt;= 0:\n        raise ValueError(\"The window length must be a positive integer.\")\n\n    if not isinstance(threshold_style, (int)) or threshold_style &lt;= 0:\n        raise ValueError(\"The threshold style must be a positive integer.\")\n\n    if not isinstance(duration, (int)) or duration &lt;= 0:\n        raise ValueError(\"The duration must be a positive integer.\")\n\n    # Calculate the analytical signal and get the envelope\n    input_signal = input_signal.flatten()\n    # Compute the analytic signal, using the Hilbert transform form scipy.signal.\n    analytic = scipy.signal.hilbert(input_signal)\n    env = np.abs(analytic)  # Compute the envelope of the analytic signal.\n\n    # Take the moving average of the analytic signal\n    env = scipy.signal.convolve(\n        env, np.ones(smooth_window) / smooth_window, mode=\"full\"\n    )  # Returns the discrete, linear convolution of two one-dimensional sequences.\n\n    env = env - np.mean(env)  # Remove the offset by subtracting the mean of 'env'\n    env = env / np.max(env)  # Normalize the 'env' by dividing by its maximum value\n\n    # Threshold the signal\n    # if threshold_style == 0:\n    #     plt.plot(env)\n    #     plt.title(\"Select a threshold on the graph\")\n    #     THR_SIG = plt.ginput(1)[0][1]\n    #     plt.close()\n    # else:\n    #     THR_SIG = 4 * np.mean(env)\n    THR_SIG = 4 * np.mean(env)\n\n    # Set noise and signal levels\n    noise = np.mean(env) / 3  # noise level\n\n    # Signal level: It's used as a reference to distinguish between the background noise and the actual signal activity.\n    threshold = np.mean(env)\n\n    # Initialize Buffers\n    thres_buf = np.zeros(\n        len(env) - duration\n    )  # This buffer stores values related to a threshold.\n    noise_buf = np.zeros(\n        len(env) - duration\n    )  # This buffer stores values related to the noise.\n    THR_buf = np.zeros(len(env))  # This buffer stores threshold values.\n    alarm = np.zeros(len(env))  # This buffer tracks alarm-related information.\n    h = 1\n\n    for i in range(len(env) - duration):\n        if np.all(env[i : i + duration + 1] &gt; THR_SIG):\n            alarm[i] = np.max(\n                env\n            )  # If the current window of data surpasses the threshold, set an alarm.\n            threshold = 0.1 * np.mean(\n                env[i : i + duration + 1]\n            )  # Set a new threshold based on the mean of the current window.\n            h += 1\n        else:\n            # Update noise\n            if np.mean(env[i : i + duration + 1]) &lt; THR_SIG:\n                noise = np.mean(\n                    env[i : i + duration + 1]\n                )  # Update the noise value based on the mean of the current window.\n            else:\n                if len(noise_buf) &gt; 0:\n                    noise = np.mean(\n                        noise_buf\n                    )  # If available, use the mean of noise buffer to update the noise.\n        thres_buf[i] = threshold  # Store the threshold value in the threshold buffer.\n        noise_buf[i] = noise  # Store the noise value in the noise buffer.\n\n        # Update threshold\n        if h &gt; 1:\n            THR_SIG = noise + 0.50 * (\n                np.abs(threshold - noise)\n            )  # Update the threshold using noise and threshold values.\n        THR_buf[i] = (\n            THR_SIG  # Store the updated threshold value in the threshold buffer.\n        )\n\n    return alarm, env\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.classify_physical_activity","title":"<code>classify_physical_activity(input_data, time_column_name='timestamp', sedentary_threshold=45, light_threshold=100, moderate_threshold=400, epoch_duration=5)</code>","text":"<p>Classify activity levels based on processed Euclidean Norm Minus One (ENMO) values.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>DataFrame</code> <p>Input data with time index and accelerometer data (N, 3) for x, y, and z axes.</p> required <code>time_column_name</code> <code>str</code> <p>Name of the index column.</p> <code>'timestamp'</code> <code>sedentary_threshold</code> <code>float</code> <p>Threshold for sedentary activity.</p> <code>45</code> <code>light_threshold</code> <code>float</code> <p>Threshold for light activity.</p> <code>100</code> <code>moderate_threshold</code> <code>float</code> <p>Threshold for moderate activity.</p> <code>400</code> <code>epoch_duration</code> <code>int</code> <p>Duration of each epoch in seconds.</p> <code>5</code> <p>Returns:</p> Name Type Description <code>processed_data</code> <code>DataFrame</code> <p>Processed data including time, averaged ENMO values base on epoch length, activity levels represented with 0 or 1.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def classify_physical_activity(\n    input_data,\n    time_column_name=\"timestamp\",\n    sedentary_threshold=45,\n    light_threshold=100,\n    moderate_threshold=400,\n    epoch_duration=5,\n):\n    \"\"\"\n    Classify activity levels based on processed Euclidean Norm Minus One (ENMO) values.\n\n    Args:\n        input_data (DataFrame): Input data with time index and accelerometer data (N, 3) for x, y, and z axes.\n        time_column_name (str): Name of the index column.\n        sedentary_threshold (float): Threshold for sedentary activity.\n        light_threshold (float): Threshold for light activity.\n        moderate_threshold (float): Threshold for moderate activity.\n        epoch_duration (int): Duration of each epoch in seconds.\n\n    Returns:\n        processed_data(DataFrame): Processed data including time, averaged ENMO values base on epoch length, activity levels represented with 0 or 1.\n    \"\"\"\n    # Check if input_data is a DataFrame\n    if not isinstance(input_data, pd.DataFrame):\n        raise ValueError(\"Input_data must be a pandas DataFrame.\")\n\n    # Check if threshold values are valid numeric types\n    if not all(\n        isinstance(threshold, (int, float))\n        for threshold in [sedentary_threshold, light_threshold, moderate_threshold]\n    ):\n        raise ValueError(\"Threshold values must be numeric.\")\n\n    # Check if epoch_duration is a positive integer\n    if not isinstance(epoch_duration, int) or epoch_duration &lt;= 0:\n        raise ValueError(\"Epoch_duration must be a positive integer.\")\n\n    # Group data by time in epochs and calculate the mean\n    processed_data = input_data.groupby(pd.Grouper(freq=f\"{epoch_duration}s\")).mean()\n\n    # Classify activity levels based on threshold values\n    processed_data[\"sedentary\"] = (processed_data[\"enmo\"] &lt; sedentary_threshold).astype(\n        int\n    )\n    processed_data[\"light\"] = (\n        (sedentary_threshold &lt;= processed_data[\"enmo\"])\n        &amp; (processed_data[\"enmo\"] &lt; light_threshold)\n    ).astype(int)\n    processed_data[\"moderate\"] = (\n        (light_threshold &lt;= processed_data[\"enmo\"])\n        &amp; (processed_data[\"enmo\"] &lt; moderate_threshold)\n    ).astype(int)\n    processed_data[\"vigorous\"] = (processed_data[\"enmo\"] &gt;= moderate_threshold).astype(\n        int\n    )\n\n    # Reset the index for the resulting DataFrame\n    processed_data.reset_index(inplace=True)\n\n    # Return a DataFrame with the time, averaged ENMO, and classes of sedentary, light, moderate and vigorous shown with 1 or 0.\n    return processed_data[\n        [time_column_name, \"enmo\", \"sedentary\", \"light\", \"moderate\", \"vigorous\"]\n    ]\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.convert_pulse_train_to_array","title":"<code>convert_pulse_train_to_array(pulse_train_list)</code>","text":"<p>Convert a List of Pulse Train Dictionaries to a 2D Array.</p> <p>This function takes a list of pulse train dictionaries and converts it into a 2D array. Each dictionary is expected to have keys 'start' and 'end', and the function creates an array where each row corresponds to a dictionary with the 'start' value in the first column and the 'end' value in the second column.</p> <p>Parameters:</p> Name Type Description Default <code>pulse_train_list</code> <code>list</code> <p>A list of dictionaries containing pulse train information.</p> required <p>Returns:</p> Name Type Description <code>array_representation</code> <code>ndarray</code> <p>A 2D array where each row represents a pulse train with the 'start' value                                 in the first column and the 'end' value in the second column.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def convert_pulse_train_to_array(pulse_train_list):\n    \"\"\"\n    Convert a List of Pulse Train Dictionaries to a 2D Array.\n\n    This function takes a list of pulse train dictionaries and converts it into a 2D array.\n    Each dictionary is expected to have keys 'start' and 'end', and the function creates an array\n    where each row corresponds to a dictionary with the 'start' value in the first column and the\n    'end' value in the second column.\n\n    Args:\n        pulse_train_list (list): A list of dictionaries containing pulse train information.\n\n    Returns:\n        array_representation(numpy.ndarray): A 2D array where each row represents a pulse train with the 'start' value\n                                            in the first column and the 'end' value in the second column.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(pulse_train_list, list):\n        raise ValueError(\"Input should be a list of pulse train dictionaries.\")\n\n    # Check if the list is empty\n    if not pulse_train_list:\n        raise ValueError(\"Input list is empty.\")\n\n    # Check that each element in the list is a dictionary with the expected keys\n    for pulse_train in pulse_train_list:\n        if not isinstance(pulse_train, dict):\n            raise ValueError(\"Each element in the list should be a dictionary.\")\n        if \"start\" not in pulse_train or \"end\" not in pulse_train:\n            raise ValueError(\"Each dictionary should contain 'start' and 'end' keys.\")\n\n    # Initialize a 2D array with the same number of rows as pulse train dictionaries and 2 columns.\n    array_representation = np.zeros((len(pulse_train_list), 2), dtype=np.uint64)\n\n    # Iterate through the list of pulse train dictionaries.\n    for i, pulse_train_dict in enumerate(pulse_train_list):\n        array_representation[i, 0] = pulse_train_dict[\"start\"]\n        array_representation[i, 1] = pulse_train_dict[\"end\"]\n\n    return array_representation\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.find_consecutive_groups","title":"<code>find_consecutive_groups(input_signal)</code>","text":"<p>Find consecutive groups of non-zero values in an input array.</p> <p>This function takes an input array <code>input_signal</code>, converts it to a column vector, and identifies consecutive groups of non-zero values. It returns a 2D array where each row represents a group, with the first column containing the start index of the group and the second column containing the end index of the group.</p> <p>Parameters:</p> Name Type Description Default <code>input_signal</code> <code>ndarray</code> <p>The input array.</p> required <p>Returns:</p> Name Type Description <code>ind</code> <code>ndarray</code> <p>A 2D array where each row represents a group of consecutive non-zero values. The first column contains the start index of the group, and the second column contains the end index.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def find_consecutive_groups(input_signal):\n    \"\"\"\n    Find consecutive groups of non-zero values in an input array.\n\n    This function takes an input array `input_signal`, converts it to a column vector, and identifies consecutive groups of\n    non-zero values. It returns a 2D array where each row represents a group, with the first column containing\n    the start index of the group and the second column containing the end index of the group.\n\n    Parameters:\n        input_signal (ndarray): The input array.\n\n    Returns:\n        ind (ndarray): A 2D array where each row represents a group of consecutive non-zero values.\n            The first column contains the start index of the group, and the second column contains the end index.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(input_signal, np.ndarray):\n        raise ValueError(\"Input data must be a NumPy array.\")\n\n    if input_signal.size &lt; 1:\n        raise ValueError(\"Input data must not be empty.\")\n\n    # Find indices of non-zeros elements\n    temp = np.where(input_signal)[0]\n\n    # Find where the difference between indices is greater than 1\n    idx = np.where(np.diff(temp) &gt; 1)[0]\n\n    # Initialize the output array\n    ind = np.zeros((len(idx) + 1, 2), dtype=int)\n\n    # Set the second column\n    ind[:, 1] = temp[np.append(idx, -1)]\n\n    # Set the first column\n    ind[:, 0] = temp[np.insert(idx + 1, 0, 0)]\n\n    return ind\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.find_interval_intersection","title":"<code>find_interval_intersection(set_a, set_b)</code>","text":"<p>Find the Intersection of Two Sets of Intervals.</p> <p>Given two sets of intervals, this function computes their intersection and returns a new set of intervals representing the overlapping regions.</p> <p>Parameters:</p> Name Type Description Default <code>set_a</code> <code>ndarray</code> <p>The first set of intervals, where each row represents an interval with two values indicating the start and end points.</p> required <code>set_b</code> <code>ndarray</code> <p>The second set of intervals, with the same structure as <code>set_a</code>.</p> required <p>Returns:</p> Name Type Description <code>intersection_intervals</code> <code>ndarray</code> <p>A new set of intervals representing the intersection of intervals from <code>set_a</code> and <code>set_b</code>.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def find_interval_intersection(set_a, set_b):\n    \"\"\"\n    Find the Intersection of Two Sets of Intervals.\n\n    Given two sets of intervals, this function computes their intersection and returns a new set\n    of intervals representing the overlapping regions.\n\n    Args:\n        set_a (numpy.ndarray): The first set of intervals, where each row represents an interval with two values\n            indicating the start and end points.\n        set_b (numpy.ndarray): The second set of intervals, with the same structure as `set_a`.\n\n    Returns:\n        intersection_intervals (numpy.ndarray): A new set of intervals representing the intersection of intervals from `set_a` and `set_b`.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(set_a, np.ndarray) or not isinstance(set_b, np.ndarray):\n        raise ValueError(\"Both input sets should be NumPy arrays.\")\n\n    # Check if the input sets have the correct structure (two columns)\n    if set_a.shape[1] != 2 or set_b.shape[1] != 2:\n        raise ValueError(\n            \"Input sets should have two columns, indicating start and end points.\"\n        )\n\n    # Get the number of intervals in each set.\n    num_intervals_a = set_a.shape[0]\n    num_intervals_b = set_b.shape[0]\n\n    # Initialize an empty list to store the intersection intervals.\n    intersection_intervals = []\n\n    # If either set of intervals is empty, return an empty array.\n    if num_intervals_a == 0 or num_intervals_b == 0:\n        return np.array(intersection_intervals)\n\n    # Initialize indices and state variables for set_a and set_b traversal.\n    index_a = 0\n    index_b = 0\n    state = 3\n\n    # Traverse both sets of intervals and compute their intersection.\n    while index_a &lt; num_intervals_a and index_b &lt; num_intervals_b:\n        if state == 1:\n            if set_a[index_a, 1] &lt; set_b[index_b, 0]:\n                index_a += 1\n                state = 3\n            elif set_a[index_a, 1] &lt; set_b[index_b, 1]:\n                intersection_intervals.append([set_b[index_b, 0], set_a[index_a, 1]])\n                index_a += 1\n                state = 2\n            else:\n                intersection_intervals.append(set_b[index_b, :])\n                index_b += 1\n        elif state == 2:\n            if set_b[index_b, 1] &lt; set_a[index_a, 0]:\n                index_b += 1\n                state = 3\n            elif set_b[index_b, 1] &lt; set_a[index_a, 1]:\n                intersection_intervals.append([set_a[index_a, 0], set_b[index_b, 1]])\n                index_b += 1\n                state = 1\n            else:\n                intersection_intervals.append(set_a[index_a, :])\n                index_a += 1\n        elif state == 3:\n            if set_a[index_a, 0] &lt; set_b[index_b, 0]:\n                state = 1\n            else:\n                state = 2\n\n    return np.array(intersection_intervals)\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.find_local_min_max","title":"<code>find_local_min_max(signal, threshold=None)</code>","text":"<p>Find Local Minima and Maxima in a Given Signal.</p> <p>This function takes an input signal and identifies the indices of local minima and maxima. Optionally, a threshold can be provided to filter out minima and maxima that do not exceed the threshold.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The input signal.</p> required <code>threshold</code> <code>float or None</code> <p>Threshold for filtering out minima and maxima below and above this value, respectively.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>minima_indices</code> <code>ndarray</code> <p>Indices of local minima in the signal.</p> <code>maxima_indices</code> <code>ndarray</code> <p>Indices of local maxima in the signal.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def find_local_min_max(signal, threshold=None):\n    \"\"\"\n    Find Local Minima and Maxima in a Given Signal.\n\n    This function takes an input signal and identifies the indices of local minima and maxima.\n    Optionally, a threshold can be provided to filter out minima and maxima that do not exceed the threshold.\n\n    Parameters:\n        signal (numpy.ndarray): The input signal.\n        threshold (float or None, optional): Threshold for filtering out minima and maxima below and above this value, respectively.\n\n    Returns:\n        minima_indices (numpy.ndarray): Indices of local minima in the signal.\n        maxima_indices (numpy.ndarray): Indices of local maxima in the signal.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(signal, np.ndarray):\n        raise ValueError(\"Input signal must be a NumPy array.\")\n\n    if signal.size &lt; 1:\n        raise ValueError(\"Input signal must not be empty.\")\n\n    # Find positive peaks in the signal\n    maxima_indices, _ = scipy.signal.find_peaks(signal)\n\n    # Find negative peaks in the inverted signal\n    minima_indices, _ = scipy.signal.find_peaks(-signal)\n\n    if threshold is not None:\n        maxima_indices = maxima_indices[signal[maxima_indices] &gt; threshold] + 1\n        minima_indices = minima_indices[signal[minima_indices] &lt; -threshold] + 1\n\n    return minima_indices, maxima_indices\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.highpass_filter","title":"<code>highpass_filter(signal, sampling_frequency=40, method='iir')</code>","text":"<p>Apply a high-pass filter to the input signal using the specified method.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The input signal to be filtered.</p> required <code>sampling_frequency</code> <code>float</code> <p>The sampling frequency of the input signal.</p> <code>40</code> <code>method</code> <code>str</code> <p>The filtering method to be used.</p> <code>'iir'</code> <p>Returns:</p> Name Type Description <code>filtered_signal</code> <code>ndarray</code> <p>The filtered signal.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def highpass_filter(signal, sampling_frequency=40, method=\"iir\"):\n    \"\"\"\n    Apply a high-pass filter to the input signal using the specified method.\n\n    Args:\n        signal (np.ndarray): The input signal to be filtered.\n        sampling_frequency (float): The sampling frequency of the input signal.\n        method (str): The filtering method to be used.\n\n    Returns:\n        filtered_signal (np.ndarray): The filtered signal.\n\n    \"\"\"\n    # Error handling for invalid input data\n    if (\n        not isinstance(signal, np.ndarray)\n        or not isinstance(sampling_frequency, (int, float))\n        or sampling_frequency &lt;= 0\n    ):\n        raise ValueError(\n            \"Invalid input data. The 'signal' must be a NumPy array, and 'sampling_frequency' must be a positive number.\"\n        )\n\n    if not isinstance(method, str):\n        raise ValueError(\"'method' must be a string.\")\n\n    method = method.lower()\n\n    if method == \"iir\":\n        filtered_signal = _iir_highpass_filter(signal, sampling_frequency)\n    else:\n        raise ValueError(f\"Unsupported filtering method: {method}\")\n\n    return filtered_signal\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.identify_pulse_trains","title":"<code>identify_pulse_trains(signal)</code>","text":"<p>Identify Pulse Trains in a Given Signal.</p> <p>This function takes an input signal and detects pulse trains within the signal. A pulse train is identified as a sequence of values with small intervals between adjacent values.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The input signal.</p> required <p>Returns:</p> Name Type Description <code>pulse_train</code> <code>list</code> <p>A list of dictionaries, each containing information about a detected pulse train. Each dictionary has the following keys:</p> <p><code>start</code>: The index of the first value in the pulse train.</p> <p><code>end</code>: The index of the last value in the pulse train.</p> <p><code>steps</code>: The number of steps in the pulse train.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def identify_pulse_trains(signal):\n    \"\"\"\n    Identify Pulse Trains in a Given Signal.\n\n    This function takes an input signal and detects pulse trains within the signal.\n    A pulse train is identified as a sequence of values with small intervals between adjacent values.\n\n    Args:\n        signal (numpy.ndarray): The input signal.\n\n    Returns:\n        pulse_train (list): A list of dictionaries, each containing information about a detected pulse train.\n            Each dictionary has the following keys:\n\n            `start`: The index of the first value in the pulse train.\n\n            `end`: The index of the last value in the pulse train.\n\n            `steps`: The number of steps in the pulse train.\n    \"\"\"\n    # Error handling for invalid input data\n    if signal.size &lt; 1:\n        raise ValueError(\"Input signal must not be empty.\")\n\n    # Initialize an empty list to store detected pulse trains.\n    pulse_trains = []\n\n    # Initialize a flag to track whether we are within a pulse train.\n    walking_flag = 0\n\n    # Set an initial threshold value for pulse train detection.\n    threshold = 3.5 * 40\n\n    # Initialize a counter for the number of detected pulse trains.\n    pulse_count = 0\n\n    # Check if the signal has more than 2 elements.\n    if len(signal) &gt; 2:\n        for i in range(len(signal) - 1):\n            # Check if the difference between adjacent values is less than the threshold.\n            if signal[i + 1] - signal[i] &lt; threshold:\n                if walking_flag == 0:\n                    # If not already in a pulse train, start a new one.\n                    pulse_trains.append({\"start\": signal[i], \"steps\": 1})\n                    pulse_count += 1\n                    walking_flag = 1\n                else:\n                    # If already in a pulse train, update the number of steps and threshold.\n                    pulse_trains[pulse_count - 1][\"steps\"] += 1\n                    threshold = (\n                        1.5 * 40\n                        + (signal[i] - pulse_trains[pulse_count - 1][\"start\"])\n                        / pulse_trains[pulse_count - 1][\"steps\"]\n                    )\n            else:\n                if walking_flag == 1:\n                    # If leaving a pulse train, record its end and reset threshold.\n                    pulse_trains[pulse_count - 1][\"end\"] = signal[i - 1]\n                    walking_flag = 0\n                    threshold = 3.5 * 40\n\n    if walking_flag == 1:\n        if signal[-1] - signal[-2] &lt; threshold:\n            # If still in a pulse train at the end, record its end and update steps.\n            pulse_trains[-1][\"end\"] = signal[-1]\n            pulse_trains[-1][\"steps\"] += 1\n        else:\n            # If leaving a pulse train at the end, record its end.\n            pulse_trains[-1][\"end\"] = signal[-2]\n\n    return pulse_trains\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.lowpass_filter","title":"<code>lowpass_filter(signal, method='savgol', order=None, **kwargs)</code>","text":"<p>Apply a low-pass filter to the input signal.</p> <p>Parameters:</p> Name Type Description Default <code>signal</code> <code>ndarray</code> <p>The input signal to be filtered.</p> required <code>method</code> <code>str</code> <p>The filter method to use (\"savgol\", \"butter\", or \"fir\").</p> <code>'savgol'</code> <code>order</code> <code>int</code> <p>The order of the filter (applicable for \"butter\" method).</p> <code>None</code> <code>**kwargs</code> <code>dict</code> <p>Additional keyword arguments specific to the Savitzky-Golay filter method or other methods.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>filt_signal</code> <code>ndarray</code> <p>The filtered signal.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def lowpass_filter(signal, method=\"savgol\", order=None, **kwargs: dict):\n    \"\"\"\n    Apply a low-pass filter to the input signal.\n\n    Args:\n        signal (numpy.ndarray): The input signal to be filtered.\n        method (str): The filter method to use (\"savgol\", \"butter\", or \"fir\").\n        order (int): The order of the filter (applicable for \"butter\" method).\n        **kwargs: Additional keyword arguments specific to the Savitzky-Golay filter method or other methods.\n\n    Returns:\n        filt_signal (numpy.ndarray): The filtered signal.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(signal, np.ndarray):\n        raise ValueError(\"Input data must be a numpy.ndarray\")\n\n    if not isinstance(method, str):\n        raise ValueError(\"'method' must be a string.\")\n\n    method = method.lower()\n\n    # Define default parameters for Savitzky-Golay filter\n    default_savgol_params = {\n        \"window_length\": 21,\n        \"polynomial_order\": 7,\n    }\n\n    # Define default parameters for FIR filter\n    default_fir_params = {\n        \"fir_file\": mat_filter_coefficients_file,\n    }\n\n    if method == \"savgol\":\n        # Update default parameters with any provided kwargs\n        savgol_params = {**default_savgol_params, **kwargs}\n        window_length = savgol_params.get(\n            \"window_length\", default_savgol_params[\"window_length\"]\n        )\n        polynomial_order = savgol_params.get(\n            \"polynomial_order\", default_savgol_params[\"polynomial_order\"]\n        )\n\n        filt_signal = scipy.signal.savgol_filter(\n            signal, window_length, polynomial_order\n        )\n        return filt_signal\n\n    elif method == \"butter\":\n        # Extract parameters specific to butterworth filter\n        cutoff_freq_hz = kwargs.get(\"cutoff_freq_hz\", 5.0)\n        sampling_rate_hz = kwargs.get(\"sampling_rate_hz\", 200.0)\n\n        if order is None:\n            raise ValueError(\"For Butterworth filter, 'order' must be specified.\")\n\n        # Apply butterworth lowpass filter\n        b, a = scipy.signal.butter(\n            N=order,\n            Wn=cutoff_freq_hz / (sampling_rate_hz / 2),\n            btype=\"low\",\n            analog=False,\n            fs=sampling_rate_hz,\n        )\n        filt_signal = scipy.signal.filtfilt(b, a, signal)\n        return filt_signal\n\n    elif method == \"fir\":\n        # Update default parameters with any provided kwargs\n        fir_params = {**default_fir_params, **kwargs}\n        fir_file = fir_params.get(\"fir_file\", default_fir_params[\"fir_file\"])\n\n        # Load FIR low-pass filter coefficients from the specified MAT file\n        lowpass_coefficients = scipy.io.loadmat(fir_file)\n        numerator_coefficient = lowpass_coefficients[\"Num\"][0, :]\n\n        # Define the denominator coefficients as [1.0] to perform FIR filtering\n        denominator_coefficient = np.array([1.0])\n\n        # Apply the FIR low-pass filter using filtfilt\n        filtered_signal = scipy.signal.filtfilt(\n            numerator_coefficient, denominator_coefficient, signal\n        )\n\n        return filtered_signal\n\n    else:\n        raise ValueError(\"Invalid filter method specified\")\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.max_peaks_between_zc","title":"<code>max_peaks_between_zc(input_signal)</code>","text":"<p>Find peaks and their locations from the vector input_signal between zero crossings.</p> <p>Parameters:</p> Name Type Description Default <code>input_signal</code> <code>ndarray</code> <p>Input column vector.</p> required <p>Returns:</p> Name Type Description <code>pks</code> <code>ndarray</code> <p>Signed max/min values between zero crossings.</p> <code>ipks</code> <code>ndarray</code> <p>Locations of the peaks in the original vector.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def max_peaks_between_zc(input_signal):\n    \"\"\"\n    Find peaks and their locations from the vector input_signal between zero crossings.\n\n    Args:\n        input_signal (numpy.ndarray): Input column vector.\n\n    Returns:\n        pks (numpy.ndarray): Signed max/min values between zero crossings.\n        ipks (numpy.ndarray): Locations of the peaks in the original vector.\n    \"\"\"\n    # Flatten the input vector to ensure it's 1D.\n    input_signal = input_signal.flatten()\n\n    # Find the locations of zero crossings in the input vector.\n    zero_crossings_locations = (\n        np.where(np.abs(np.diff(np.sign(input_signal))) == 2)[0] + 1\n    )\n\n    # Calculate the number of peaks.\n    number_of_peaks = len(zero_crossings_locations) - 1\n\n    def imax(input_signal):\n        return np.argmax(input_signal)\n\n    # Find the indices of the maximum values within each peak region.\n    ipk = np.array(\n        [\n            imax(\n                np.abs(\n                    input_signal[\n                        zero_crossings_locations[i] : zero_crossings_locations[i + 1]\n                    ]\n                )\n            )\n            for i in range(number_of_peaks)\n        ]\n    )\n    ipks = zero_crossings_locations[:number_of_peaks] + ipk\n    ipks = ipks + 1\n\n    # Retrieve the signed max/min values at the peak locations.\n    pks = input_signal[ipks - 1]\n\n    return pks, ipks\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.moving_var","title":"<code>moving_var(data, window)</code>","text":"<p>Compute the centered moving variance.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>int) </code> <p>Data to take the moving variance on window</p> required <code>window</code> <code>size(int)</code> <p>Window size for the moving variance.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>m_var (numpy.ndarray) : Moving variance</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def moving_var(data, window) -&gt; np.ndarray:\n    \"\"\"\n    Compute the centered moving variance.\n\n    Args:\n        data (int) : Data to take the moving variance on window\n        window size (int) : Window size for the moving variance.\n\n    Returns:\n        m_var (numpy.ndarray) : Moving variance\n    \"\"\"\n\n    # Initialize an array to store the moving variance\n    m_var = np.zeros(data.shape)\n\n    # Calculate the padding required\n    pad = int(np.ceil(window / 2))\n\n    # Define the shape and strides for creating rolling windows\n    shape = data.shape[:-1] + (data.shape[-1] - window + 1, window)\n    strides = data.strides + (data.strides[-1],)\n\n    # Create rolling windows from the input data\n    rw_seq = np.lib.stride_tricks.as_strided(data, shape=shape, strides=strides)\n\n    # Compute the variance along the rolling windows and store it in m_var\n    n = rw_seq.shape[0]\n    m_var[pad : pad + n] = np.var(rw_seq, axis=-1, ddof=1)\n\n    # Copy the variance values to the padding regions\n    m_var[:pad], m_var[pad + n :] = m_var[pad], m_var[-pad - 1]\n\n    return m_var\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.organize_and_pack_results","title":"<code>organize_and_pack_results(walking_periods, peak_steps)</code>","text":"<p>Organize and Pack Walking Results with Associated Peak Steps.</p> <p>Given lists of walking periods and peak step indices, this function organizes and packs the results into a more structured format. It calculates the number of steps in each walking period, associates peak steps with their corresponding walking periods, and extends the duration of walking periods based on step time. The function also checks for overlapping walking periods and merges them.</p> <p>Parameters:</p> Name Type Description Default <code>walking_periods</code> <code>list</code> <p>List of tuples representing walking periods, where each tuple contains the start and end indices.</p> required <code>peak_steps</code> <code>list</code> <p>List of peak step indices.</p> required <p>Returns:</p> Name Type Description <code>organized_results</code> <code>list</code> <p>A list of dictionaries representing organized walking results, each dictionary contains:</p> <pre><code>- 'start': Start index of the walking period.\n\n- 'end': End index of the walking period.\n\n- 'steps': Number of steps within the walking period.\n\n- 'mid_swing': List of peak step indices within the walking period.\n</code></pre> <code>all_mid_swing</code> <code>list</code> <p>A list of sorted peak step indices across all walking periods.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def organize_and_pack_results(walking_periods, peak_steps):\n    \"\"\"Organize and Pack Walking Results with Associated Peak Steps.\n\n    Given lists of walking periods and peak step indices, this function organizes and packs the results\n    into a more structured format. It calculates the number of steps in each walking period, associates\n    peak steps with their corresponding walking periods, and extends the duration of walking periods based\n    on step time. The function also checks for overlapping walking periods and merges them.\n\n    Args:\n        walking_periods (list): List of tuples representing walking periods, where each tuple contains the start and end indices.\n        peak_steps (list): List of peak step indices.\n\n    Returns:\n        organized_results (list): A list of dictionaries representing organized walking results, each dictionary contains:\n\n                - 'start': Start index of the walking period.\n\n                - 'end': End index of the walking period.\n\n                - 'steps': Number of steps within the walking period.\n\n                - 'mid_swing': List of peak step indices within the walking period.\n\n        all_mid_swing (list): A list of sorted peak step indices across all walking periods.\n    \"\"\"\n    # Calculate the number of walking periods.\n    num_periods = len(walking_periods)\n\n    # Initialize a list of dictionaries to store organized walking results.\n    organized_results = [\n        {\n            \"start\": walking_periods[i][0],\n            \"end\": walking_periods[i][1],\n            \"steps\": 0,\n            \"mid_swing\": [],\n        }\n        for i in range(num_periods)\n    ]\n\n    # Initialize a list to store all peak step indices.\n    all_mid_swing = []\n\n    # Iterate through each walking period.\n    for i in range(num_periods):\n        # Find peak steps within the current walking period.\n        steps_within_period = [\n            p\n            for p in peak_steps\n            if organized_results[i][\"start\"] &lt;= p &lt;= organized_results[i][\"end\"]\n        ]\n\n        # Calculate the number of steps within the walking period.\n        organized_results[i][\"steps\"] = len(steps_within_period)\n\n        # Store the peak step indices within the walking period.\n        organized_results[i][\"mid_swing\"] = steps_within_period\n\n        # Add peak step indices to the list of all peak step indices.\n        all_mid_swing.extend(steps_within_period)\n\n        # Calculate step time based on detected peak steps\n        if len(steps_within_period) &gt; 2:\n            step_time = sum(\n                [\n                    steps_within_period[j + 1] - steps_within_period[j]\n                    for j in range(len(steps_within_period) - 1)\n                ]\n            ) / (len(steps_within_period) - 1)\n            organized_results[i][\"start\"] = int(\n                organized_results[i][\"start\"] - 1.5 * step_time / 2\n            )\n            organized_results[i][\"end\"] = int(\n                organized_results[i][\"end\"] + 1.5 * step_time / 2\n            )\n\n    # Sort all peak step indices.\n    all_mid_swing.sort()\n\n    # Check for overlapping walking periods and merge them\n    i = 0\n    while i &lt; num_periods - 1:\n        if organized_results[i][\"end\"] &gt;= organized_results[i + 1][\"start\"]:\n            organized_results[i][\"end\"] = organized_results[i + 1][\"end\"]\n            organized_results[i][\"steps\"] += organized_results[i + 1][\"steps\"]\n            organized_results[i][\"mid_swing\"].extend(\n                organized_results[i + 1][\"mid_swing\"]\n            )\n            organized_results.pop(i + 1)\n            num_periods -= 1\n        else:\n            i += 1\n\n    return organized_results, all_mid_swing\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.process_postural_transitions_stationary_periods","title":"<code>process_postural_transitions_stationary_periods(time, accel, gyro, stationary, tilt_angle_deg, sampling_period, sampling_freq_Hz, init_period, local_peaks)</code>","text":"<p>Estimate orientation and analyze postural transitions based on sensor data.</p> <p>Parameters:</p> Name Type Description Default <code>time</code> <code>ndarray</code> <p>Array of timestamps.</p> required <code>accel</code> <code>ndarray</code> <p>Array of accelerometer data (3D).</p> required <code>gyro</code> <code>ndarray</code> <p>Array of gyroscope data (3D).</p> required <code>stationary</code> <code>ndarray</code> <p>Array indicating stationary periods.</p> required <code>tilt_angle_deg</code> <code>ndarray</code> <p>Array of tilt angle data.</p> required <code>sampling_period</code> <code>float</code> <p>Sampling period in seconds.</p> required <code>sampling_freq_Hz</code> <code>float</code> <p>Sampling frequency in Hz.</p> required <code>init_period</code> <code>float</code> <p>Initialization period in seconds.</p> required <code>local_peaks</code> <code>ndarray</code> <p>Array of indices indicating local peaks.</p> required <p>Returns:</p> Name Type Description <code>time_pt</code> <code>list</code> <p>List of peak times.</p> <code>pt_type</code> <code>list</code> <p>List of postural transition types.</p> <code>pt_angle</code> <code>list</code> <p>List of postural transition angles.</p> <code>duration</code> <code>list</code> <p>List of postural transition durations.</p> <code>flexion_max_vel</code> <code>list</code> <p>List of maximum flexion velocities.</p> <code>extension_max_vel</code> <code>list</code> <p>List of maximum extension velocities.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def process_postural_transitions_stationary_periods(\n    time,\n    accel,\n    gyro,\n    stationary,\n    tilt_angle_deg,\n    sampling_period,\n    sampling_freq_Hz,\n    init_period,\n    local_peaks,\n):\n    \"\"\"\n    Estimate orientation and analyze postural transitions based on sensor data.\n\n    Args:\n        time (ndarray): Array of timestamps.\n        accel (ndarray): Array of accelerometer data (3D).\n        gyro (ndarray): Array of gyroscope data (3D).\n        stationary (ndarray): Array indicating stationary periods.\n        tilt_angle_deg (ndarray): Array of tilt angle data.\n        sampling_period (float): Sampling period in seconds.\n        sampling_freq_Hz (float): Sampling frequency in Hz.\n        init_period (float): Initialization period in seconds.\n        local_peaks (ndarray): Array of indices indicating local peaks.\n\n    Returns:\n        time_pt (list): List of peak times.\n        pt_type (list): List of postural transition types.\n        pt_angle (list): List of postural transition angles.\n        duration (list): List of postural transition durations.\n        flexion_max_vel (list): List of maximum flexion velocities.\n        extension_max_vel (list): List of maximum extension velocities.\n    \"\"\"\n    # Check if input arrays are empty\n    if any(arr.size == 0 for arr in [time, accel, gyro, stationary, tilt_angle_deg]):\n        raise ValueError(\"Input arrays cannot be empty\")\n\n    # If there is enough stationary data, perform sensor fusion using accelerometer and gyro data\n    # Initialize quaternion array for orientation estimation\n    quat = np.zeros((len(time), 4))\n\n    # Initial convergence: Update the quaternion using the mean accelerometer values over a certain period\n    # This helps in initializing the orientation for accurate estimation\n    index_sel = np.arange(0, np.where(time &gt;= time[0] + init_period)[0][0] + 1)\n    mean_accel = np.mean(accel[index_sel], axis=0)\n    quat[0] = quaternion.rotm2quat(np.eye(3) + quaternion.axang2rotm(mean_accel))\n\n    # Update the quaternion for all data points\n    for t in range(1, len(time)):\n        # Calculate the rotation matrix from gyroscope data\n        dt = time[t] - time[t - 1]\n        ang_velocity = gyro[t] * dt\n        delta_rot = quaternion.axang2rotm(ang_velocity)\n\n        # Update the quaternion based on the rotation matrix\n        quat[t] = quaternion.quatmultiply(quat[t - 1], quaternion.rotm2quat(delta_rot))\n\n        # Normalize the quaternion to avoid drift\n        quat[t] = quaternion.quatnormalize(quat[t])\n\n    # Analyze gyro data to detect peak velocities and directional changes\n    # Zero-crossing method is used to define the beginning and the end of a PT in the gyroscope signal\n    iZeroCr = np.where((gyro[:, 1][:-1] * gyro[:, 1][1:]) &lt; 0)[0]\n\n    # Calculate the difference between consecutive values\n    gyrY_diff = np.diff(gyro[:, 1])\n\n    # Beginning of a PT was defined as the first zero crossing point of themedio-lateral angular\n    # velocity (gyro[:,1]) on the left side of the PT event, with negative slope.\n    # Initialize left side indices with ones\n    ls = np.ones_like(local_peaks)\n\n    # Initialize right side indices with length of gyro data\n    # rs = len(gyro[:,1]) * np.ones_like(local_peaks)\n    rs = np.full_like(local_peaks, len(gyro[:, 1]))\n    for i in range(len(local_peaks)):\n        # Get the index of the current local peak\n        pt = local_peaks[i]\n\n        # Calculate distances to all zero-crossing points relative to the peak\n        dist2peak = iZeroCr - pt\n\n        # Extract distances to zero-crossing points on the left side of the peak\n        dist2peak_ls = dist2peak[dist2peak &lt; 0]\n\n        # Extract distances to zero-crossing points on the right side of the peak\n        dist2peak_rs = dist2peak[dist2peak &gt; 0]\n\n        # Iterate over distances to zero-crossing points on the left side of the peak (in reverse order)\n        for j in range(len(dist2peak_ls) - 1, -1, -1):\n            # Check if slope is down and the left side not too close to the peak (more than 200ms)\n            if gyrY_diff[pt + dist2peak_ls[j]] &lt; 0 and -dist2peak_ls[j] &gt; 25:\n                # Store the index of the left side\n                ls[i] = pt + dist2peak_ls[j]\n                break\n\n    # Further analysis to distinguish between different types of postural transitions (sit-to-stand or stand-to-sit)\n    # Rotate body accelerations to Earth frame\n    acc = quaternion.rotm2quat(\n        np.column_stack((accel[:, 0], accel[:, 1], accel[:, 2])), quat\n    )\n\n    # Remove gravity from measurements\n    acc -= np.array([[0, 0, 1]] * len(time))\n\n    # Convert acceletion data to m/s^2\n    acc *= 9.81\n\n    # Calculate velocities\n    vel = np.zeros_like(acc)\n\n    # Iterate over time steps\n    for t in range(1, len(vel)):\n        # Integrate acceleration to calculate velocity\n        vel[t, :] = vel[t - 1, :] + acc[t, :] * sampling_period\n        if stationary[t] == 1:\n            # Force zero velocity when stationary\n            vel[t, :] = [0, 0, 0]\n\n    # Compute and remove integral drift\n    velDrift = np.zeros_like(vel)\n\n    # Indices where stationary changes to non-stationary\n    activeStart = np.where(np.diff(stationary) == -1)[0]\n\n    # Indices where non-stationary changes to stationary\n    activeEnd = np.where(np.diff(stationary) == 1)[0]\n    if activeStart[0] &gt; activeEnd[0]:\n        # Ensure start from index 0 if starts non-stationary\n        activeStart = np.insert(activeStart, 0, 0)\n\n    if activeStart[-1] &gt; activeEnd[-1]:\n        # Ensure last segment ends properly\n        activeEnd = np.append(activeEnd, len(stationary))\n    for i in range(len(activeEnd)):\n        # Calculate drift rate\n        driftRate = vel[activeEnd[i] - 1] / (activeEnd[i] - activeStart[i])\n\n        # Enumerate time steps within the segment\n        enum = np.arange(1, activeEnd[i] - activeStart[i] + 1)\n\n        # Calculate drift for each time step\n        drift = np.column_stack(\n            (enum * driftRate[0], enum * driftRate[1], enum * driftRate[2])\n        )\n\n        # Store the drift for this segment\n        velDrift[activeStart[i] : activeEnd[i], :] = drift\n\n    # Remove integral drift from velocity\n    vel -= velDrift\n\n    # Compute translational position\n    pos = np.zeros_like(vel)\n\n    # Iterate over time steps\n    for t in range(1, len(pos)):\n        # Integrate velocity to yield position\n        pos[t, :] = pos[t - 1, :] + vel[t, :] * sampling_period\n\n    # Estimate vertical displacement and classify as actual PTs or Attempts\n    # Calculate vertical displacement\n    disp_z = pos[rs, 2] - pos[ls, 2]\n\n    # Initialize flag for actual PTs\n    pt_actual_flag = np.zeros_like(local_peaks)\n\n    for i in range(len(disp_z)):\n        # Displacement greater than 10cm and less than 1m\n        if 0.1 &lt; abs(disp_z[i]) &lt; 1:\n            # Flag as actual PT if displacement meets criteria\n            pt_actual_flag[i] = 1\n\n    # Initialize list for PT types\n    pt_type = []\n\n    # Distinguish between different types of postural transitions\n    for i in range(len(local_peaks)):\n        if pt_actual_flag[i] == 1:\n            if disp_z[i] == 0:\n                pt_type.append(\"NA\")\n            elif disp_z[i] &gt; 0:\n                pt_type.append(\"sit to stand\")\n            else:\n                pt_type.append(\"stand to sit\")\n        else:\n            pt_type.append(\"NA\")\n\n    # Calculate maximum flexion velocity and maximum extension velocity\n    flexion_max_vel = np.zeros_like(local_peaks)\n    extension_max_vel = np.zeros_like(local_peaks)\n    for i in range(len(local_peaks)):\n        flexion_max_vel[i] = max(abs(gyro[:, 1][ls[i] : local_peaks[i]]))\n        extension_max_vel[i] = max(abs(gyro[:, 1][local_peaks[i] : rs[i]]))\n\n    # Calculate PT angle\n    pt_angle = np.abs(tilt_angle_deg[local_peaks] - tilt_angle_deg[ls])\n    if ls[0] == 0:\n        # Adjust angle for the first PT if necessary\n        pt_angle[0] = np.abs(tilt_angle_deg[local_peaks[0]] - tilt_angle_deg[rs[0]])\n\n    # Calculate duration of each PT\n    duration = (rs - ls) / sampling_freq_Hz\n\n    # Convert peak times to integers\n    time_pt = time[local_peaks]\n\n    # Initialize PTs list\n    # i.e., the participant was considered to perform a complete standing up or sitting down movement\n    PTs = [\n        [\n            \"Time[s]\",\n            \"Type\",\n            \"Angle[\u00b0]\",\n            \"Duration[s]\",\n            \"Max flexion velocity[\u00b0/s]\",\n            \"Max extension velocity[\u00b0/s]\",\n            \"Vertical displacement[m]\",\n        ]\n    ]\n\n    # Initialize Attempts list\n    # i.e., the participant was considered not to perform a complete PT, e.g., forward and backwards body motion\n    Attempts = [\n        [\n            \"Time[s]\",\n            \"Type\",\n            \"Angle[\u00b0]\",\n            \"Duration[s]\",\n            \"Max flexion velocity[\u00b0/s]\",\n            \"Max extension velocity[\u00b0/s]\",\n            \"Vertical displacement[m]\",\n        ]\n    ]\n\n    # Iterate over detected peaks\n    for i in range(len(local_peaks)):\n        if pt_actual_flag[i] == 1:\n            PTs.append(\n                [\n                    time_pt[i],\n                    pt_type[i],\n                    pt_angle[i],\n                    duration[i],\n                    flexion_max_vel[i],\n                    extension_max_vel[i],\n                    disp_z[i],\n                ]\n            )  # Append PT details to PTs list\n        else:\n            Attempts.append(\n                [\n                    time_pt[i],\n                    pt_type[i],\n                    pt_angle[i],\n                    duration[i],\n                    flexion_max_vel[i],\n                    extension_max_vel[i],\n                    disp_z[i],\n                ]\n            )  # Append PT details to Attempts list\n\n    # Extract postural transition information from PTs\n    time_pt = [pt[0] for pt in PTs[1:]]\n    pt_type = [pt[1] for pt in PTs[1:]]\n    pt_angle = [pt[2] for pt in PTs[1:]]\n    duration = [pt[3] for pt in PTs[1:]]\n    flexion_max_vel = [pt[4] for pt in PTs[1:]]\n    extension_max_vel = [pt[5] for pt in PTs[1:]]\n\n    # Return the necessary outputs\n    return time_pt, pt_type, pt_angle, duration, flexion_max_vel, extension_max_vel\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.resample_interpolate","title":"<code>resample_interpolate(input_signal, initial_sampling_frequency, target_sampling_frequency)</code>","text":"<p>Resample and interpolate a signal to a new sampling frequency.</p> <p>This function takes a signal <code>input_signal</code> sampled at an initial sampling frequency <code>initial_sampling_frequency</code> and resamples it to a target sampling frequency <code>target_sampling_frequency</code> using linear interpolation.</p> <p>Parameters:</p> Name Type Description Default <code>input_signal</code> <code>array_like</code> <p>The input signal.</p> required <code>initial_sampling_frequency</code> <code>float</code> <p>The initial sampling frequency of the input signal. Default is 100.</p> required <code>target_sampling_frequency</code> <code>float</code> <p>The target sampling frequency for the output signal. Default is 40.</p> required <p>Returns:</p> Name Type Description <code>resampled_signal</code> <code>array_like</code> <p>The resampled and interpolated signal.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def resample_interpolate(\n    input_signal, initial_sampling_frequency: float, target_sampling_frequency: float\n):\n    \"\"\"\n    Resample and interpolate a signal to a new sampling frequency.\n\n    This function takes a signal `input_signal` sampled at an initial sampling frequency `initial_sampling_frequency`\n    and resamples it to a target sampling frequency `target_sampling_frequency` using linear interpolation.\n\n    Args:\n        input_signal (array_like): The input signal.\n        initial_sampling_frequency (float, optional): The initial sampling frequency of the input signal. Default is 100.\n        target_sampling_frequency (float, optional): The target sampling frequency for the output signal. Default is 40.\n\n    Returns:\n        resampled_signal (array_like): The resampled and interpolated signal.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(input_signal, np.ndarray):\n        raise ValueError(\"Input signal should be a NumPy array.\")\n\n    if (\n        not isinstance(initial_sampling_frequency, (int, float))\n        or initial_sampling_frequency &lt;= 0\n    ):\n        raise ValueError(\"The initial sampling frequency must be a positive float.\")\n\n    if (\n        not isinstance(target_sampling_frequency, (int, float))\n        or target_sampling_frequency &lt;= 0\n    ):\n        raise ValueError(\"The target sampling frequency must be a positive float.\")\n\n    # Calculate the length of the input signal.\n    recording_time = len(input_signal)\n\n    # Create an array representing the time indices of the input signal.\n    x = np.arange(1, recording_time + 1)\n\n    # Create an array representing the time indices of the resampled signal.\n    xq = np.arange(\n        1, recording_time + 1, initial_sampling_frequency / target_sampling_frequency\n    )\n\n    # Create an interpolation function using linear interpolation and apply it to the data.\n    interpolator = scipy.interpolate.interp1d(\n        x, input_signal, kind=\"linear\", axis=0, fill_value=\"extrapolate\"\n    )\n\n    # Resample and interpolate the input signal to the desired target sampling rate.\n    resampled_signal = interpolator(xq)\n\n    return resampled_signal\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.signal_decomposition_algorithm","title":"<code>signal_decomposition_algorithm(vertical_accelerarion_data, initial_sampling_frequency=100)</code>","text":"<p>Perform the Signal Decomposition algorithm on accelerometer data.</p> <p>Parameters:</p> Name Type Description Default <code>vertical_accelerarion_data</code> <code>ndarray</code> <p>Vertical Acceleration data.</p> required <code>initial_sampling_frequency</code> <code>float</code> <p>Sampling frequency of the data.</p> <code>100</code> <p>Returns:</p> Name Type Description <code>IC_seconds</code> <code>ndarray</code> <p>Detected IC (Initial Contact) timings in seconds.</p> <code>FC_seconds</code> <code>ndarray</code> <p>Detected FC (Foot-off Contact) timings in seconds.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def signal_decomposition_algorithm(\n    vertical_accelerarion_data, initial_sampling_frequency=100\n):\n    \"\"\"\n    Perform the Signal Decomposition algorithm on accelerometer data.\n\n    Args:\n        vertical_accelerarion_data (numpy.ndarray): Vertical Acceleration data.\n        initial_sampling_frequency (float): Sampling frequency of the data.\n\n    Returns:\n        IC_seconds (numpy.ndarray): Detected IC (Initial Contact) timings in seconds.\n        FC_seconds (numpy.ndarray): Detected FC (Foot-off Contact) timings in seconds.\n    \"\"\"\n    # Error handling for invalid input data\n    if not isinstance(vertical_accelerarion_data, np.ndarray):\n        raise ValueError(\"vertical_acceleration_data must be a numpy.ndarray\")\n\n    if len(vertical_accelerarion_data.shape) &lt; 1:\n        raise ValueError(\"vertical_acceleration_data must have at least one dimension\")\n\n    if (\n        not isinstance(initial_sampling_frequency, (int, float))\n        or initial_sampling_frequency &lt;= 0\n    ):\n        raise ValueError(\"The initial sampling frequency must be a positive float.\")\n\n    # Define the target sampling frequency for processing.\n    target_sampling_frequency = 40\n\n    # Resample and interpolate the vertical acceleration data to the target sampling frequency.\n    smoothed_vertical_accelerarion_data = resample_interpolate(\n        vertical_accelerarion_data,\n        initial_sampling_frequency,\n        target_sampling_frequency,\n    )\n\n    # Load filtering coefficients from a .mat file\n    filtering_file = scipy.io.loadmat(mat_filter_coefficients_file)\n    num = filtering_file[\"Num\"][0, :]\n    width_of_pad = 10000 * len(num)\n    smoothed_vertical_accelerarion_data_padded = np.pad(\n        smoothed_vertical_accelerarion_data, width_of_pad, mode=\"wrap\"\n    )\n\n    # Remove 40Hz drift from the filtered data\n    drift_removed_acceleration = highpass_filter(\n        signal=smoothed_vertical_accelerarion_data_padded,\n        sampling_frequency=target_sampling_frequency,\n        method=\"iir\",\n    )\n\n    # Filter data using the fir low-pass filter\n    detrended_vertical_acceleration_signal = lowpass_filter(\n        drift_removed_acceleration, method=\"fir\"\n    )\n\n    # Remove the padding from the detrended signal\n    detrended_vertical_acceleration_signal_lpf_rmzp = (\n        detrended_vertical_acceleration_signal[\n            width_of_pad\n            - 1 : len(detrended_vertical_acceleration_signal)\n            - width_of_pad\n        ]\n    )\n\n    # Integrate the detrended acceleration signal\n    det_ver_acc_sig_LPInt = (\n        scipy.integrate.cumulative_trapezoid(\n            detrended_vertical_acceleration_signal_lpf_rmzp, initial=\"0\"\n        )\n        / target_sampling_frequency\n    )\n\n    # Perform the continuous wavelet transform on the filtered acceleration data\n    smoothed_wavelet_result = apply_continuous_wavelet_transform(\n        det_ver_acc_sig_LPInt,\n        scales=9,\n        desired_scale=9,\n        wavelet=\"gaus2\",\n        sampling_frequency=target_sampling_frequency,\n    )\n\n    # Center the wavelet result around zero\n    smoothed_wavelet_result = smoothed_wavelet_result - np.mean(smoothed_wavelet_result)\n    smoothed_wavelet_result = np.array(smoothed_wavelet_result)\n\n    # Apply max_peaks_between_zc funtion to find peaks and their locations.\n    pks1, ipks1 = max_peaks_between_zc(smoothed_wavelet_result.T)\n\n    # Calculate indx1 (logical indices of negative elements)\n    indx1 = pks1 &lt; 0\n\n    # Extract IC (indices of negative peaks)\n    indices_of_negative_peaks = ipks1[indx1]\n\n    # Convert IC to seconds\n    IC_seconds = indices_of_negative_peaks / target_sampling_frequency\n\n    # Apply continuous wavelet transform\n    accVLPIntCwt2 = apply_continuous_wavelet_transform(\n        smoothed_wavelet_result,\n        scales=9,\n        desired_scale=9,\n        wavelet=\"gaus2\",\n        sampling_frequency=target_sampling_frequency,\n    )\n\n    # Center the wavelet result around zero\n    accVLPIntCwt2 = accVLPIntCwt2 - np.mean(accVLPIntCwt2)\n    accVLPIntCwt2 = np.array(accVLPIntCwt2)\n\n    # Apply max_peaks_between_zc funtion to find peaks and their locations.\n    pks2, ipks2 = max_peaks_between_zc(accVLPIntCwt2)\n\n    # Calculate indx1 (logical indices of negative elements)\n    indx2 = pks2 &gt; 0\n\n    # Extract IC (indices of negative peaks)\n    final_contact = ipks2[indx2]\n\n    # Extract Foot-off Contact (FC) timings in seconds\n    FC_seconds = final_contact / target_sampling_frequency\n\n    return IC_seconds, FC_seconds\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.tilt_angle_estimation","title":"<code>tilt_angle_estimation(data, sampling_frequency_hz)</code>","text":"<p>Estimate tilt angle using simple method with gyro data.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>(ndarray, DataFrame)</code> <p>Array or DataFrame containing gyro data.</p> required <code>sampling_frequency_hz</code> <code>(float, int)</code> <p>Sampling frequency.</p> required <p>Returns:</p> Name Type Description <code>tilt</code> <code>ndarray</code> <p>Tilt angle estimate (deg).</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def tilt_angle_estimation(data, sampling_frequency_hz):\n    \"\"\"\n    Estimate tilt angle using simple method with gyro data.\n\n    Args:\n        data (ndarray, DataFrame): Array or DataFrame containing gyro data.\n        sampling_frequency_hz (float, int): Sampling frequency.\n\n    Returns:\n        tilt (ndarray): Tilt angle estimate (deg).\n    \"\"\"\n    # Error handling for invalid input data\n    if isinstance(data, pd.DataFrame):\n        data = data.to_numpy()\n\n    # Check if data is a numpy array\n    if not isinstance(data, np.ndarray):\n        raise TypeError(\"Input data must be a numpy array or pandas DataFrame\")\n\n    # Integrate gyro data over time to estimate tilt\n    tilt_angle = np.cumsum(data) / sampling_frequency_hz\n\n    return tilt_angle\n</code></pre>"},{"location":"utils/preprocessing/#utils.preprocessing.wavelet_decomposition","title":"<code>wavelet_decomposition(data, level, wavetype)</code>","text":"<p>Denoise a signal using wavelet decomposition and reconstruction.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>Input signal to denoise.</p> required <code>level</code> <code>int</code> <p>Order of wavelet decomposition.</p> required <code>wavetype</code> <code>str</code> <p>Wavelet type to use.</p> required <p>Returns:</p> Name Type Description <code>denoised_signal</code> <code>ndarray</code> <p>Denoised signal.</p> Source code in <code>kielmat/utils/preprocessing.py</code> <pre><code>def wavelet_decomposition(data, level, wavetype):\n    \"\"\"\n    Denoise a signal using wavelet decomposition and reconstruction.\n\n    Args:\n        data (ndarray): Input signal to denoise.\n        level (int): Order of wavelet decomposition.\n        wavetype (str): Wavelet type to use.\n\n    Returns:\n        denoised_signal (ndarray): Denoised signal.\n    \"\"\"\n    # Perform wavelet decomposition\n    coeffs = pywt.wavedec(data, wavetype, mode=\"constant\", level=level)\n\n    # Zero out wavelet coefficients beyond specified order\n    for i in range(1, len(coeffs)):\n        if i != 0:  # Keep the first set of coefficients\n            coeffs[i][:] = 0\n\n    # Reconstruct signal from coefficients\n    denoised_signal = pywt.waverec(coeffs, wavetype, mode=\"constant\")\n\n    return denoised_signal\n</code></pre>"}]}